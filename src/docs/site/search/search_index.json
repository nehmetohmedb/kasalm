{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Kasal","text":""},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Getting Started - Get up and running quickly with installation and configuration guides.</li> <li>Generation Features - Learn how to use AI to generate agents, tasks, and crew plans.</li> <li>Architecture - Understand Kasal's clean architecture and design principles.</li> <li>CrewAI Engine - Learn about Kasal's integration with CrewAI for agent-based workflows.</li> <li>Frontend - Explore the React frontend and state management with Zustand.</li> </ul>"},{"location":"#what-is-kasal","title":"What is Kasal?","text":"<p>Kasal is a low-code/no-code platform that makes it easy for non-technical users to build, orchestrate, and deploy agentic AI solutions. By providing a visual interface on top of the powerful CrewAI framework, Kasal democratizes access to AI agent technology, allowing anyone to create sophisticated AI workflows without writing code.</p> <p>At its core, Kasal abstracts away the complexity of the CrewAI framework, providing an intuitive interface where users can visually design, connect, and deploy autonomous AI agents that work together to solve complex problems.</p>"},{"location":"#core-functionality","title":"Core Functionality","text":"<p>Kasal empowers non-technical users to:</p> <ol> <li> <p>Design AI Agent Workflows Visually: Create multi-agent systems through an intuitive drag-and-drop interface, eliminating the need for coding knowledge.</p> </li> <li> <p>Orchestrate Agent Interactions: Define communication patterns and collaboration methods between agents using visual connectors and simple configuration panels.</p> </li> <li> <p>Monitor Executions in Real-Time: Track your AI agents' progress and outputs through comprehensive dashboards and visualizations.</p> </li> <li> <p>Connect to External Tools: Integrate with external services and data sources through pre-built connectors, no API expertise required.</p> </li> <li> <p>Deploy with One Click: Move from design to deployment seamlessly with simplified deployment options.</p> </li> </ol>"},{"location":"#technical-foundation","title":"Technical Foundation","text":"<p>While hiding complexity for end users, Kasal is built on a robust technical foundation:</p> <ul> <li>Backend: A FastAPI application with fully asynchronous request handling, organized in a clean, layered architecture.</li> <li>Database: SQLAlchemy 2.0 with async support, implementing the repository pattern for data access.</li> <li>Frontend: A modern React application with Zustand state management and a responsive UI.</li> <li>API: RESTful API design with comprehensive OpenAPI documentation.</li> <li>Deployment: Built as a Python wheel package that can be easily installed and deployed.</li> </ul>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>Kasal follows a modular, layered architecture that separates concerns and promotes maintainability:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Frontend Layer                 \u2502\n\u2502                                                 \u2502\n\u2502  React Components + Zustand State Management    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   API Layer                     \u2502\n\u2502                                                 \u2502\n\u2502  FastAPI Routes + OpenAPI Documentation         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Service Layer                   \u2502\n\u2502                                                 \u2502\n\u2502  Business Logic + CrewAI Engine Integration     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               Repository Layer                  \u2502\n\u2502                                                 \u2502\n\u2502  Data Access + SQLAlchemy ORM                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                Database Layer                   \u2502\n\u2502                                                 \u2502\n\u2502  SQLite/PostgreSQL + Migrations                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#crewai-integration","title":"CrewAI Integration","text":"<p>Kasal simplifies the use of CrewAI, an advanced framework for orchestrating autonomous AI agents. While CrewAI is powerful, it typically requires Python programming knowledge. Kasal provides:</p>"},{"location":"#no-code-agent-creation","title":"No-Code Agent Creation","text":"<ul> <li>Visual Agent Builder: Create specialized agents with specific roles, goals, and backstories through a simple form interface</li> <li>Pre-configured Tools: Select from a library of ready-to-use tools without writing code</li> <li>Template Library: Start with pre-built agent templates for common use cases</li> </ul>"},{"location":"#visual-workflow-design","title":"Visual Workflow Design","text":"<ul> <li>Drag-and-Drop Interface: Design complex agent workflows visually</li> <li>Workflow Templates: Use pre-built workflow patterns for common scenarios</li> <li>Visual Dependency Mapping: Create task dependencies with simple connector lines</li> </ul>"},{"location":"#one-click-deployment","title":"One-Click Deployment","text":"<ul> <li>Execution Dashboard: Launch and monitor agent executions from a central dashboard</li> <li>Result Visualization: View and analyze results through intuitive visualizations</li> <li>Export Capabilities: Export results in various formats for further use</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Visual Workflow Designer: Build agent workflows without coding</li> <li>Template Library: Start quickly with pre-built agents and workflows</li> <li>Integration Marketplace: Connect to external services without API knowledge</li> <li>Real-Time Monitoring: Track agent activities through visual dashboards</li> <li>User-Friendly Interface: Designed for non-technical users</li> <li>Enterprise Security: Role-based access control and data protection</li> <li>Scalable Architecture: Handle workflows of any complexity</li> </ul>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>Our documentation is organized following best practices to help you find what you need:</p> <ul> <li>Getting Started: Installation and quick setup guides</li> <li>Architecture: System design and architectural patterns</li> <li>Features: Detailed documentation of key features</li> <li>Development: Guidelines for developers contributing to Kasal</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"Resource Description Installation Guide Step-by-step instructions to set up Kasal Generation Features Guide to AI-assisted agent, task, and crew generation Architecture Overview High-level overview of Kasal's architecture CrewAI Engine Details on the CrewAI integration Best Practices Recommended practices for working with Kasal API Reference Technical reference for Kasal's API"},{"location":"#contribution","title":"Contribution","text":"<p>We welcome contributions to Kasal! If you'd like to contribute, please review our Best Practices guide and submit a pull request.</p> <p> Kasal Documentation \u2022 Built with MkDocs and Material for MkDocs </p>"},{"location":"ARCHITECTURE/","title":"Modern Python Backend Architecture","text":"<p>This document provides a comprehensive guide to the architecture and design patterns used in our modern Python backend, built with FastAPI and SQLAlchemy 2.0.</p>"},{"location":"ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Architecture Overview</li> <li>Design Patterns</li> <li>Layers and Responsibilities</li> <li>Dependency Injection</li> <li>Database Access</li> <li>Database Seeding</li> <li>API Development</li> <li>Error Handling</li> <li>Testing</li> <li>Security Best Practices</li> <li>Performance Optimization</li> <li>Service Consolidation</li> </ul>"},{"location":"ARCHITECTURE/#architecture-overview","title":"Architecture Overview","text":"<p>This backend follows a layered architecture pattern with clear separation of concerns, promoting maintainability, testability, and scalability. The architecture is inspired by Domain-Driven Design (DDD) principles and Clean Architecture.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502\n\u2502    API Layer    \u2502 FastAPI Routes\n\u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502\n\u2502  Service Layer  \u2502 Business Logic\n\u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502\n\u2502 Repository Layer\u2502 Data Access \n\u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502\n\u2502 Database Layer  \u2502 SQLAlchemy Models\n\u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#key-features","title":"Key Features","text":"<ul> <li>Fully Asynchronous: Uses Python's async/await throughout all layers for maximum performance</li> <li>Type Safety: Comprehensive type hints for improved code quality and IDE support</li> <li>Clean Separation: Each layer has distinct responsibilities with well-defined interfaces</li> <li>Dependency Injection: Ensures loose coupling and easier testing</li> <li>Repository Pattern: Abstracts database access logic</li> <li>Unit of Work Pattern: Manages database transactions consistently</li> <li>Database Seeding: Idempotent population of predefined data</li> <li>Consolidated Services: Related functionality grouped in cohesive service modules</li> </ul>"},{"location":"ARCHITECTURE/#design-patterns","title":"Design Patterns","text":""},{"location":"ARCHITECTURE/#repository-pattern","title":"Repository Pattern","text":"<p>The Repository Pattern abstracts data access logic, providing a collection-like interface for domain objects.</p> <p>Benefits: - Centralizes data access logic - Decouples business logic from data access details - Makes testing easier through mocking - Simplifies switching data sources or ORM if needed</p> <p>Example: <pre><code>class ExecutionRepository(BaseRepository):\n    async def get_execution_by_job_id(self, job_id: str) -&gt; Optional[Execution]:\n        query = select(self.model).where(self.model.job_id == job_id)\n        result = await self.session.execute(query)\n        return result.scalars().first()\n\n    async def create_execution(self, data: Dict[str, Any]) -&gt; Execution:\n        execution = self.model(**data)\n        self.session.add(execution)\n        await self.session.commit()\n        await self.session.refresh(execution)\n        return execution\n</code></pre></p>"},{"location":"ARCHITECTURE/#unit-of-work-pattern","title":"Unit of Work Pattern","text":"<p>The Unit of Work pattern manages database transactions and ensures consistency.</p> <p>Benefits: - Maintains database integrity - Simplifies transaction management - Groups related operations - Ensures proper commit/rollback behavior</p> <p>Example: <pre><code>async with UnitOfWork() as uow:\n    item = await item_service.create(uow, item_data)\n    # Transaction is automatically committed on exit\n    # or rolled back on exception\n</code></pre></p>"},{"location":"ARCHITECTURE/#service-layer","title":"Service Layer","text":"<p>The Service Layer implements business logic, orchestrating operations using repositories.</p> <p>Benefits: - Centralizes business rules and workflows - Coordinates across multiple repositories - Enforces domain constraints - Provides a clear API for the controllers/routes</p> <p>Example: <pre><code>class ExecutionService:\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def create_execution(self, config: CrewConfig, background_tasks = None) -&gt; Dict[str, Any]:\n        # Implementation for creating a new execution\n        execution_id = ExecutionService.create_execution_id()\n        # ... service implementation details\n        return result\n</code></pre></p>"},{"location":"ARCHITECTURE/#layers-and-responsibilities","title":"Layers and Responsibilities","text":""},{"location":"ARCHITECTURE/#api-layer-fastapi-routes","title":"API Layer (FastAPI Routes)","text":"<p>The API layer is responsible for handling HTTP requests and responses. It's implemented using FastAPI routes.</p> <p>Responsibilities: - Request validation - Route definitions - Parameter parsing - Response formatting - HTTP status codes - Authentication/Authorization checks - Documentation</p> <p>Example: <pre><code>@router.post(\"\", response_model=ExecutionCreateResponse)\nasync def create_execution(\n    config: CrewConfig,\n    background_tasks: BackgroundTasks, \n    db: AsyncSession = Depends(get_db)\n):\n    execution_service = ExecutionService(db)\n    result = await execution_service.create_execution(\n        config=config,\n        background_tasks=background_tasks\n    )\n    return ExecutionCreateResponse(**result)\n</code></pre></p>"},{"location":"ARCHITECTURE/#service-layer_1","title":"Service Layer","text":"<p>The service layer contains business logic and orchestrates operations.</p> <p>Responsibilities: - Implementing business rules - Orchestrating repositories - Transaction management - Domain logic - Input validation - Business-specific validation</p>"},{"location":"ARCHITECTURE/#repository-layer","title":"Repository Layer","text":"<p>The repository layer abstracts data access operations.</p> <p>Responsibilities: - Data access operations (CRUD) - Query building - Custom query methods - Database-specific implementations - Mapping between database models and domain models</p>"},{"location":"ARCHITECTURE/#database-layer","title":"Database Layer","text":"<p>The database layer defines the data models and database connection.</p> <p>Responsibilities: - Database connection management - Model definitions - Schema migrations - Database constraints and relationships</p>"},{"location":"ARCHITECTURE/#seeds-layer","title":"Seeds Layer","text":"<p>The seeds layer provides functionality for populating the database with predefined data.</p> <p>Responsibilities: - Defining default data for tables - Idempotent insertion of records - Supporting both development and production environments - Ensuring data consistency across deployments</p>"},{"location":"ARCHITECTURE/#dependency-injection","title":"Dependency Injection","text":"<p>FastAPI's dependency injection system is used throughout the application to provide:</p> <ul> <li>Database sessions</li> <li>Repositories</li> <li>Services</li> <li>Configuration</li> <li>Authentication</li> </ul> <p>Benefits: - Looser coupling between components - Easier testing through mocking - Cleaner code with less boilerplate - Better separation of concerns</p> <p>Example: <pre><code>def get_service(\n    service_class: Type[BaseService],\n    repository_class: Type[BaseRepository],\n    model_class: Type[Base],\n) -&gt; Callable[[UOWDep], BaseService]:\n    def _get_service(uow: UOWDep) -&gt; BaseService:\n        return service_class(repository_class, model_class, uow)\n    return _get_service\n\n# Usage:\nget_item_service = get_service(ItemService, ItemRepository, Item)\n\n@router.get(\"/{item_id}\")\nasync def read_item(\n    item_id: int,\n    service: Annotated[ItemService, Depends(get_item_service)],\n):\n    # Use service here\n</code></pre></p>"},{"location":"ARCHITECTURE/#database-access","title":"Database Access","text":"<p>Database access is built on SQLAlchemy 2.0 with asynchronous support.</p> <p>Key Components: - <code>AsyncSession</code>: Asynchronous database session for non-blocking database access - <code>Base</code>: SQLAlchemy declarative base class for database models - <code>Migrations</code>: Alembic for database schema migrations - <code>UnitOfWork</code>: Pattern for transaction management</p> <p>Best Practices: - Use async/await for database operations - Define explicit relationships between models - Use migrations for schema changes</p>"},{"location":"ARCHITECTURE/#database-seeding","title":"Database Seeding","text":"<p>The application includes a database seeding system to populate tables with predefined data.</p> <p>Key Components: - <code>Seeders</code>: Modular components for populating specific tables - <code>Seed Runner</code>: Utility for running seeders individually or as a group - <code>Auto-Seeding</code>: Optional functionality to seed on application startup</p> <p>Architecture: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502\n\u2502   Seed Runner   \u2502 Command-line interface\n\u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502     \u2502                 \u2502\n\u2502  Tools Seeder   \u2502     \u2502 Schemas Seeder  \u2502\n\u2502                 \u2502     \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502\n         \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502     \u2502                 \u2502\n\u2502 Templates Seeder\u2502     \u2502 ModelConfig Seeder\n\u2502                 \u2502     \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502\n         \u2502                       \u2502\n         \u25bc                       \u25bc\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u2502                             \u2502\n      \u2502         Database            \u2502\n      \u2502                             \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Best Practices: - Make seeders idempotent (can be run multiple times) - Check for existing records before inserting - Use proper transactions for data consistency - Split large datasets into logical modules - Include both async and sync implementations - Use UTC timestamps for created_at and updated_at fields</p> <p>For more details, see Database Seeding.</p>"},{"location":"ARCHITECTURE/#api-development","title":"API Development","text":"<p>APIs are built using FastAPI with a focus on RESTful design.</p> <p>Best Practices: - Use proper HTTP methods (GET, POST, PUT, PATCH, DELETE) - Return appropriate status codes - Validate input with Pydantic models - Document APIs with docstrings - Use path parameters for resource identifiers - Use query parameters for filtering and pagination - Implement proper error handling</p>"},{"location":"ARCHITECTURE/#error-handling","title":"Error Handling","text":"<p>Errors are handled consistently across the application:</p> <ul> <li>HTTPExceptions: For API errors with proper status codes</li> <li>Custom Exceptions: For domain-specific errors</li> <li>Validation Errors: Handled by Pydantic and FastAPI</li> </ul> <p>Error responses follow a consistent format: <pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre></p>"},{"location":"ARCHITECTURE/#testing","title":"Testing","text":"<p>The application is designed to be testable at all layers:</p> <ul> <li>Unit Tests: Testing individual components in isolation</li> <li>Integration Tests: Testing components together</li> <li>API Tests: Testing the HTTP endpoints</li> </ul> <p>Test tools: - pytest for test framework - pytest-asyncio for testing async code - pytest-cov for coverage reports</p> <p>Example unit test: <pre><code>@pytest.mark.asyncio\nasync def test_create_item(mock_uow, mock_repository):\n    with patch(\"src.services.item_service.ItemRepository\", return_value=mock_repository):\n        service = ItemService(mock_uow)\n        item_in = ItemCreate(name=\"Test Item\", price=10.0)\n\n        result = await service.create(item_in)\n\n        assert result is not None\n        assert result.name == \"Test Item\"\n        mock_repository.create.assert_called_once_with(item_in.model_dump())\n</code></pre></p>"},{"location":"ARCHITECTURE/#security-best-practices","title":"Security Best Practices","text":"<p>The architecture supports several security best practices:</p> <ul> <li>Dependency injection for authentication</li> <li>Environment-based configuration with sensitive values</li> <li>Input validation with Pydantic</li> <li>Database connection security</li> <li>Password hashing</li> <li>JWT token-based authentication</li> </ul>"},{"location":"ARCHITECTURE/#performance-optimization","title":"Performance Optimization","text":"<p>Several techniques are used for optimal performance:</p> <ul> <li>Asynchronous database access</li> <li>Connection pooling</li> <li>Pagination for large datasets</li> <li>Efficient query building</li> <li>Type hints for MyPy optimization</li> <li>Dependency caching</li> </ul>"},{"location":"ARCHITECTURE/#service-consolidation","title":"Service Consolidation","text":"<p>To maintain code cleanliness and reduce redundancy, we consolidate related services that handle the same domain entities. This approach reduces code fragmentation while improving maintainability.</p>"},{"location":"ARCHITECTURE/#execution-service-example","title":"Execution Service Example","text":"<p>The <code>ExecutionService</code> was formed by consolidating multiple execution-related services:</p> <pre><code>class ExecutionService:\n    \"\"\"\n    Service for execution-related operations.\n\n    Responsible for:\n    1. Running executions (crew and flow executions)\n    2. Tracking execution status\n    3. Generating descriptive execution names\n    4. Managing execution metadata\n    \"\"\"\n\n    # Service implementation...\n</code></pre> <p>Benefits of Service Consolidation:</p> <ol> <li>Single Responsibility per Domain: Each service handles one domain area</li> <li>Reduced File Count: Fewer files to navigate and maintain</li> <li>Clearer Dependencies: Methods that rely on each other are co-located</li> <li>Logical Grouping: Related operations are together</li> <li>Simplified Imports: External modules need to import from fewer places</li> </ol> <p>Consolidation Strategy:</p> <p>When deciding to consolidate services, we follow these guidelines:</p> <ol> <li>Services should operate on the same domain entities</li> <li>The combined service should maintain a clear purpose</li> <li>Methods should have logical cohesion</li> <li>The combined service shouldn't become too large (&gt;1000 lines is a warning sign)</li> </ol>"},{"location":"ARCHITECTURE/#router-consolidation","title":"Router Consolidation","text":"<p>Similar to services, we consolidate routers that handle endpoints related to the same domain area. This approach keeps related endpoints in the same file and simplifies API discovery.</p> <p>For example, the <code>executions_router.py</code> handles all execution-related endpoints:</p> <pre><code># In executions_router.py\n@router.post(\"\", response_model=ExecutionCreateResponse)\nasync def create_execution(...):\n    # Implementation...\n\n@router.get(\"/{execution_id}\", response_model=ExecutionResponse)\nasync def get_execution_status(...):\n    # Implementation...\n\n@router.post(\"/generate-name\", response_model=ExecutionNameGenerationResponse)\nasync def generate_execution_name(...):\n    # Implementation...\n</code></pre> <p>This consolidation ensures that related API endpoints are logically grouped, making the API more discoverable and the codebase more maintainable.</p>"},{"location":"ARCHITECTURE/#conclusion","title":"Conclusion","text":"<p>This modern Python backend architecture provides a solid foundation for building scalable, maintainable, and high-performance APIs. By following these patterns and practices, developers can create robust applications that are easy to understand, test, and extend. </p>"},{"location":"AUTHORIZATION/","title":"Kasal Platform Authorization Model","text":""},{"location":"AUTHORIZATION/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>User Model</li> <li>Role-Based Access Control</li> <li>Permission Model</li> <li>Authentication Flow</li> <li>Authorization Flow</li> <li>API Security</li> <li>Frontend Implementation</li> <li>Backend Implementation</li> <li>Identity Provider Integration</li> <li>Role and Privilege Configuration</li> <li>Testing Strategy</li> </ul>"},{"location":"AUTHORIZATION/#overview","title":"Overview","text":"<p>The Kasal Platform implements a comprehensive Role-Based Access Control (RBAC) system to manage user permissions and secure access to resources. This document outlines the authorization model and serves as the reference for both frontend and backend implementation.</p> <p>The system is designed with three primary user roles (Admin, Technical, Regular) with predefined permissions for each role. The authentication is implemented using JWT tokens with refresh token capabilities.</p>"},{"location":"AUTHORIZATION/#user-model","title":"User Model","text":""},{"location":"AUTHORIZATION/#core-user-entity","title":"Core User Entity","text":"<pre><code>interface User {\n  id: string;              // Unique identifier\n  username: string;        // Username for login\n  email: string;           // User email address\n  password: string;        // Hashed password (never returned to client)\n  role: UserRole;          // User role (enum)\n  status: UserStatus;      // Account status\n  created_at: string;      // Creation timestamp\n  updated_at: string;      // Last update timestamp\n  last_login: string;      // Last login timestamp\n}\n\nenum UserRole {\n  ADMIN = 'admin',\n  TECHNICAL = 'technical',\n  REGULAR = 'regular'\n}\n\nenum UserStatus {\n  ACTIVE = 'active',\n  INACTIVE = 'inactive',\n  SUSPENDED = 'suspended'\n}\n</code></pre>"},{"location":"AUTHORIZATION/#user-profile","title":"User Profile","text":"<p>Additional user information stored separately from core auth data:</p> <pre><code>interface UserProfile {\n  user_id: string;         // Reference to User\n  display_name: string;    // User's displayed name\n  avatar_url: string;      // Profile picture URL\n  preferences: object;     // User preferences (JSON)\n}\n</code></pre>"},{"location":"AUTHORIZATION/#external-identity-support","title":"External Identity Support","text":"<p>The system now supports linking user accounts with external identity providers:</p> <pre><code>interface ExternalIdentity {\n  id: string;              // Unique identifier\n  user_id: string;         // Reference to User\n  provider: string;        // Provider name\n  provider_user_id: string; // User ID in external system\n  email: string;           // Email from provider\n  profile_data: string;    // JSON profile data from provider\n  created_at: string;      // Creation timestamp\n  last_login: string;      // Last login timestamp\n}\n</code></pre>"},{"location":"AUTHORIZATION/#role-based-access-control","title":"Role-Based Access Control","text":""},{"location":"AUTHORIZATION/#user-roles","title":"User Roles","text":"<ol> <li>Admin</li> <li>Full access to all system features</li> <li>Can manage users (create, update, delete)</li> <li>Can assign roles to users</li> <li>Can configure system settings</li> <li> <p>Can perform all actions of Technical and Regular users</p> </li> <li> <p>Technical</p> </li> <li>Can create and manage agents and tasks</li> <li>Can configure workflows</li> <li>Can view system logs and metrics</li> <li>Can perform all actions of Regular users</li> <li> <p>Cannot manage users or change system settings</p> </li> <li> <p>Regular</p> </li> <li>Can run predefined agents and tasks</li> <li>Can view results and logs of their executions</li> <li>Cannot create new agents or tasks</li> <li>Cannot access system configuration</li> </ol>"},{"location":"AUTHORIZATION/#custom-roles","title":"Custom Roles","text":"<p>The system now supports custom roles with specific privilege sets:</p> <pre><code>interface Role {\n  id: string;              // Unique identifier\n  name: string;            // Role name\n  description: string;     // Role description\n  created_at: string;      // Creation timestamp\n  updated_at: string;      // Last update timestamp\n  privileges: string[];    // Array of privilege names\n}\n</code></pre>"},{"location":"AUTHORIZATION/#permission-model","title":"Permission Model","text":""},{"location":"AUTHORIZATION/#permission-structure","title":"Permission Structure","text":"<p>Permissions are defined as action-resource pairs and grouped by role.</p> <pre><code>interface Permission {\n  resource: string;       // Resource type (e.g., \"agent\", \"task\", \"user\")\n  action: string;         // Action (e.g., \"create\", \"read\", \"update\", \"delete\", \"execute\")\n}\n\n// Examples of permissions\nconst permissions = {\n  \"agent:create\": [\"admin\", \"technical\"],\n  \"agent:read\": [\"admin\", \"technical\", \"regular\"],\n  \"agent:update\": [\"admin\", \"technical\"],\n  \"agent:delete\": [\"admin\"],\n  \"agent:execute\": [\"admin\", \"technical\", \"regular\"],\n\n  \"task:create\": [\"admin\", \"technical\"],\n  \"task:read\": [\"admin\", \"technical\", \"regular\"],\n  \"task:update\": [\"admin\", \"technical\"],\n  \"task:delete\": [\"admin\"],\n  \"task:execute\": [\"admin\", \"technical\", \"regular\"],\n\n  \"user:create\": [\"admin\"],\n  \"user:read\": [\"admin\"],\n  \"user:update\": [\"admin\"],\n  \"user:delete\": [\"admin\"],\n\n  \"system:configure\": [\"admin\"]\n}\n</code></pre>"},{"location":"AUTHORIZATION/#privileges-model","title":"Privileges Model","text":"<p>The system implements a flexible privilege system:</p> <pre><code>interface Privilege {\n  id: string;              // Unique identifier\n  name: string;            // Privilege name (format: \"resource:action\")\n  description: string;     // Privilege description\n  created_at: string;      // Creation timestamp\n}\n\ninterface RolePrivilege {\n  id: string;              // Unique identifier\n  role_id: string;         // Reference to Role\n  privilege_id: string;    // Reference to Privilege\n}\n</code></pre>"},{"location":"AUTHORIZATION/#permission-checking","title":"Permission Checking","text":"<p>Permissions are checked using: 1. Role-based checks (simpler, default approach) 2. Granular permission checks via the new RoleService</p>"},{"location":"AUTHORIZATION/#authentication-flow","title":"Authentication Flow","text":""},{"location":"AUTHORIZATION/#registration","title":"Registration","text":"<ol> <li>User submits registration form with username, email, password</li> <li>System validates input and checks for existing users</li> <li>Password is hashed using bcrypt</li> <li>New user is created with default \"regular\" role</li> <li>Welcome email is sent</li> <li>User is redirected to login page</li> </ol>"},{"location":"AUTHORIZATION/#login","title":"Login","text":"<ol> <li>User submits login form with username/email and password</li> <li>System validates credentials</li> <li>If valid, system generates:</li> <li>Access token (short-lived JWT, 15 minutes)</li> <li>Refresh token (longer-lived JWT, 7 days)</li> <li>Tokens are returned to client</li> <li>Client stores tokens (access token in memory, refresh token in httpOnly cookie)</li> </ol>"},{"location":"AUTHORIZATION/#external-provider-authentication","title":"External Provider Authentication","text":"<ol> <li>User selects an identity provider (Google, GitHub, etc.)</li> <li>User is redirected to the provider's authentication page</li> <li>After successful authentication, provider redirects back with authorization code</li> <li>Backend exchanges code for user information</li> <li>If user with linked identity exists, they are logged in</li> <li>If user with matching email exists, identity is linked to their account</li> <li>Otherwise, a new user account is created and linked to the identity</li> </ol>"},{"location":"AUTHORIZATION/#token-refresh","title":"Token Refresh","text":"<ol> <li>When access token expires, client uses refresh token to get new access token</li> <li>If refresh token is valid, new access token is issued</li> <li>If refresh token is invalid or expired, user is logged out and redirected to login</li> </ol>"},{"location":"AUTHORIZATION/#logout","title":"Logout","text":"<ol> <li>Client clears tokens from storage</li> <li>Refresh token is invalidated on server</li> <li>User is redirected to login page</li> </ol>"},{"location":"AUTHORIZATION/#authorization-flow","title":"Authorization Flow","text":""},{"location":"AUTHORIZATION/#api-request-authorization","title":"API Request Authorization","text":"<ol> <li>Client includes access token in Authorization header</li> <li>Backend middleware validates token signature and expiration</li> <li>If token is valid, user information is extracted and attached to request</li> <li>Route handlers check user role against required permissions</li> <li>Request is processed or rejected based on permissions</li> </ol>"},{"location":"AUTHORIZATION/#frontend-authorization","title":"Frontend Authorization","text":"<ol> <li>Protected routes check user authentication status</li> <li>UI components are conditionally rendered based on user permissions</li> <li>Action buttons are disabled or hidden based on user permissions</li> </ol>"},{"location":"AUTHORIZATION/#api-security","title":"API Security","text":""},{"location":"AUTHORIZATION/#token-security","title":"Token Security","text":"<ul> <li>Access tokens expire quickly (15 minutes)</li> <li>Refresh tokens have longer life but are securely stored</li> <li>All tokens are signed with a server secret</li> <li>Token rotation on suspicious activity</li> </ul>"},{"location":"AUTHORIZATION/#api-endpoints-security","title":"API Endpoints Security","text":"<ol> <li>Public Endpoints (no auth required)</li> <li><code>/auth/login</code></li> <li><code>/auth/register</code></li> <li><code>/auth/forgot-password</code></li> <li> <p><code>/auth/reset-password</code></p> </li> <li> <p>Protected Endpoints (require authentication)</p> </li> <li><code>/auth/refresh-token</code></li> <li><code>/auth/logout</code></li> <li> <p><code>/users/me</code></p> </li> <li> <p>Role-Restricted Endpoints (require specific roles)</p> </li> <li><code>/users</code> (admin only)</li> <li><code>/roles</code> (admin only)</li> <li><code>/identity-providers</code> (admin only)</li> <li><code>/agents/create</code> (admin, technical)</li> <li><code>/tasks/create</code> (admin, technical)</li> </ol>"},{"location":"AUTHORIZATION/#security-headers","title":"Security Headers","text":"<ul> <li>CORS configuration to restrict allowed origins</li> <li>Content-Security-Policy to prevent XSS</li> <li>X-Content-Type-Options to prevent MIME sniffing</li> <li>X-Frame-Options to prevent clickjacking</li> </ul>"},{"location":"AUTHORIZATION/#frontend-implementation","title":"Frontend Implementation","text":""},{"location":"AUTHORIZATION/#authentication-store-zustand","title":"Authentication Store (Zustand)","text":"<pre><code>// authStore.ts structure\ninterface AuthState {\n  user: User | null;\n  token: string | null;\n  isAuthenticated: boolean;\n  isLoading: boolean;\n  error: string | null;\n\n  login: (email: string, password: string) =&gt; Promise&lt;void&gt;;\n  logout: () =&gt; void;\n  register: (userData: RegisterData) =&gt; Promise&lt;void&gt;;\n  refreshToken: () =&gt; Promise&lt;boolean&gt;;\n  clearError: () =&gt; void;\n\n  hasPermission: (permission: string) =&gt; boolean;\n  isAdmin: () =&gt; boolean;\n  isTechnical: () =&gt; boolean;\n}\n</code></pre>"},{"location":"AUTHORIZATION/#protected-routes","title":"Protected Routes","text":"<pre><code>// Example of protected route implementation\nconst ProtectedRoute = ({ children, requiredRole }) =&gt; {\n  const { isAuthenticated, hasPermission } = useAuth();\n\n  if (!isAuthenticated) {\n    return &lt;Navigate to=\"/login\" /&gt;;\n  }\n\n  if (requiredRole &amp;&amp; !hasPermission(requiredRole)) {\n    return &lt;Navigate to=\"/unauthorized\" /&gt;;\n  }\n\n  return children;\n};\n</code></pre>"},{"location":"AUTHORIZATION/#ui-access-control","title":"UI Access Control","text":"<pre><code>// Example of conditional rendering based on permissions\nconst ActionsMenu = () =&gt; {\n  const { isAdmin, isTechnical } = useAuth();\n\n  return (\n    &lt;Menu&gt;\n      {/* Available to all authenticated users */}\n      &lt;MenuItem&gt;View Dashboard&lt;/MenuItem&gt;\n\n      {/* Only for technical and admin users */}\n      {isTechnical() &amp;&amp; (\n        &lt;&gt;\n          &lt;MenuItem&gt;Create Agent&lt;/MenuItem&gt;\n          &lt;MenuItem&gt;Create Task&lt;/MenuItem&gt;\n        &lt;/&gt;\n      )}\n\n      {/* Only for admin users */}\n      {isAdmin() &amp;&amp; (\n        &lt;&gt;\n          &lt;MenuItem&gt;Manage Users&lt;/MenuItem&gt;\n          &lt;MenuItem&gt;System Settings&lt;/MenuItem&gt;\n        &lt;/&gt;\n      )}\n    &lt;/Menu&gt;\n  );\n};\n</code></pre>"},{"location":"AUTHORIZATION/#backend-implementation","title":"Backend Implementation","text":""},{"location":"AUTHORIZATION/#database-models","title":"Database Models","text":"<p>User model with relationships to roles and permissions:</p> <pre><code># SQLAlchemy model example\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(String, primary_key=True, default=generate_uuid)\n    username = Column(String, unique=True, index=True, nullable=False)\n    email = Column(String, unique=True, index=True, nullable=False)\n    hashed_password = Column(String, nullable=False)\n    role = Column(Enum(\"admin\", \"technical\", \"regular\"), default=\"regular\")\n    status = Column(Enum(\"active\", \"inactive\", \"suspended\"), default=\"active\")\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    last_login = Column(DateTime, nullable=True)\n\n    # Relationships\n    profile = relationship(\"UserProfile\", back_populates=\"user\", uselist=False)\n    refresh_tokens = relationship(\"RefreshToken\", back_populates=\"user\")\n    external_identities = relationship(\"ExternalIdentity\", back_populates=\"user\")\n\nclass Role(Base):\n    __tablename__ = \"roles\"\n\n    id = Column(String, primary_key=True, default=generate_uuid)\n    name = Column(String, nullable=False, unique=True)\n    description = Column(String, nullable=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n    # Relationships\n    role_privileges = relationship(\"RolePrivilege\", back_populates=\"role\")\n\nclass Privilege(Base):\n    __tablename__ = \"privileges\"\n\n    id = Column(String, primary_key=True, default=generate_uuid)\n    name = Column(String, nullable=False, unique=True)\n    description = Column(String, nullable=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    # Relationships\n    role_privileges = relationship(\"RolePrivilege\", back_populates=\"privilege\")\n\nclass RolePrivilege(Base):\n    __tablename__ = \"role_privileges\"\n\n    id = Column(String, primary_key=True, default=generate_uuid)\n    role_id = Column(String, ForeignKey(\"roles.id\", ondelete=\"CASCADE\"))\n    privilege_id = Column(String, ForeignKey(\"privileges.id\", ondelete=\"CASCADE\"))\n\n    # Relationships\n    role = relationship(\"Role\", back_populates=\"role_privileges\")\n    privilege = relationship(\"Privilege\", back_populates=\"role_privileges\")\n</code></pre>"},{"location":"AUTHORIZATION/#role-service","title":"Role Service","text":"<p>The new RoleService provides comprehensive role and privilege management:</p> <pre><code>class RoleService:\n    \"\"\"Service for role management operations\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        self.session = session\n        self.role_repo = RoleRepository(Role, session)\n        self.privilege_repo = PrivilegeRepository(Privilege, session)\n        self.role_privilege_repo = RolePrivilegeRepository(RolePrivilege, session)\n\n    async def get_role(self, role_id: str) -&gt; Optional[Role]:\n        \"\"\"Get a role by ID\"\"\"\n        return await self.role_repo.get(role_id)\n\n    async def get_role_with_privileges(self, role_id: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get a role with its privileges\"\"\"\n        # Implementation...\n\n    async def create_role(self, role_data: RoleCreate) -&gt; Dict[str, Any]:\n        \"\"\"Create a new role with privileges\"\"\"\n        # Implementation...\n\n    async def update_role(self, role_id: str, role_data: RoleUpdate) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Update a role and its privileges\"\"\"\n        # Implementation...\n\n    async def delete_role(self, role_id: str) -&gt; bool:\n        \"\"\"Delete a role\"\"\"\n        # Implementation...\n\n    async def check_role_has_privilege(self, role_id: str, privilege_name: str) -&gt; bool:\n        \"\"\"Check if a role has a specific privilege\"\"\"\n        # Implementation...\n</code></pre>"},{"location":"AUTHORIZATION/#identity-provider-service","title":"Identity Provider Service","text":"<p>The new IdentityProviderService manages external authentication providers:</p> <pre><code>class IdentityProviderService:\n    \"\"\"Service for identity provider management operations\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        self.session = session\n        self.provider_repo = IdentityProviderRepository(IdentityProvider, session)\n        self.external_identity_repo = ExternalIdentityRepository(ExternalIdentity, session)\n\n    async def get_provider(self, provider_id: str) -&gt; Optional[IdentityProvider]:\n        \"\"\"Get a provider by ID\"\"\"\n        # Implementation...\n\n    async def get_providers(self, skip: int = 0, limit: int = 100, enabled_only: bool = False) -&gt; List[IdentityProvider]:\n        \"\"\"Get a list of identity providers\"\"\"\n        # Implementation...\n\n    async def create_provider(self, provider_data: IdentityProviderCreate) -&gt; IdentityProvider:\n        \"\"\"Create a new identity provider\"\"\"\n        # Implementation...\n\n    async def update_provider(self, provider_id: str, provider_data: IdentityProviderUpdate) -&gt; Optional[IdentityProvider]:\n        \"\"\"Update an identity provider\"\"\"\n        # Implementation...\n\n    async def delete_provider(self, provider_id: str) -&gt; bool:\n        \"\"\"Delete an identity provider\"\"\"\n        # Implementation...\n\n    async def toggle_provider_status(self, provider_id: str, enabled: bool) -&gt; Optional[IdentityProvider]:\n        \"\"\"Enable or disable an identity provider\"\"\"\n        # Implementation...\n</code></pre>"},{"location":"AUTHORIZATION/#authentication-service","title":"Authentication Service","text":"<pre><code># Updated authentication service\nclass AuthService:\n    \"\"\"Service for authentication operations\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        self.session = session\n        self.user_repo = UserRepository(User, session)\n        self.refresh_token_repo = RefreshTokenRepository(RefreshToken, session)\n        self.user_profile_repo = UserProfileRepository(UserProfile, session)\n        self.external_identity_repo = ExternalIdentityRepository(ExternalIdentity, session)\n        self.identity_provider_repo = IdentityProviderRepository(IdentityProvider, session)\n\n    async def authenticate_user(self, username_or_email: str, password: str) -&gt; Optional[User]:\n        \"\"\"Authenticate a user by username/email and password\"\"\"\n        # Implementation...\n\n    async def register_user(self, user_data: UserCreate) -&gt; User:\n        \"\"\"Register a new user\"\"\"\n        # Implementation...\n\n    async def create_user_tokens(self, user: User) -&gt; Dict[str, str]:\n        \"\"\"Create access and refresh tokens for a user\"\"\"\n        # Implementation...\n\n    async def authenticate_with_external_provider(\n        self, provider: str, provider_user_id: str, email: str, profile_data: Dict[str, Any] = None\n    ) -&gt; Tuple[User, bool]:\n        \"\"\"Authenticate a user with an external identity provider\"\"\"\n        # Implementation...\n</code></pre>"},{"location":"AUTHORIZATION/#authorization-middleware","title":"Authorization Middleware","text":"<pre><code># FastAPI dependency for authentication\nasync def get_current_user(\n    token: str = Depends(oauth2_scheme),\n    session: AsyncSession = Depends(get_db)\n) -&gt; User:\n    \"\"\"Get the current user from the token.\"\"\"\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n\n    try:\n        # Decode JWT\n        payload = jwt.decode(\n            token, \n            settings.JWT_SECRET_KEY, \n            algorithms=[settings.JWT_ALGORITHM]\n        )\n        user_id: str = payload.get(\"sub\")\n        if user_id is None:\n            raise credentials_exception\n    except JWTError:\n        raise credentials_exception\n\n    # Get user from database\n    user_service = UserService(session)\n    user = await user_service.get_user(user_id)\n    if user is None:\n        raise credentials_exception\n\n    return user\n\n# Role-checking dependency\ndef check_user_role(allowed_roles: List[str]):\n    \"\"\"Check if the current user has one of the allowed roles.\"\"\"\n    async def _check_role(current_user: User = Depends(get_current_user)):\n        if current_user.role not in allowed_roles:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Not enough permissions\"\n            )\n        return current_user\n\n    return _check_role\n\n# Permission-checking dependency\ndef check_permission(permission: str):\n    \"\"\"Check if the current user has the required permission.\"\"\"\n    async def _check_permission(\n        current_user: User = Depends(get_current_user),\n        session: AsyncSession = Depends(get_db)\n    ) -&gt; User:\n        # Implementation...\n\n    return _check_permission\n</code></pre>"},{"location":"AUTHORIZATION/#identity-provider-integration","title":"Identity Provider Integration","text":"<p>The platform supports multiple authentication methods including local username/password authentication and integration with external identity providers.</p>"},{"location":"AUTHORIZATION/#supported-identity-providers","title":"Supported Identity Providers","text":"<ol> <li>Local Authentication</li> <li>Username/password stored in the application database</li> <li>Default method if no external providers are configured</li> <li>Supports password hashing with bcrypt</li> <li> <p>Password reset flow with email confirmation</p> </li> <li> <p>OAuth 2.0 / OpenID Connect Providers</p> </li> <li> <p>Google</p> <ul> <li>OAuth 2.0 and OpenID Connect compliant</li> <li>Provides email verification automatically</li> <li>Profile information access for user details</li> <li>Requires Google Cloud Console project setup</li> </ul> </li> <li> <p>GitHub</p> <ul> <li>OAuth 2.0 compliant</li> <li>User information through GitHub API</li> <li>Team/organization membership for role mapping</li> <li>Requires GitHub OAuth App registration</li> </ul> </li> <li> <p>Microsoft Entra ID (formerly Azure AD)</p> <ul> <li>OpenID Connect and OAuth 2.0 compliant</li> <li>Enterprise user directory integration</li> <li>Group membership for role mapping</li> <li>Tenant-specific configuration</li> <li>Requires application registration in Azure portal</li> </ul> </li> <li> <p>AWS Cognito</p> <ul> <li>OpenID Connect and OAuth 2.0 compliant</li> <li>User pool management</li> <li>Custom attributes for role assignments</li> <li>Requires AWS Cognito user pool setup</li> </ul> </li> <li> <p>Auth0</p> <ul> <li>Identity-as-a-Service platform</li> <li>Support for social logins (Google, Facebook, Twitter, etc.)</li> <li>Rules and hooks for custom authentication logic</li> <li>Role management through Auth0 dashboard</li> <li>Requires Auth0 tenant setup</li> </ul> </li> <li> <p>Okta</p> <ul> <li>Enterprise identity provider</li> <li>User directory synchronization</li> <li>Group-based access control</li> <li>Custom authorization servers</li> <li>Requires Okta developer account</li> </ul> </li> <li> <p>SAML 2.0 Providers</p> </li> <li>Support for enterprise identity providers using SAML</li> <li>Attribute mapping for user information</li> <li>Metadata exchange for configuration</li> <li> <p>IdP-initiated and SP-initiated flows</p> </li> <li> <p>Custom Identity Provider Integration</p> </li> <li>Extensible architecture for custom provider integration</li> <li>Pluggable authentication modules</li> <li>Custom provider implementation guidelines</li> </ol>"},{"location":"AUTHORIZATION/#provider-configuration","title":"Provider Configuration","text":"<p>The platform now includes a comprehensive API for managing identity providers:</p> <pre><code>@router.get(\n    \"/\",\n    response_model=List[IdentityProviderResponse],\n    summary=\"Get all identity providers\"\n)\nasync def get_identity_providers(\n    skip: int = 0,\n    limit: int = 100,\n    enabled_only: bool = False,\n    session: AsyncSession = Depends(get_db),\n    current_user: User = Depends(get_current_user),\n):\n    # Implementation...\n\n@router.post(\n    \"/\",\n    response_model=IdentityProviderResponse,\n    status_code=status.HTTP_201_CREATED,\n    summary=\"Create a new identity provider\",\n    dependencies=[Depends(admin_only)],\n)\nasync def create_identity_provider(\n    provider_data: IdentityProviderCreate,\n    session: AsyncSession = Depends(get_db),\n):\n    # Implementation...\n\n@router.put(\n    \"/{provider_id}\",\n    response_model=IdentityProviderResponse,\n    summary=\"Update an identity provider\",\n    dependencies=[Depends(admin_only)],\n)\nasync def update_identity_provider(\n    provider_id: str,\n    provider_data: IdentityProviderUpdate,\n    session: AsyncSession = Depends(get_db),\n):\n    # Implementation...\n\n@router.patch(\n    \"/{provider_id}/toggle\",\n    response_model=IdentityProviderResponse,\n    summary=\"Toggle an identity provider's status\",\n    dependencies=[Depends(admin_only)],\n)\nasync def toggle_identity_provider(\n    provider_id: str,\n    enabled: bool,\n    session: AsyncSession = Depends(get_db),\n):\n    # Implementation...\n</code></pre>"},{"location":"AUTHORIZATION/#role-and-privilege-configuration","title":"Role and Privilege Configuration","text":"<p>The platform provides an administrative API for configuring roles and assigning granular privileges.</p>"},{"location":"AUTHORIZATION/#role-management-api","title":"Role Management API","text":"<pre><code>@router.get(\"\", response_model=List[RoleInDB])\nasync def read_roles(\n    skip: int = 0,\n    limit: int = 100,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Get list of roles\"\"\"\n    # Implementation...\n\n@router.post(\"\", response_model=RoleWithPrivileges, status_code=status.HTTP_201_CREATED)\nasync def create_role(\n    role_data: RoleCreate,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Create a new role\"\"\"\n    # Implementation...\n\n@router.get(\"/{role_id}\", response_model=RoleWithPrivileges)\nasync def read_role(\n    role_id: str,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Get a role by ID\"\"\"\n    # Implementation...\n\n@router.put(\"/{role_id}\", response_model=RoleWithPrivileges)\nasync def update_role(\n    role_id: str,\n    role_data: RoleUpdate,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Update a role\"\"\"\n    # Implementation...\n\n@router.delete(\"/{role_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_role(\n    role_id: str,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Delete a role\"\"\"\n    # Implementation...\n</code></pre>"},{"location":"AUTHORIZATION/#privilege-management-api","title":"Privilege Management API","text":"<pre><code>@privilege_router.get(\"\", response_model=List[PrivilegeInDB])\nasync def read_privileges(\n    skip: int = 0,\n    limit: int = 100,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Get list of privileges\"\"\"\n    # Implementation...\n\n@privilege_router.post(\"\", response_model=PrivilegeInDB, status_code=status.HTTP_201_CREATED)\nasync def create_privilege(\n    privilege_data: PrivilegeCreate,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Create a new privilege\"\"\"\n    # Implementation...\n\n@privilege_router.get(\"/{privilege_id}\", response_model=PrivilegeInDB)\nasync def read_privilege(\n    privilege_id: str,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Get a privilege by ID\"\"\"\n    # Implementation...\n\n@privilege_router.put(\"/{privilege_id}\", response_model=PrivilegeInDB)\nasync def update_privilege(\n    privilege_id: str,\n    privilege_data: PrivilegeUpdate,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Update a privilege\"\"\"\n    # Implementation...\n\n@privilege_router.delete(\"/{privilege_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_privilege(\n    privilege_id: str,\n    session: AsyncSession = Depends(get_db),\n):\n    \"\"\"Delete a privilege\"\"\"\n    # Implementation...\n</code></pre>"},{"location":"AUTHORIZATION/#testing-strategy","title":"Testing Strategy","text":"<p>Comprehensive testing is implemented for authentication and authorization components:</p> <ol> <li>Unit Tests</li> <li>Service layer tests for AuthService, RoleService, and IdentityProviderService</li> <li>Repository layer tests for data access operations</li> <li> <p>Permission checking logic tests</p> </li> <li> <p>Integration Tests</p> </li> <li>API endpoint tests with authentication</li> <li>Role-based access control tests</li> <li>Token generation and validation tests</li> <li> <p>Identity provider integration tests</p> </li> <li> <p>End-to-End Tests</p> </li> <li>Complete authentication flows</li> <li>Role assignment and permission checking</li> <li> <p>External identity provider authentication</p> </li> <li> <p>Security Tests</p> </li> <li>JWT token validation and security</li> <li>Password hashing effectiveness</li> <li>CSRF protection verification</li> <li>Rate limiting and brute force prevention </li> </ol>"},{"location":"BEST_PRACTICES/","title":"Python Backend Best Practices","text":"<p>This document outlines the best practices for Python backend development using FastAPI, SQLAlchemy, and related technologies. Following these guidelines will help maintain code quality, performance, and maintainability.</p>"},{"location":"BEST_PRACTICES/#project-structure","title":"Project Structure","text":"<ul> <li>Organize by feature/domain rather than by technical role</li> <li>Keep related code (routes, models, schemas, services) together</li> <li>Use consistent naming conventions</li> <li>Limit file size (max 400 lines recommended)</li> <li>Use <code>__init__.py</code> files to expose public interfaces</li> </ul> <pre><code>backend/\n\u251c\u2500\u2500 src/                 # Application source code\n\u2502   \u251c\u2500\u2500 api/             # API routes and controllers\n\u2502   \u251c\u2500\u2500 core/            # Core application components\n\u2502   \u251c\u2500\u2500 db/              # Database setup and session management\n\u2502   \u251c\u2500\u2500 models/          # SQLAlchemy models\n\u2502   \u251c\u2500\u2500 repositories/    # Repository pattern implementations\n\u2502   \u251c\u2500\u2500 schemas/         # Pydantic models for validation\n\u2502   \u251c\u2500\u2500 services/        # Business logic services\n\u2502   \u251c\u2500\u2500 config/          # Configuration management\n\u2502   \u251c\u2500\u2500 utils/           # Utility functions\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 main.py          # Application entry point\n\u251c\u2500\u2500 tests/               # Test suite\n\u2502   \u251c\u2500\u2500 integration/     # Integration tests\n\u2502   \u2514\u2500\u2500 unit/            # Unit tests\n\u251c\u2500\u2500 migrations/          # Alembic migration scripts\n\u251c\u2500\u2500 pyproject.toml       # Dependencies and build settings\n\u251c\u2500\u2500 alembic.ini          # Alembic configuration\n\u2514\u2500\u2500 README.md            # Project documentation\n</code></pre>"},{"location":"BEST_PRACTICES/#code-organization","title":"Code Organization","text":""},{"location":"BEST_PRACTICES/#layered-architecture","title":"Layered Architecture","text":"<ul> <li>API Layer: FastAPI routes and controllers</li> <li>Service Layer: Business logic</li> <li>Repository Layer: Data access and persistence</li> <li>Database Layer: Database models and connection</li> </ul>"},{"location":"BEST_PRACTICES/#design-patterns","title":"Design Patterns","text":"<ul> <li>Repository Pattern: For data access abstraction</li> <li>Unit of Work Pattern: For transaction management</li> <li>Service Layer Pattern: For business logic encapsulation</li> <li>Dependency Injection: For loose coupling and testability</li> </ul>"},{"location":"BEST_PRACTICES/#fastapi-best-practices","title":"FastAPI Best Practices","text":""},{"location":"BEST_PRACTICES/#routing","title":"Routing","text":"<ul> <li>Group related endpoints in separate router files</li> <li>Use descriptive route names</li> <li>Follow RESTful conventions for HTTP methods</li> <li>Use proper status codes</li> <li>Implement pagination for collection endpoints</li> <li>Use path parameters for resource identifiers</li> <li>Use query parameters for filtering/sorting</li> </ul> <pre><code>@router.get(\"/{item_id}\", response_model=ItemSchema)\nasync def read_item(\n    item_id: int,\n    service: Annotated[ItemService, Depends(get_item_service)],\n):\n    item = await service.get(item_id)\n    if not item:\n        raise HTTPException(status_code=404, detail=\"Item not found\")\n    return item\n</code></pre>"},{"location":"BEST_PRACTICES/#request-validation","title":"Request Validation","text":"<ul> <li>Use Pydantic models for request/response validation</li> <li>Create different models for different operations (Create, Update, Response)</li> <li>Use validators for complex validations</li> <li>Include detailed error messages</li> <li>Apply appropriate constraints (min/max lengths, regex patterns)</li> </ul> <pre><code>class ItemCreate(BaseModel):\n    name: str = Field(..., min_length=1, max_length=100)\n    description: Optional[str] = Field(None, max_length=1000)\n    price: float = Field(..., gt=0)\n</code></pre>"},{"location":"BEST_PRACTICES/#response-handling","title":"Response Handling","text":"<ul> <li>Define response models explicitly</li> <li>Include appropriate HTTP status codes</li> <li>Use meaningful error messages</li> <li>Structure responses consistently</li> <li>Implement pagination metadata for collections</li> <li>Don't expose sensitive information</li> </ul>"},{"location":"BEST_PRACTICES/#dependency-injection","title":"Dependency Injection","text":"<ul> <li>Use FastAPI's dependency system extensively</li> <li>Create reusable dependencies</li> <li>Chain dependencies when needed</li> <li>Cache dependencies for performance</li> <li>Use dependency overrides for testing</li> </ul> <pre><code>def get_repository(repo_class, model_class):\n    def _get_repo(uow: UnitOfWork = Depends(get_unit_of_work)):\n        return repo_class(model_class, uow.session)\n    return _get_repo\n</code></pre>"},{"location":"BEST_PRACTICES/#asyncawait","title":"Async/Await","text":"<ul> <li>Use async/await for I/O bound operations</li> <li>Don't mix sync and async code</li> <li>Use proper async libraries (asyncpg, httpx)</li> <li>Be aware of the event loop</li> <li>Use background tasks for long-running operations</li> </ul> <pre><code>async def get_items(skip: int = 0, limit: int = 100):\n    async with async_session_factory() as session:\n        query = select(Item).offset(skip).limit(limit)\n        result = await session.execute(query)\n        return result.scalars().all()\n</code></pre>"},{"location":"BEST_PRACTICES/#documentation","title":"Documentation","text":"<ul> <li>Document all public APIs with docstrings</li> <li>Include parameter descriptions</li> <li>Document return values and exceptions</li> <li>Keep API documentation up-to-date</li> <li>Use FastAPI's automatic documentation (Swagger/ReDoc)</li> </ul> <pre><code>@router.post(\"\", response_model=ItemSchema, status_code=201)\nasync def create_item(item: ItemCreate):\n    \"\"\"\n    Create a new item.\n\n    Args:\n        item: The item data to create\n\n    Returns:\n        The created item\n\n    Raises:\n        HTTPException: If an item with the same name already exists\n    \"\"\"\n    # Implementation...\n</code></pre>"},{"location":"BEST_PRACTICES/#database-best-practices","title":"Database Best Practices","text":""},{"location":"BEST_PRACTICES/#sqlalchemy-usage","title":"SQLAlchemy Usage","text":"<ul> <li>Use SQLAlchemy 2.0 style (select instead of query)</li> <li>Define explicit relationships between models</li> <li>Use appropriate column types and constraints</li> <li>Define indexes for frequently queried columns</li> <li>Use migrations for schema changes</li> <li>Implement soft delete where appropriate</li> </ul> <pre><code>class Item(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(100), index=True)\n    price: Mapped[float]\n    is_active: Mapped[bool] = mapped_column(default=True)\n</code></pre>"},{"location":"BEST_PRACTICES/#database-access","title":"Database Access","text":"<ul> <li>Use the repository pattern to abstract database access</li> <li>Implement transactions with Unit of Work</li> <li>Use async database access for better performance</li> <li>Apply proper pagination for large datasets</li> <li>Use database connections efficiently</li> <li>Implement database connection pooling</li> </ul> <pre><code>class BaseRepository(Generic[ModelType]):\n    def __init__(self, model: Type[ModelType], session: AsyncSession):\n        self.model = model\n        self.session = session\n\n    async def get(self, id: int) -&gt; Optional[ModelType]:\n        query = select(self.model).where(self.model.id == id)\n        result = await self.session.execute(query)\n        return result.scalars().first()\n</code></pre>"},{"location":"BEST_PRACTICES/#database-migrations","title":"Database Migrations","text":"<ul> <li>Use Alembic for database migrations</li> <li>Create migrations for schema changes</li> <li>Test migrations before applying to production</li> <li>Include both upgrade and downgrade paths</li> <li>Document database changes</li> </ul>"},{"location":"BEST_PRACTICES/#testing","title":"Testing","text":""},{"location":"BEST_PRACTICES/#test-organization","title":"Test Organization","text":"<ul> <li>Separate unit tests from integration tests</li> <li>Use a consistent naming convention</li> <li>Structure tests to match application structure</li> <li>Create fixtures for common test scenarios</li> <li>Implement test helpers for repetitive tasks</li> </ul>"},{"location":"BEST_PRACTICES/#testing-techniques","title":"Testing Techniques","text":"<ul> <li>Test all layers independently</li> <li>Mock external dependencies</li> <li>Use parametrized tests for edge cases</li> <li>Test error conditions</li> <li>Implement test database setup/teardown</li> <li>Use proper assertions</li> </ul> <pre><code>@pytest.mark.asyncio\nasync def test_create_item(mock_uow, mock_repository):\n    # Arrange\n    with patch(\"src.services.item_service.ItemRepository\", return_value=mock_repository):\n        service = ItemService(mock_uow)\n        item_in = ItemCreate(name=\"Test Item\", price=10.0)\n\n        # Act\n        result = await service.create(item_in)\n\n        # Assert\n        assert result is not None\n        assert result.name == \"Test Item\"\n        mock_repository.create.assert_called_once_with(item_in.model_dump())\n</code></pre>"},{"location":"BEST_PRACTICES/#test-coverage","title":"Test Coverage","text":"<ul> <li>Aim for high test coverage (&gt;80%)</li> <li>Focus on critical paths</li> <li>Include edge cases and error handling</li> <li>Don't sacrifice test quality for coverage</li> <li>Use coverage reports to identify untested code</li> </ul>"},{"location":"BEST_PRACTICES/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Use HTTPS in production</li> <li>Implement proper authentication/authorization</li> <li>Validate all user inputs</li> <li>Protect against common web vulnerabilities (XSS, CSRF, SQL injection)</li> <li>Store sensitive information securely</li> <li>Use environment variables for configuration</li> <li>Regularly update dependencies</li> <li>Implement rate limiting for APIs</li> <li>Use proper logging (without sensitive data)</li> </ul>"},{"location":"BEST_PRACTICES/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Use async/await for I/O bound operations</li> <li>Implement caching where appropriate</li> <li>Optimize database queries (indexes, query optimization)</li> <li>Use connection pooling</li> <li>Paginate large data sets</li> <li>Minimize database round trips</li> <li>Profile and optimize bottlenecks</li> <li>Consider using background tasks for long-running operations</li> </ul>"},{"location":"BEST_PRACTICES/#error-handling","title":"Error Handling","text":"<ul> <li>Implement global exception handlers</li> <li>Provide helpful error messages</li> <li>Log errors appropriately</li> <li>Return appropriate status codes</li> <li>Don't expose sensitive information in errors</li> <li>Handle both expected and unexpected errors</li> <li>Use custom exception classes for domain errors</li> </ul> <pre><code>@app.exception_handler(CustomException)\nasync def custom_exception_handler(request: Request, exc: CustomException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\"detail\": exc.detail},\n    )\n</code></pre>"},{"location":"BEST_PRACTICES/#configuration-management","title":"Configuration Management","text":"<ul> <li>Use environment variables for configuration</li> <li>Implement different configurations for different environments</li> <li>Use Pydantic for configuration validation</li> <li>Don't hardcode sensitive information</li> <li>Provide sensible defaults</li> <li>Document configuration options</li> </ul> <pre><code>class Settings(BaseSettings):\n    DATABASE_URI: PostgresDsn\n    API_KEY: SecretStr\n    DEBUG: bool = False\n\n    class Config:\n        env_file = \".env\"\n        env_file_encoding = \"utf-8\"\n</code></pre>"},{"location":"BEST_PRACTICES/#logging","title":"Logging","text":"<ul> <li>Implement structured logging</li> <li>Use appropriate log levels</li> <li>Include contextual information</li> <li>Avoid logging sensitive data</li> <li>Configure different handlers for different environments</li> <li>Make logs searchable and filterable</li> <li>Use correlation IDs for request tracking</li> </ul>"},{"location":"BEST_PRACTICES/#conclusion","title":"Conclusion","text":"<p>Following these best practices will help create robust, maintainable, and efficient Python backends. These guidelines should be adapted to specific project requirements and team preferences. </p>"},{"location":"BUILD/","title":"Kasal Build System","text":"<p>This document explains how to use the build system to create a distributable wheel package that includes both the backend and frontend components.</p>"},{"location":"BUILD/#overview","title":"Overview","text":"<p>The build script (<code>build.py</code>) packages the entire application into a Python wheel distribution that can be easily installed using pip. The wheel includes:</p> <ol> <li>The backend Python code</li> <li>The built frontend React static files</li> <li>Configuration files and migrations</li> </ol>"},{"location":"BUILD/#prerequisites","title":"Prerequisites","text":"<p>Before running the build script, ensure you have the following installed:</p> <ul> <li>Python 3.9+</li> <li>Node.js and npm</li> <li>wheel package (<code>pip install wheel</code>)</li> </ul>"},{"location":"BUILD/#folder-structure","title":"Folder Structure","text":"<p>The build process will create the following folder structure:</p> <pre><code>kasal/\n\u251c\u2500\u2500 build/            # Build artifacts\n\u2502   \u251c\u2500\u2500 logs/         # Build logs\n\u2502   \u251c\u2500\u2500 package/      # Temporary package files\n\u2502   \u2514\u2500\u2500 temp/         # Temporary files during build\n\u2514\u2500\u2500 dist/             # Final wheel package\n</code></pre>"},{"location":"BUILD/#building-the-project","title":"Building the Project","text":"<p>To build the project, run:</p> <pre><code>python build.py\n</code></pre> <p>This will:</p> <ol> <li>Clean any previous build artifacts</li> <li>Build the frontend React application</li> <li>Package the backend Python code</li> <li>Create the necessary package files</li> <li>Build the wheel package</li> <li>Copy the wheel to the <code>dist</code> directory</li> </ol> <p>The build process generates detailed logs in the <code>build/logs</code> directory.</p>"},{"location":"BUILD/#installing-the-wheel","title":"Installing the Wheel","text":"<p>After building, you can install the wheel package using pip:</p> <pre><code>pip install dist/kasal-0.1.0-py3-none-any.whl\n</code></pre>"},{"location":"BUILD/#running-the-application","title":"Running the Application","text":"<p>Once installed, you can run the application using:</p> <pre><code># Run directly as a module\npython -m kasal.backend.src.main\n\n# Or use the installed entry point\nkasal\n</code></pre>"},{"location":"BUILD/#development-workflow","title":"Development Workflow","text":"<p>When developing:</p> <ol> <li>Make changes to the frontend or backend code</li> <li>Run <code>python build.py</code> to create a new wheel</li> <li>Install the updated wheel</li> <li>Test the application</li> </ol>"},{"location":"BUILD/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues during the build process:</p> <ol> <li>Check the build logs in <code>build/logs/</code></li> <li>Ensure all prerequisites are installed</li> <li>Verify that both frontend and backend can be built independently</li> </ol> <p>For more detailed information, look at the error messages in the build logs. </p>"},{"location":"CREWAI_ENGINE/","title":"CrewAI Engine Architecture","text":""},{"location":"CREWAI_ENGINE/#overview","title":"Overview","text":"<p>The CrewAI Engine is a modular service that integrates the CrewAI framework into the application. It orchestrates autonomous AI agents that collaborate to perform complex tasks through a well-defined workflow. The engine is designed with a clean separation of concerns, allowing for maintainability, extensibility, and testing.</p>"},{"location":"CREWAI_ENGINE/#core-architecture","title":"Core Architecture","text":"<p>The engine follows a layered architecture pattern:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            API Layer                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Service Layer               \u2502\n\u2502    (CrewAIEngineService)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Specialized Modules           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502Configuration\u2502  \u2502Crew Preparation\u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Tracing   \u2502  \u2502   Execution    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         CrewAI Framework              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"CREWAI_ENGINE/#key-components","title":"Key Components","text":""},{"location":"CREWAI_ENGINE/#crewaiengineservice","title":"CrewAIEngineService","text":"<p>The main entry point and orchestrator that: - Initializes the engine - Manages execution lifecycles - Coordinates between components - Exposes public APIs for execution management</p> <p>Source: <code>backend/src/engines/crewai/crewai_engine_service.py</code></p>"},{"location":"CREWAI_ENGINE/#configuration-adapter","title":"Configuration Adapter","text":"<p>Handles transformation of configuration data between formats: - Converts API/frontend config to engine format  - Normalizes configs for consistent processing - Extracts YAML configuration for agents and tasks - Applies default values when needed</p> <p>Source: <code>backend/src/engines/crewai/config_adapter.py</code></p>"},{"location":"CREWAI_ENGINE/#crew-preparation","title":"Crew Preparation","text":"<p>Responsible for creating all components needed for execution: - Prepares agents with roles, goals, and tools - Configures tasks with proper descriptions and assignments - Creates output directories for execution artifacts - Assembles the final Crew with proper configuration</p> <p>Source: <code>backend/src/engines/crewai/crew_preparation.py</code></p>"},{"location":"CREWAI_ENGINE/#execution-runner","title":"Execution Runner","text":"<p>Manages the actual execution of the Crew: - Runs the crew asynchronously to prevent blocking - Handles completion, cancellation, and failure cases - Updates execution status with retry logic - Cleans up resources after execution</p> <p>Source: <code>backend/src/engines/crewai/execution_runner.py</code></p>"},{"location":"CREWAI_ENGINE/#trace-management","title":"Trace Management","text":"<p>Collects and processes trace data for monitoring and debugging: - Maintains background tasks for processing trace data - Batches traces for efficient database operations - Manages start/stop of trace processing - Coordinates with logging services</p> <p>Source: <code>backend/src/engines/crewai/trace_management.py</code></p>"},{"location":"CREWAI_ENGINE/#helper-modules","title":"Helper Modules","text":"<p>Specialized functions for specific aspects of agent/task management: - <code>tool_helpers.py</code>: Tool preparation and assignment - <code>agent_helpers.py</code>: Agent creation and configuration - <code>task_helpers.py</code>: Task creation and conditional logic - <code>conversion_helpers.py</code>: YAML parsing and configuration conversion</p>"},{"location":"CREWAI_ENGINE/#tool-registry","title":"Tool Registry","text":"<p>Central repository for available tools: - Discovers and registers available CrewAI tools - Manages custom tool implementations - Provides tools to agents on demand - Handles API key integration</p> <p>Source: <code>backend/src/engines/crewai/tools/registry.py</code></p>"},{"location":"CREWAI_ENGINE/#execution-flow","title":"Execution Flow","text":"<ol> <li>Initialization</li> <li>Engine is initialized at application startup</li> <li>Trace writer tasks are started</li> <li> <p>Tool registry loads available tools and configurations</p> </li> <li> <p>Configuration</p> </li> <li>Frontend submits execution configuration</li> <li>Configuration is normalized through the adapter</li> <li> <p>Planning parameters are properly configured when enabled</p> </li> <li> <p>Preparation</p> </li> <li>Tools are prepared for the execution</li> <li>Agents are created with appropriate roles and tools</li> <li>Tasks are created and assigned to agents</li> <li> <p>Output directory is set up</p> </li> <li> <p>Execution</p> </li> <li>Crew is created with configured parameters</li> <li>Execution task is started asynchronously</li> <li> <p>Execution status is updated to \"RUNNING\"</p> </li> <li> <p>Monitoring</p> </li> <li>Agent traces are collected during execution</li> <li>Traces are processed and stored in the database</li> <li> <p>Execution logs are streamed for real-time monitoring</p> </li> <li> <p>Completion</p> </li> <li>Execution completes successfully, fails, or is cancelled</li> <li>Final status is updated with appropriate message</li> <li>Results are stored in the database</li> <li>Resources are cleaned up</li> </ol>"},{"location":"CREWAI_ENGINE/#special-features","title":"Special Features","text":""},{"location":"CREWAI_ENGINE/#planning-support","title":"Planning Support","text":"<p>The engine supports CrewAI's planning feature, which enables: - Automatic planning of task execution steps - Addition of planning information to task descriptions - Improved coordination between agents - Configuration of planning-specific LLM</p> <p>To enable planning, set the <code>planning</code> parameter to <code>true</code> in the execution configuration. You can also specify a different LLM for planning using the <code>planning_llm</code> parameter.</p>"},{"location":"CREWAI_ENGINE/#async-trace-processing","title":"Async Trace Processing","text":"<p>The engine uses an asynchronous trace processing mechanism to: - Prevent blocking during trace collection - Batch process traces for efficiency - Ensure trace data is saved even if the main execution fails - Provide real-time visibility into agent operations</p>"},{"location":"CREWAI_ENGINE/#tool-management","title":"Tool Management","text":"<p>The tool registry provides a flexible approach to tools: - Auto-discovery of built-in CrewAI tools - Registration of custom tools - API key management - Context-sensitive tool provisioning</p>"},{"location":"CREWAI_ENGINE/#error-handling","title":"Error Handling","text":"<p>The engine implements robust error handling: - Exponential backoff for transient failures - Status update retries with configurable limits - Detailed error logging - Exception isolation to prevent cascading failures</p>"},{"location":"CREWAI_ENGINE/#database-interaction","title":"Database Interaction","text":"<p>The engine follows the repository pattern for database access: - No direct database access from service layer - All database operations go through repositories - Status updates use dedicated services - Trace data is written asynchronously to avoid blocking</p>"},{"location":"CREWAI_ENGINE/#logging-and-debugging","title":"Logging and Debugging","text":"<p>Comprehensive logging is implemented through: - A centralized logging system - Component-specific log prefixes - Structured logs with execution context - Debug-level detail when needed - Execution traces for fine-grained visibility</p>"},{"location":"CREWAI_ENGINE/#integration-points","title":"Integration Points","text":""},{"location":"CREWAI_ENGINE/#frontend-integration","title":"Frontend Integration","text":"<p>The engine integrates with the frontend through: - The execution API endpoints - WebSocket connections for real-time updates - Status queries for execution monitoring - Execution trace retrieval for detailed inspection</p>"},{"location":"CREWAI_ENGINE/#llm-integration","title":"LLM Integration","text":"<p>The engine supports various LLM providers: - OpenAI (default) - Anthropic - Local models - Custom LLM configurations - Model-specific parameters</p>"},{"location":"CREWAI_ENGINE/#configuration-options","title":"Configuration Options","text":"<p>Important configuration options include:</p> Parameter Description Default <code>planning</code> Enable/disable planning feature <code>false</code> <code>planning_llm</code> LLM model to use for planning Same as main LLM <code>process_type</code> Process type (sequential/hierarchical) <code>sequential</code> <code>verbose</code> Enable verbose logging <code>true</code> <code>memory</code> Enable agent memory <code>true</code> <code>max_rpm</code> Maximum requests per minute <code>10</code>"},{"location":"CREWAI_ENGINE/#repository-structure","title":"Repository Structure","text":"<pre><code>backend/src/engines/crewai/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 crewai_engine_service.py    # Main engine service\n\u251c\u2500\u2500 config_adapter.py           # Configuration adapter\n\u251c\u2500\u2500 crew_preparation.py         # Crew preparation module\n\u251c\u2500\u2500 execution_runner.py         # Execution runner module\n\u251c\u2500\u2500 trace_management.py         # Trace management module\n\u251c\u2500\u2500 callbacks/                  # Event callbacks\n\u251c\u2500\u2500 crew_logger.py              # CrewAI logger\n\u251c\u2500\u2500 helpers/                    # Helper modules\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent_helpers.py\n\u2502   \u251c\u2500\u2500 task_helpers.py\n\u2502   \u251c\u2500\u2500 tool_helpers.py\n\u2502   \u2514\u2500\u2500 conversion_helpers.py\n\u2514\u2500\u2500 tools/                      # Tool implementations\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 registry.py\n</code></pre>"},{"location":"CREWAI_ENGINE/#best-practices","title":"Best Practices","text":"<p>When working with the CrewAI Engine:</p> <ol> <li>Configuration Handling</li> <li>Always use the configuration adapter for normalization</li> <li>Provide sensible defaults for missing parameters</li> <li> <p>Validate configurations before execution</p> </li> <li> <p>Error Management</p> </li> <li>Implement proper error handling at all levels</li> <li>Use the retry mechanism for transient failures</li> <li> <p>Log errors with appropriate context</p> </li> <li> <p>Resource Cleanup</p> </li> <li>Ensure all resources are properly cleaned up</li> <li>Cancel background tasks when no longer needed</li> <li> <p>Close database connections and file handles</p> </li> <li> <p>Asynchronous Operations</p> </li> <li>Use asynchronous code for I/O-bound operations</li> <li>Avoid blocking the event loop</li> <li> <p>Implement proper cancellation handling</p> </li> <li> <p>Database Access</p> </li> <li>Always use repositories for database access</li> <li>Never access the database directly from services</li> <li>Use transactions for related operations</li> </ol>"},{"location":"CREWAI_ENGINE/#example-usage","title":"Example Usage","text":"<pre><code># Initialize the engine\nengine = await EngineFactory.get_engine(\n    engine_type=\"crewai\",\n    db=db,\n    initialize=True,\n    llm_provider=\"openai\",\n    model=\"gpt-4o\"\n)\n\n# Run an execution\nexecution_id = str(uuid4())\nresult = await engine.run_execution(\n    execution_id=execution_id,\n    execution_config=config\n)\n\n# Check status\nstatus = await engine.get_execution_status(execution_id)\n\n# Cancel execution if needed\nsuccess = await engine.cancel_execution(execution_id)\n</code></pre>"},{"location":"DATABASE_MIGRATIONS/","title":"Database Migrations Guide","text":""},{"location":"DATABASE_MIGRATIONS/#overview","title":"Overview","text":"<p>This guide covers how to work with database migrations in the Kasal project. We use Alembic, a database migration tool for SQLAlchemy, to manage schema changes to our database.</p> <p>Migrations are essential for: - Tracking database schema changes in version control - Applying schema changes consistently across environments - Rolling back database changes if needed - Collaborating on database schema changes across the team</p>"},{"location":"DATABASE_MIGRATIONS/#migration-structure","title":"Migration Structure","text":"<p>In our project, migrations are stored in the <code>backend/migrations</code> directory:</p> <pre><code>backend/\n\u251c\u2500\u2500 migrations/\n\u2502   \u251c\u2500\u2500 versions/       # Contains individual migration scripts\n\u2502   \u251c\u2500\u2500 env.py          # Alembic environment configuration\n\u2502   \u2514\u2500\u2500 script.py.mako  # Template for migration scripts\n\u2514\u2500\u2500 alembic.ini         # Alembic configuration file\n</code></pre>"},{"location":"DATABASE_MIGRATIONS/#creating-migrations","title":"Creating Migrations","text":""},{"location":"DATABASE_MIGRATIONS/#automatic-migration-generation","title":"Automatic Migration Generation","text":"<p>For most schema changes, you can use Alembic's automatic migration generation. This works by comparing the state of your models with the state of the database, and generating the necessary SQL to bring the database in line with your models.</p> <ol> <li> <p>First, make changes to your SQLAlchemy models in the <code>src/models/</code> directory:    <pre><code># Example: Adding a new column to an existing model\nclass Agent(Base):\n    # Existing fields...\n\n    # New field\n    result_as_answer = Column(Boolean, default=False)\n</code></pre></p> </li> <li> <p>Make sure your model is imported in <code>src/db/all_models.py</code> so Alembic can detect it.</p> </li> <li> <p>Generate a migration script:    <pre><code>cd backend\nalembic revision --autogenerate -m \"Add result_as_answer to Agent model\"\n</code></pre></p> </li> <li> <p>Review the generated migration script in <code>migrations/versions/</code> to ensure it will make the changes you expect. It's important to review the migration before applying it to catch any potential issues.</p> </li> </ol>"},{"location":"DATABASE_MIGRATIONS/#manual-migration-creation","title":"Manual Migration Creation","text":"<p>Sometimes automatic migration generation might not capture all the changes correctly, or you might need more complex migrations. In these cases, you can create a manual migration:</p> <pre><code>cd backend\nalembic revision -m \"Custom migration description\"\n</code></pre> <p>This will create an empty migration script that you can fill in with custom SQL commands using Alembic's operations API.</p>"},{"location":"DATABASE_MIGRATIONS/#applying-migrations","title":"Applying Migrations","text":"<p>To apply migrations and update your database schema:</p> <pre><code>cd backend\nalembic upgrade head\n</code></pre> <p>This will apply all pending migrations to bring your database to the latest schema version.</p>"},{"location":"DATABASE_MIGRATIONS/#specific-migration-targets","title":"Specific Migration Targets","text":"<p>You can also:</p> <ul> <li> <p>Upgrade to a specific migration:   <pre><code>alembic upgrade &lt;revision_id&gt;\n</code></pre></p> </li> <li> <p>Downgrade to a previous migration:   <pre><code>alembic downgrade &lt;revision_id&gt;\n</code></pre></p> </li> <li> <p>Upgrade or downgrade relative to current version:   <pre><code>alembic upgrade +2   # Apply the next 2 migrations\nalembic downgrade -1  # Revert the most recent migration\n</code></pre></p> </li> </ul>"},{"location":"DATABASE_MIGRATIONS/#real-world-example","title":"Real-World Example","text":"<p>Here's a complete example of adding a new field to an existing model:</p> <ol> <li> <p>Add the field to the model in <code>src/models/agent.py</code>:    <pre><code>class Agent(Base):\n    # Existing fields...\n    result_as_answer = Column(Boolean, default=False)\n</code></pre></p> </li> <li> <p>Generate a migration:    <pre><code>cd backend\nalembic revision --autogenerate -m \"Add result_as_answer to Agent model\"\n</code></pre></p> </li> <li> <p>Review the generated migration file in <code>migrations/versions/</code>:    <pre><code>def upgrade() -&gt; None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.add_column('agents', sa.Column('result_as_answer', sa.Boolean(), nullable=True))\n    # ### end Alembic commands ###\n\ndef downgrade() -&gt; None:\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_column('agents', 'result_as_answer')\n    # ### end Alembic commands ###\n</code></pre></p> </li> <li> <p>Apply the migration:    <pre><code>alembic upgrade head\n</code></pre></p> </li> <li> <p>Verify the change in your database:    <pre><code># Using psql\npsql -U your_user -d your_database -c \"\\d agents\"\n</code></pre></p> </li> </ol>"},{"location":"DATABASE_MIGRATIONS/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always review generated migrations before applying them. Auto-generation is not perfect and may miss certain details or include unwanted changes.</p> </li> <li> <p>Keep migrations small and focused on specific changes to make them easier to review and revert if necessary.</p> </li> <li> <p>Test migrations in a development environment before applying them to production.</p> </li> <li> <p>Include meaningful descriptions in your migration names to make it clear what they do.</p> </li> <li> <p>Don't modify existing migration files that have been applied to any environment. Create new migrations instead.</p> </li> <li> <p>Be careful with data migrations that modify existing data. These should be thoroughly tested.</p> </li> <li> <p>Include default values for new non-nullable columns, or add them as nullable first, then fill them with data, and finally alter them to be non-nullable in a subsequent migration.</p> </li> <li> <p>Create migrations for each model change rather than making multiple model changes and then creating a single migration.</p> </li> </ol>"},{"location":"DATABASE_MIGRATIONS/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DATABASE_MIGRATIONS/#common-issues","title":"Common Issues","text":"<ol> <li>Migration fails with \"Target database is not up to date\"</li> <li>Run <code>alembic current</code> to see the current revision</li> <li>Run <code>alembic history</code> to see the migration history</li> <li> <p>You may need to manually fix the alembic_version table in your database</p> </li> <li> <p>Auto-generation is not detecting changes</p> </li> <li>Ensure your models are imported in <code>src/db/all_models.py</code></li> <li>Check that the model is properly configured with <code>__tablename__</code></li> <li> <p>Verify that the Base class is the same one imported in the Alembic environment</p> </li> <li> <p>\"Can't locate revision identified by...\"</p> </li> <li>Ensure all migration files are properly committed to version control</li> <li> <p>Check that you have the latest version of the code with all migrations</p> </li> <li> <p>Migration directory doesn't exist</p> </li> <li>Create the directory: <code>mkdir -p migrations/versions</code></li> </ol>"},{"location":"DATABASE_MIGRATIONS/#additional-resources","title":"Additional Resources","text":"<ul> <li>Alembic Documentation</li> <li>SQLAlchemy Documentation </li> </ul>"},{"location":"DATABASE_SEEDING/","title":"Database Seeding","text":"<p>This document explains the database seeding functionality in the application, which allows for automatic population of predefined data into database tables.</p>"},{"location":"DATABASE_SEEDING/#overview","title":"Overview","text":"<p>Database seeding is the process of initializing a database with a set of predefined data. This is particularly useful for:</p> <ul> <li>Populating lookup tables with standard values</li> <li>Setting up development and testing environments</li> <li>Ensuring required reference data is available</li> <li>Initializing the application with demo data</li> </ul> <p>The seeding system is designed to be:</p> <ul> <li>Idempotent: Can be run multiple times without creating duplicates</li> <li>Modular: Each type of data has its own seeder module</li> <li>Configurable: Can be enabled/disabled through environment variables</li> <li>Flexible: Supports both sync and async execution patterns</li> <li>Resilient: Continues seeding even if one seeder fails</li> </ul>"},{"location":"DATABASE_SEEDING/#available-seeders","title":"Available Seeders","text":"<p>The application includes the following seeders:</p>"},{"location":"DATABASE_SEEDING/#1-tools-seeder","title":"1. Tools Seeder","text":"<p>Populates the <code>tools</code> table with default tool configurations for AI agents.</p> <ul> <li>Module: <code>src/seeds/tools.py</code></li> <li>Command: <code>python -m src.seeds.seed_runner --tools</code></li> </ul>"},{"location":"DATABASE_SEEDING/#2-schemas-seeder","title":"2. Schemas Seeder","text":"<p>Populates the <code>schemas</code> table with predefined JSON schemas.</p> <ul> <li>Module: <code>src/seeds/schemas.py</code></li> <li>Command: <code>python -m src.seeds.seed_runner --schemas</code></li> </ul>"},{"location":"DATABASE_SEEDING/#3-prompt-templates-seeder","title":"3. Prompt Templates Seeder","text":"<p>Populates the <code>prompt_templates</code> table with default prompt templates for various generation tasks.</p> <ul> <li>Module: <code>src/seeds/prompt_templates.py</code></li> <li>Command: <code>python -m src.seeds.seed_runner --prompt_templates</code></li> </ul>"},{"location":"DATABASE_SEEDING/#4-model-configurations-seeder","title":"4. Model Configurations Seeder","text":"<p>Populates the <code>model_configs</code> table with configurations for various LLM models from different providers.</p> <ul> <li>Module: <code>src/seeds/model_configs.py</code></li> <li>Command: <code>python -m src.seeds.seed_runner --model_configs</code></li> </ul>"},{"location":"DATABASE_SEEDING/#running-seeders","title":"Running Seeders","text":"<p>There are multiple ways to run the seeders:</p>"},{"location":"DATABASE_SEEDING/#using-the-seed-runner","title":"Using the Seed Runner","text":"<p>The <code>seed_runner</code> module provides a command-line interface for running seeders:</p> <pre><code># Run all seeders\npython -m src.seeds.seed_runner --all\n\n# Run a specific seeder\npython -m src.seeds.seed_runner --tools\npython -m src.seeds.seed_runner --schemas\npython -m src.seeds.seed_runner --prompt_templates\npython -m src.seeds.seed_runner --model_configs\n\n# Run multiple specific seeders\npython -m src.seeds.seed_runner --tools --schemas\n\n# Run with debug mode enabled\npython -m src.seeds.seed_runner --all --debug\n</code></pre>"},{"location":"DATABASE_SEEDING/#automatic-seeding-on-application-startup","title":"Automatic Seeding on Application Startup","text":"<p>The application automatically runs all seeders during the application startup process in the FastAPI lifespan context manager. This ensures that all required data is available before the application starts serving requests.</p> <p>Seeding is controlled by the <code>AUTO_SEED_DATABASE</code> setting in <code>src/config/settings.py</code>:</p> <pre><code># Add the following setting to control database seeding\nAUTO_SEED_DATABASE: bool = True\n</code></pre> <p>You can override this setting using environment variables:</p> <pre><code>AUTO_SEED_DATABASE=true   # Enable automatic seeding\nAUTO_SEED_DATABASE=false  # Disable automatic seeding\n</code></pre>"},{"location":"DATABASE_SEEDING/#seeding-process-flow","title":"Seeding Process Flow","text":"<ol> <li>When the application starts, the lifespan context manager initializes the database</li> <li>After successful database initialization, it checks if seeding is enabled</li> <li>If enabled, it imports the seed runner and executes all registered seeders</li> <li>Each seeder runs independently - if one fails, others will still be executed</li> <li>Detailed logs are generated throughout the process</li> </ol>"},{"location":"DATABASE_SEEDING/#debugging-seeding","title":"Debugging Seeding","text":"<p>To enable detailed debug logging for the seeding process, set the <code>SEED_DEBUG</code> environment variable:</p> <pre><code>SEED_DEBUG=true  # Enable detailed seeding debug logs\n</code></pre> <p>This will output comprehensive information about: - Which seeders are being loaded - When each seeder starts and completes - Any errors that occur during the seeding process</p> <p>You can also enable debug mode in the application code:</p> <pre><code># In main.py\nimport os\nos.environ[\"SEED_DEBUG\"] = \"True\"\n</code></pre>"},{"location":"DATABASE_SEEDING/#how-seeders-work","title":"How Seeders Work","text":"<p>Each seeder follows a consistent pattern:</p> <ol> <li>Define the default data to be seeded</li> <li>Provide both async and sync implementations</li> <li>Check for existing records to avoid duplicates</li> <li>Insert new records and update existing ones as needed</li> <li>Log the results of the seeding operation</li> </ol>"},{"location":"DATABASE_SEEDING/#example-seeder-structure","title":"Example Seeder Structure","text":"<pre><code>async def seed_async():\n    \"\"\"Seed data into the database using async session.\"\"\"\n    async with async_session_factory() as session:\n        # Check existing records\n        result = await session.execute(select(Model.key))\n        existing_keys = {row[0] for row in result.scalars().all()}\n\n        # Insert/update records\n        items_added = 0\n        items_updated = 0\n\n        for item_key, item_data in DEFAULT_ITEMS.items():\n            if item_key not in existing_keys:\n                # Add new item\n                session.add(Model(**item_data))\n                items_added += 1\n            else:\n                # Update existing item\n                result = await session.execute(\n                    select(Model).filter(Model.key == item_key)\n                )\n                existing_item = result.scalars().first()\n                # Update fields...\n                items_updated += 1\n\n        # Commit changes\n        if items_added &gt; 0 or items_updated &gt; 0:\n            await session.commit()\n\ndef seed_sync():\n    \"\"\"Sync version of the seeder\"\"\"\n    # Similar implementation using synchronous session\n\n# Main entry point for the seeder\nasync def seed():\n    \"\"\"Main entry point for seeding.\"\"\"\n    try:\n        await seed_async()\n        logger.info(\"Seeding completed successfully\")\n    except Exception as e:\n        logger.error(f\"Error in seeding: {str(e)}\")\n        import traceback\n        logger.error(f\"Traceback: {traceback.format_exc()}\")\n        # You can choose to raise the exception or not depending on your strategy\n\n## Creating a New Seeder\n\nTo create a new seeder for additional data:\n\n1. Create a new file in the `src/seeds/` directory\n2. Implement the `seed_async()` and `seed_sync()` functions\n3. Provide a main `seed()` function that calls the appropriate implementation\n4. Update the `seed_runner.py` file to include your new seeder\n\nExample of adding a new seeder to `seed_runner.py`:\n\n```python\n# Add your import\nfrom src.seeds import tools, schemas, prompt_templates, model_configs, your_new_seeder\n\n# Add to the SEEDERS dictionary\ntry:\n    SEEDERS[\"your_new_seeder_name\"] = your_new_seeder.seed\n    debug_log(\"Added your_new_seeder.seed to SEEDERS\")\nexcept (NameError, AttributeError) as e:\n    logger.error(f\"Error adding your_new_seeder: {e}\")\n</code></pre>"},{"location":"DATABASE_SEEDING/#best-practices","title":"Best Practices","text":"<p>When using or extending the seeding functionality:</p> <ol> <li>Maintain idempotency: Always check for existing records before inserting</li> <li>Use appropriate timestamps: Set created_at and updated_at fields with UTC time</li> <li>Handle errors gracefully: Use try/except blocks and log errors</li> <li>Keep seed data manageable: Split large datasets into logical modules</li> <li>Document seed data: Include comments explaining the purpose of the seeded data</li> <li>Test seeders: Ensure they run correctly in different environments</li> <li>Add proper logging: Use logging to track the seeding process</li> </ol>"},{"location":"DATABASE_SEEDING/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues with the seeding process:</p> <ol> <li>Enable debug mode: Set <code>SEED_DEBUG=true</code> to get more detailed logs</li> <li>Check database connectivity: Ensure the database is accessible</li> <li>Verify model definitions: Make sure model definitions match the data being seeded</li> <li>Inspect logs: Check system.log and application logs for specific error messages</li> <li>Run seeders manually: Try running the seeders manually to isolate issues</li> </ol>"},{"location":"DATABASE_SEEDING/#environment-specific-considerations","title":"Environment-Specific Considerations","text":"<ul> <li>Development: Enable auto-seeding for convenience</li> <li>Testing: Use seeders to create test data in a controlled manner</li> <li>Production: Use seeders with caution, typically only for initial setup or specific reference data</li> <li>CI/CD: Consider running seeders as part of your deployment pipeline </li> </ul>"},{"location":"DOCUMENTATION/","title":"Modern Python Backend Documentation","text":"<p>This document serves as an index to all documentation files in this project, providing an overview of the modern Python backend architecture and how each component fits together.</p>"},{"location":"DOCUMENTATION/#documentation-overview","title":"Documentation Overview","text":"Document Description README.md Project overview, features, and setup instructions ARCHITECTURE.md Detailed explanation of architectural patterns and layers BEST_PRACTICES.md Coding guidelines and best practices MODELS.md Documentation for SQLAlchemy database models SCHEMAS.md Documentation for Pydantic validation schemas SCHEMAS_STRUCTURE.md Detailed guide to schemas folder structure and organization LOGGING.md Comprehensive guide to the logging system GETTING_STARTED.md Step-by-step guide for developers REPOSITORY_PATTERN.md Detailed explanation of the Repository Pattern implementation"},{"location":"DOCUMENTATION/#architecture-layers","title":"Architecture Layers","text":"<p>Our backend follows a clean, layered architecture with clear separation of concerns:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    API Layer    \u2502 FastAPI Routes\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Service Layer  \u2502 Business Logic\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Repository Layer\u2502 Data Access\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Database Layer  \u2502 Models &amp; Connection\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Each layer has specific responsibilities and communicates only with adjacent layers.</p>"},{"location":"DOCUMENTATION/#component-relationships","title":"Component Relationships","text":""},{"location":"DOCUMENTATION/#how-everything-fits-together","title":"How Everything Fits Together","text":"<ol> <li>API Layer (FastAPI Routes)</li> <li>Uses Schemas for request/response validation</li> <li>Calls Services to execute business logic</li> <li> <p>Handles HTTP-specific concerns</p> </li> <li> <p>Service Layer (Business Logic)</p> </li> <li>Implements business rules and workflows</li> <li>Uses Repositories for data access</li> <li>Coordinates operations across multiple repositories</li> <li> <p>Transforms between Schemas and Models</p> </li> <li> <p>Repository Layer (Data Access)</p> </li> <li>Uses Models to interact with database</li> <li>Abstracts database operations (CRUD)</li> <li> <p>Handles query building and execution</p> </li> <li> <p>Database Layer (SQLAlchemy)</p> </li> <li>Defines Models that map to database tables</li> <li>Manages database connections and sessions</li> <li>Handles migrations and schema changes (see Database Migrations Guide)</li> </ol>"},{"location":"DOCUMENTATION/#component-details","title":"Component Details","text":""},{"location":"DOCUMENTATION/#models-vs-schemas","title":"Models vs. Schemas","text":"<ul> <li>Models (SQLAlchemy)</li> <li>Represent database tables</li> <li>Define relationships between entities</li> <li>Handle persistence concerns</li> <li> <p>Located in <code>src/models/</code></p> </li> <li> <p>Schemas (Pydantic)</p> </li> <li>Validate incoming/outgoing data</li> <li>Document API contracts</li> <li>Transform data between layers</li> <li>Located in <code>src/schemas/</code></li> <li>Organized by domain with re-exports for clean imports</li> <li>Includes base, create, update, and response schema types</li> </ul>"},{"location":"DOCUMENTATION/#design-patterns","title":"Design Patterns","text":"<p>The architecture implements several design patterns:</p> <ul> <li>Repository Pattern: Abstracts data access with <code>BaseRepository</code></li> <li>Unit of Work Pattern: Manages transactions with <code>UnitOfWork</code></li> <li>Dependency Injection: Provides dependencies to routes via FastAPI's dependency system</li> <li>Service Layer Pattern: Encapsulates business logic in services</li> <li>Consolidated Services: Groups related functionality within a domain into a cohesive service</li> </ul>"},{"location":"DOCUMENTATION/#service-consolidation","title":"Service Consolidation","text":"<p>To improve maintainability and reduce code fragmentation, related services handling the same domain entities are consolidated. This approach follows the Single Responsibility Principle at the domain level rather than at the function level.</p>"},{"location":"DOCUMENTATION/#examples-of-consolidated-services","title":"Examples of Consolidated Services","text":"<ul> <li>ExecutionService: Handles all execution-related operations including:</li> <li>Creating and running executions</li> <li>Tracking execution status</li> <li>Generating descriptive names for executions</li> <li>Managing execution metadata</li> </ul> <p>This replaces separate services like <code>ExecutionRunnerService</code> and simplifies dependencies.</p>"},{"location":"DOCUMENTATION/#consolidated-routers","title":"Consolidated Routers","text":"<p>Similarly, related API endpoints are grouped into consolidated router files:</p> <ul> <li>executions_router.py: All execution-related endpoints including:</li> <li>Creating executions</li> <li>Retrieving execution status</li> <li>Listing executions</li> <li>Generating execution names</li> </ul> <p>This approach simplifies API structure and improves discoverability.</p>"},{"location":"DOCUMENTATION/#directory-structure","title":"Directory Structure","text":"<pre><code>backend/\n\u251c\u2500\u2500 src/                 # Application source code\n\u2502   \u251c\u2500\u2500 api/             # API routes and controllers\n\u2502   \u251c\u2500\u2500 core/            # Core components (base classes, dependency injection)\n\u2502   \u251c\u2500\u2500 db/              # Database setup and session management\n\u2502   \u251c\u2500\u2500 models/          # SQLAlchemy models\n\u2502   \u251c\u2500\u2500 repositories/    # Repository pattern implementations\n\u2502   \u251c\u2500\u2500 schemas/         # Pydantic models for validation\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py  # Re-exports important schemas\n\u2502   \u2502   \u251c\u2500\u2500 base.py      # Common base schemas\n\u2502   \u2502   \u251c\u2500\u2500 {domain}/    # Domain-specific schemas\n\u2502   \u2502   \u2514\u2500\u2500 common/      # Shared schemas (pagination, etc.)\n\u2502   \u251c\u2500\u2500 services/        # Business logic services\n\u2502   \u251c\u2500\u2500 config/          # Configuration management\n\u2502   \u2502   \u2514\u2500\u2500 logging.py   # Logging configuration\n\u2502   \u251c\u2500\u2500 utils/           # Utility functions\n\u2502   \u2514\u2500\u2500 main.py          # Application entry point\n\u251c\u2500\u2500 tests/               # Test suite\n\u2502   \u251c\u2500\u2500 integration/     # Integration tests\n\u2502   \u2514\u2500\u2500 unit/            # Unit tests\n\u251c\u2500\u2500 migrations/          # Alembic migration scripts\n\u251c\u2500\u2500 logs/                # Application log files (excluded from version control)\n\u251c\u2500\u2500 pyproject.toml       # Dependencies and build settings\n\u2514\u2500\u2500 docs/                # Documentation files\n</code></pre>"},{"location":"DOCUMENTATION/#logging-strategy","title":"Logging Strategy","text":"<p>The application uses a structured logging approach:</p> <ul> <li>Configuration: Defined in <code>src/config/logging.py</code> </li> <li>Log Files: Stored in the top-level <code>logs/</code> directory (excluded from version control)</li> <li>Log Levels: DEBUG, INFO, WARNING, ERROR, CRITICAL based on environment</li> <li>Naming Convention: <code>{service_name}.{log_level}.{date}.log</code></li> <li>Handlers:</li> <li>File handlers for persistent logs</li> <li>Console handlers for development</li> <li>Optional external service integration (e.g., ELK, Datadog)</li> </ul> <p>This approach keeps runtime artifacts separate from source code while maintaining configuration within the application structure.</p>"},{"location":"DOCUMENTATION/#data-flow","title":"Data Flow","text":"<p>To illustrate how data flows through the system, consider a typical request lifecycle:</p> <ol> <li>HTTP Request \u2192 FastAPI parses and validates using Schemas</li> <li>API Route \u2192 Calls appropriate Service with validated data</li> <li>Service \u2192 Applies business logic, calls Repository methods</li> <li>Repository \u2192 Executes database operations using Models</li> <li>Database \u2192 Returns results to Repository</li> <li>Repository \u2192 Returns data to Service</li> <li>Service \u2192 Processes data, returns to API Route</li> <li>API Route \u2192 Converts to response Schema</li> <li>HTTP Response \u2192 Returned to client</li> </ol>"},{"location":"DOCUMENTATION/#real-example-creating-an-execution","title":"Real Example: Creating an Execution","text":"<p>Let's walk through how creating an execution works in our system:</p> <ol> <li>Client \u2192 Sends POST request to <code>/executions</code> with execution configuration</li> <li>FastAPI \u2192 Validates request data using <code>CrewConfig</code> schema</li> <li>API Route \u2192 Creates <code>ExecutionService</code> instance and calls <code>create_execution()</code></li> <li>ExecutionService \u2192 Generates execution ID, prepares execution data</li> <li>ExecutionService \u2192 Calls <code>ExecutionRepository.create_execution()</code> with prepared data</li> <li>ExecutionRepository \u2192 Creates database record, commits transaction</li> <li>ExecutionService \u2192 Schedules background task for execution</li> <li>API Route \u2192 Returns <code>ExecutionCreateResponse</code> to client</li> <li>Background \u2192 Execution runs asynchronously, updating status via repository</li> </ol>"},{"location":"DOCUMENTATION/#key-design-principles","title":"Key Design Principles","text":"<ol> <li>Separation of Concerns: Each layer has specific responsibilities</li> <li>Dependency Inversion: Higher layers depend on abstractions, not implementations</li> <li>Single Responsibility: Each component has one reason to change (at the domain level)</li> <li>Don't Repeat Yourself: Common functionality is abstracted and reused</li> <li>Explicit is Better Than Implicit: Clear, readable code over magic</li> <li>Cohesion: Related functionality is grouped together</li> </ol>"},{"location":"DOCUMENTATION/#getting-started","title":"Getting Started","text":"<p>For new developers, we recommend the following reading order:</p> <ol> <li>README.md for project overview</li> <li>GETTING_STARTED.md for setup and first steps</li> <li>ARCHITECTURE.md for understanding the system design</li> <li>MODELS.md and SCHEMAS.md for data handling</li> <li>SCHEMAS_STRUCTURE.md for schema organization</li> <li>DATABASE_MIGRATIONS.md for working with database schema changes</li> <li>BEST_PRACTICES.md for coding guidelines</li> </ol>"},{"location":"DOCUMENTATION/#conclusion","title":"Conclusion","text":"<p>This documentation is designed to help developers understand and contribute to the codebase effectively. Each document focuses on a specific aspect of the architecture, but together they provide a comprehensive guide to our modern Python backend design.</p> <p>If you find any documentation gaps or have suggestions for improvements, please create an issue or pull request. </p>"},{"location":"GETTING_STARTED/","title":"Getting Started with Kasal","text":"<p>This guide will help you set up and run the Kasal platform on your local machine for development purposes.</p>"},{"location":"GETTING_STARTED/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9 or higher for the backend</li> <li>Node.js 16 or higher for the frontend</li> <li>Poetry for Python dependency management</li> <li>npm for frontend dependency management</li> </ul>"},{"location":"GETTING_STARTED/#project-setup","title":"Project Setup","text":""},{"location":"GETTING_STARTED/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/yourusername/kasal.git\ncd kasal\n</code></pre>"},{"location":"GETTING_STARTED/#2-backend-setup","title":"2. Backend Setup","text":""},{"location":"GETTING_STARTED/#install-dependencies","title":"Install Dependencies","text":"<pre><code>cd backend\npoetry install\n</code></pre>"},{"location":"GETTING_STARTED/#environment-configuration","title":"Environment Configuration","text":"<p>Create a <code>.env</code> file in the backend directory:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit the <code>.env</code> file to configure:</p> <ul> <li>Database settings (SQLite by default for development)</li> <li>API keys for any integrated LLM services</li> <li>Other environment-specific settings</li> </ul>"},{"location":"GETTING_STARTED/#initialize-the-database","title":"Initialize the Database","text":"<p>Run database migrations:</p> <pre><code>poetry run alembic upgrade head\n</code></pre> <p>The application is configured to automatically seed the database with initial data on startup. If you want to disable this, set <code>AUTO_SEED_DATABASE=false</code> in your <code>.env</code> file.</p>"},{"location":"GETTING_STARTED/#start-the-backend-server","title":"Start the Backend Server","text":"<pre><code># Either use the provided script\n./run.sh\n\n# Or start with uvicorn directly\npoetry run uvicorn src.main:app --reload\n</code></pre> <p>The backend API will be available at http://localhost:8000.</p>"},{"location":"GETTING_STARTED/#3-frontend-setup","title":"3. Frontend Setup","text":""},{"location":"GETTING_STARTED/#install-dependencies_1","title":"Install Dependencies","text":"<pre><code>cd ../frontend\nnpm install\n</code></pre>"},{"location":"GETTING_STARTED/#start-the-frontend-development-server","title":"Start the Frontend Development Server","text":"<pre><code>npm start\n</code></pre> <p>The frontend will be available at http://localhost:3000.</p>"},{"location":"GETTING_STARTED/#building-the-documentation","title":"Building the Documentation","text":"<p>Kasal uses MkDocs with the Material theme for documentation. To build and view the documentation locally:</p>"},{"location":"GETTING_STARTED/#1-install-mkdocs-and-the-material-theme","title":"1. Install MkDocs and the Material theme","text":"<pre><code>pip install mkdocs mkdocs-material\n</code></pre>"},{"location":"GETTING_STARTED/#2-build-the-documentation","title":"2. Build the documentation","text":"<pre><code># From the project root\nmkdocs build\n</code></pre> <p>This will generate the documentation site in the <code>docs/site</code> directory.</p>"},{"location":"GETTING_STARTED/#3-serve-the-documentation-locally","title":"3. Serve the documentation locally","text":"<pre><code># From the project root\nmkdocs serve\n</code></pre> <p>This will start a local server at http://127.0.0.1:8000/ where you can view the documentation.</p>"},{"location":"GETTING_STARTED/#4-editing-documentation","title":"4. Editing Documentation","text":"<p>Documentation files are written in Markdown and located in the <code>docs/</code> directory. To update the Getting Started guide:</p> <ol> <li>Edit the <code>docs/GETTING_STARTED.md</code> file</li> <li>Run <code>mkdocs serve</code> to preview changes in real-time</li> <li>Once satisfied, commit your changes to the repository</li> </ol> <p>The backend server will automatically serve the documentation at http://localhost:8000/docs when running.</p>"},{"location":"GETTING_STARTED/#accessing-the-application","title":"Accessing the Application","text":"<p>Once both the backend and frontend are running, you can access:</p> <ul> <li>Kasal Web Interface: http://localhost:3000</li> <li>API Documentation: http://localhost:8000/api-docs</li> <li>Project Documentation: http://localhost:8000/docs</li> </ul>"},{"location":"GETTING_STARTED/#project-structure","title":"Project Structure","text":""},{"location":"GETTING_STARTED/#backend-fastapi-sqlalchemy","title":"Backend (FastAPI + SQLAlchemy)","text":"<pre><code>backend/\n\u251c\u2500\u2500 src/                 # Application source code\n\u2502   \u251c\u2500\u2500 api/             # API routes and controllers\n\u2502   \u251c\u2500\u2500 core/            # Core functionality and base classes\n\u2502   \u251c\u2500\u2500 db/              # Database configuration and models\n\u2502   \u251c\u2500\u2500 models/          # SQLAlchemy data models\n\u2502   \u251c\u2500\u2500 repositories/    # Data access layer\n\u2502   \u251c\u2500\u2500 schemas/         # Pydantic models for validation\n\u2502   \u251c\u2500\u2500 services/        # Business logic services\n\u2502   \u251c\u2500\u2500 engines/         # CrewAI integration\n\u2502   \u251c\u2500\u2500 seeds/           # Database seeders\n\u2502   \u251c\u2500\u2500 config/          # Configuration management\n\u2502   \u251c\u2500\u2500 utils/           # Utility functions\n\u2502   \u251c\u2500\u2500 main.py          # Application entry point\n\u2514\u2500\u2500 tests/               # Test suite\n</code></pre>"},{"location":"GETTING_STARTED/#frontend-react-typescript","title":"Frontend (React + TypeScript)","text":"<pre><code>frontend/\n\u251c\u2500\u2500 src/                 # Application source code\n\u2502   \u251c\u2500\u2500 components/      # Reusable UI components\n\u2502   \u251c\u2500\u2500 pages/           # Page components\n\u2502   \u251c\u2500\u2500 hooks/           # Custom React hooks\n\u2502   \u251c\u2500\u2500 services/        # API services\n\u2502   \u251c\u2500\u2500 store/           # State management with Zustand\n\u2502   \u251c\u2500\u2500 types/           # TypeScript type definitions\n\u2502   \u251c\u2500\u2500 utils/           # Utility functions\n\u2514\u2500\u2500 public/              # Static assets\n</code></pre>"},{"location":"GETTING_STARTED/#using-kasal","title":"Using Kasal","text":""},{"location":"GETTING_STARTED/#creating-your-first-agent-workflow","title":"Creating Your First Agent Workflow","text":"<ol> <li>Access the Kasal web interface at http://localhost:3000</li> <li>Navigate to the workspace page</li> <li>Use the visual designer to:</li> <li>Create agents by dragging them onto the canvas</li> <li>Define agent properties, tools, and memory</li> <li>Connect agents to create workflows</li> <li>Configure task dependencies</li> </ol>"},{"location":"GETTING_STARTED/#running-your-workflow","title":"Running Your Workflow","text":"<ol> <li>Save your workflow</li> <li>Click the \"Execute\" button to run the workflow</li> <li>Monitor execution in real-time</li> <li>View results in the execution panel</li> </ol>"},{"location":"GETTING_STARTED/#development-guidelines","title":"Development Guidelines","text":"<ul> <li>Backend Development: Follow the clean architecture pattern with clear separation between layers</li> <li>API Design: Use RESTful principles for all endpoints</li> <li>Database Changes: Create migrations using Alembic for any model changes</li> <li>Frontend Development: Use TypeScript for all components and maintain a consistent UI design</li> <li>Testing: Write tests for all new features</li> </ul>"},{"location":"GETTING_STARTED/#troubleshooting","title":"Troubleshooting","text":""},{"location":"GETTING_STARTED/#common-issues","title":"Common Issues","text":"<ul> <li>Database Errors: Verify your database configuration in <code>.env</code></li> <li>Connection Refused: Ensure both backend and frontend servers are running</li> <li>Authentication Errors: Check API keys and credentials in <code>.env</code></li> <li>Frontend Build Errors: Clean node_modules and reinstall dependencies</li> </ul>"},{"location":"GETTING_STARTED/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the logs in <code>backend/logs/</code></li> <li>Review the API documentation at http://localhost:8000/api-docs</li> <li>Consult the comprehensive documentation at http://localhost:8000/docs</li> </ol>"},{"location":"GETTING_STARTED/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Kasal Architecture</li> <li>Explore the CrewAI Engine integration</li> <li>Understand Frontend State Management </li> </ul>"},{"location":"LLM_MANAGER/","title":"LLM Manager","text":""},{"location":"LLM_MANAGER/#overview","title":"Overview","text":"<p>The LLM Manager (<code>LLMManager</code>) is a core component that provides centralized management for configuring and interacting with different Language Model (LLM) providers through the LiteLLM interface. It serves as a unified configuration point for all LLM-related operations in the application.</p>"},{"location":"LLM_MANAGER/#location","title":"Location","text":"<pre><code>backend/src/core/llm_manager.py\n</code></pre>"},{"location":"LLM_MANAGER/#configuration-approaches","title":"Configuration Approaches","text":"<p>The application uses two different approaches for LLM configuration:</p> <ol> <li> <p>LiteLLM Configuration: Uses <code>LLMManager.configure_litellm()</code> - This configuration is used for general text generation and completion tasks that utilize LiteLLM directly.</p> </li> <li> <p>CrewAI Configuration: Uses <code>LLMManager.configure_crewai_llm()</code> - This method configures a CrewAI LLM instance with the proper provider prefixes and settings required by CrewAI.</p> </li> </ol>"},{"location":"LLM_MANAGER/#provider-prefixing-for-crewai","title":"Provider Prefixing for CrewAI","text":"<p>For CrewAI integration, model names must be properly prefixed with the provider name for certain providers. The <code>configure_crewai_llm</code> method handles this automatically:</p> <ul> <li>DeepSeek: Uses format <code>deepseek/model-name</code></li> <li>Anthropic: Uses format <code>anthropic/model-name</code></li> <li>Ollama: Uses format <code>ollama/model-name</code></li> <li>Databricks: Uses format <code>databricks/model-name</code></li> <li>OpenAI: No prefix needed, uses format <code>model-name</code></li> </ul> <pre><code># Example of CrewAI LLM configuration\ncrewai_llm = await LLMManager.configure_crewai_llm(\"deepseek-chat\")\n\n# Applies the agent's crew with the properly configured LLM\nfor agent in crew.agents:\n    agent.llm = crewai_llm\n</code></pre>"},{"location":"LLM_MANAGER/#key-features","title":"Key Features","text":"<ul> <li>Centralized LLM configuration management</li> <li>Provider-specific configuration handling</li> <li>API key management integration</li> <li>Support for multiple LLM providers (OpenAI, Anthropic, DeepSeek, Ollama, Databricks)</li> <li>Specialized configuration for different use cases (LiteLLM vs CrewAI)</li> <li>Proper model name formatting with provider prefixes</li> </ul>"},{"location":"LLM_MANAGER/#methods","title":"Methods","text":""},{"location":"LLM_MANAGER/#configure_litellm","title":"<code>configure_litellm</code>","text":"<pre><code>@staticmethod\nasync def configure_litellm(model: str) -&gt; Dict[str, Any]\n</code></pre> <p>Primary configuration method used by services that interact directly with LiteLLM. This method: - Retrieves model configuration - Sets up provider-specific parameters - Handles API key management - Configures provider-specific endpoints</p> <p>Used by: - Agent Generation Service - Task Generation Service - Connection Service - Crew Generation Service</p>"},{"location":"LLM_MANAGER/#configure_crewai_llm","title":"<code>configure_crewai_llm</code>","text":"<pre><code>@staticmethod\nasync def configure_crewai_llm(model_name: str) -&gt; LLM\n</code></pre> <p>Specialized configuration method for CrewAI integration. This method: - Creates and returns a properly configured CrewAI LLM instance - Handles provider-specific model name formatting with prefixes - Configures provider-specific endpoints - Manages API keys - Returns a ready-to-use CrewAI LLM object</p> <p>Used by: - Crew Execution Runner</p>"},{"location":"LLM_MANAGER/#usage-by-services","title":"Usage by Services","text":""},{"location":"LLM_MANAGER/#litellm-services","title":"LiteLLM Services","text":"<p>The following services use the standard <code>configure_litellm</code> method:</p> <ol> <li>Agent Generation Service</li> <li>Purpose: Configures LLMs for agent creation and configuration</li> <li> <p>Usage: During agent initialization and task processing</p> </li> <li> <p>Task Generation Service</p> </li> <li>Purpose: Sets up LLMs for task generation and management</li> <li> <p>Usage: When creating and processing tasks</p> </li> <li> <p>Connection Service</p> </li> <li>Purpose: Configures LLMs for handling service connections</li> <li> <p>Usage: During connection establishment and management</p> </li> <li> <p>Crew Generation Service</p> </li> <li>Purpose: Sets up LLMs for crew creation and configuration</li> <li>Usage: When initializing and managing crews</li> </ol>"},{"location":"LLM_MANAGER/#crewai-execution","title":"CrewAI Execution","text":"<p>The Crew Execution Runner uses the specialized <code>configure_crewai_llm</code> method:</p> <ul> <li>Purpose: Creates a properly configured CrewAI LLM instance</li> <li>Usage: Before running crew operations</li> <li>Special Requirements: Needs provider-prefixed model names for compatibility with LiteLLM</li> </ul>"},{"location":"LLM_MANAGER/#supported-providers","title":"Supported Providers","text":"<p>The LLM Manager supports the following providers:</p> <ol> <li>OpenAI</li> <li>Models: GPT-4, GPT-3.5-Turbo, etc.</li> <li>Configuration: API key based</li> <li> <p>CrewAI Format: <code>model-name</code> (no prefix needed)</p> </li> <li> <p>Anthropic</p> </li> <li>Models: Claude series</li> <li>Configuration: API key based</li> <li> <p>CrewAI Format: <code>anthropic/model-name</code></p> </li> <li> <p>DeepSeek</p> </li> <li>Models: DeepSeek Chat, DeepSeek Reasoner</li> <li>Configuration: API key and custom endpoint</li> <li> <p>CrewAI Format: <code>deepseek/model-name</code></p> </li> <li> <p>Ollama</p> </li> <li>Models: Llama, Mistral, etc.</li> <li>Configuration: Local endpoint configuration</li> <li> <p>CrewAI Format: <code>ollama/model-name</code></p> </li> <li> <p>Databricks</p> </li> <li>Models: Databricks-hosted models</li> <li>Configuration: Token-based authentication and custom endpoint</li> <li>CrewAI Format: <code>databricks/model-name</code></li> </ol>"},{"location":"LLM_MANAGER/#best-practices","title":"Best Practices","text":"<ol> <li>Service Layer Usage</li> <li>Always use the appropriate configuration method for your use case</li> <li>For direct LiteLLM usage, use <code>configure_litellm</code></li> <li> <p>For CrewAI integration, use <code>configure_crewai_llm</code></p> </li> <li> <p>Error Handling</p> </li> <li>Always handle configuration errors appropriately</li> <li>Implement retry mechanisms for transient failures</li> <li> <p>Log configuration issues for debugging</p> </li> <li> <p>API Key Management</p> </li> <li>Never hardcode API keys</li> <li>Use the <code>ApiKeysService</code> for key management</li> <li> <p>Handle missing API key scenarios gracefully</p> </li> <li> <p>Provider-Specific Configuration</p> </li> <li>Be aware of provider-specific requirements</li> <li>Use appropriate environment variables for endpoints</li> <li>Follow provider-specific naming conventions</li> </ol>"},{"location":"LLM_MANAGER/#example-usage","title":"Example Usage","text":"<pre><code># For direct LiteLLM services\nmodel_params = await LLMManager.configure_litellm(\"gpt-4\")\n\n# For CrewAI integration\ncrewai_llm = await LLMManager.configure_crewai_llm(\"deepseek-chat\")\nagent.llm = crewai_llm\n</code></pre>"},{"location":"LLM_MANAGER/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and their solutions:</p> <ol> <li>Provider Not Configured</li> <li>Ensure the provider is properly specified in the model configuration</li> <li> <p>Check if the provider is supported</p> </li> <li> <p>API Key Issues</p> </li> <li>Verify API key is set in the environment</li> <li>Check API key permissions</li> <li> <p>Ensure API key is properly configured in the service</p> </li> <li> <p>Endpoint Configuration</p> </li> <li>Verify endpoint URLs are correctly set</li> <li>Check environment variables for custom endpoints</li> <li> <p>Ensure network access to endpoints</p> </li> <li> <p>LLM Provider NOT provided Error</p> </li> <li>This error typically occurs when using CrewAI with improperly formatted model names</li> <li>Ensure you're using <code>configure_crewai_llm</code> for CrewAI integration</li> <li>Verify the model name includes the proper provider prefix</li> <li>The format should be <code>provider/model-name</code> for most providers (except OpenAI)</li> </ol>"},{"location":"LLM_MANAGER/#future-considerations","title":"Future Considerations","text":"<ul> <li>Support for additional LLM providers</li> <li>Enhanced configuration options</li> <li>Performance optimization</li> <li>Caching mechanisms</li> <li>Rate limiting implementation</li> <li>Additional CrewAI-specific configuration options</li> </ul>"},{"location":"LLM_MANAGER/#handling-the-llm-provider-not-provided-error","title":"Handling the \"LLM Provider NOT provided\" Error","text":"<p>This is a common error when using CrewAI with LiteLLM. Our solution:</p> <ol> <li> <p>Root Cause: CrewAI's integration with LiteLLM requires model names to include provider prefixes.</p> </li> <li> <p>Solution: The <code>configure_crewai_llm</code> method automatically formats model names with the correct provider prefix.</p> </li> <li> <p>Implementation: </p> </li> <li>We use CrewAI's native <code>LLM</code> class</li> <li>We format model names with provider prefixes (e.g., <code>deepseek/deepseek-chat</code>)</li> <li>We directly apply the configured LLM to each agent in the crew</li> </ol> <p>This approach ensures proper integration between CrewAI and LiteLLM by handling the provider-specific formatting requirements in a centralized way. </p>"},{"location":"LOGGING/","title":"Logging Guide","text":"<p>This document provides comprehensive documentation for the logging system in our backend architecture.</p>"},{"location":"LOGGING/#overview","title":"Overview","text":"<p>The application uses a structured logging approach that separates configuration from log storage. This design follows best practices for maintainability, observability, and separation of concerns.</p>"},{"location":"LOGGING/#logging-architecture","title":"Logging Architecture","text":"<p>The logging architecture consists of:</p> <ol> <li>Configuration (<code>src/config/logging.py</code>): Contains all logging setup and configuration</li> <li>Log Storage (<code>logs/</code> directory): Stores the actual log files (excluded from version control)</li> <li>Integration Points: Code that uses the logging system across the application</li> </ol>"},{"location":"LOGGING/#directory-structure","title":"Directory Structure","text":"<pre><code>backend/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 config/\n\u2502   \u2502   \u2514\u2500\u2500 logging.py     # Logging configuration\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 logs/                 # Log files (gitignored)\n\u2502   \u251c\u2500\u2500 backend.2023-06-15.log\n\u2502   \u251c\u2500\u2500 backend.error.2023-06-15.log\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"LOGGING/#log-file-naming-convention","title":"Log File Naming Convention","text":"<p>Log files follow this naming pattern:</p> <ul> <li>Regular logs: <code>backend.{date}.log</code></li> <li>Error logs: <code>backend.error.{date}.log</code></li> </ul> <p>For example: <code>backend.2023-06-15.log</code> or <code>backend.error.2023-06-15.log</code></p>"},{"location":"LOGGING/#configuration-details","title":"Configuration Details","text":"<p>The logging system is configured in <code>src/config/logging.py</code> and provides:</p>"},{"location":"LOGGING/#environment-based-configuration","title":"Environment-Based Configuration","text":"<p>The logging configuration adapts based on the application environment:</p> <ul> <li>Development: Verbose console output with DEBUG level, formatted for readability</li> <li>Staging: More structured output with INFO level</li> <li>Production: Minimal console output but comprehensive file logging</li> </ul>"},{"location":"LOGGING/#log-handlers","title":"Log Handlers","text":"<p>Three types of handlers are configured:</p> <ol> <li>Console Handler: Outputs logs to the console (stdout)</li> <li>File Handler: Writes all INFO and above logs to a daily log file</li> <li>Error File Handler: Writes only ERROR and above logs to a separate error log file</li> </ol>"},{"location":"LOGGING/#log-formatting","title":"Log Formatting","text":"<p>Two formats are available:</p> <ol> <li>Simple Format: <code>%(asctime)s - %(levelname)s - %(message)s</code></li> <li>Used for development console output</li> <li> <p>Example: <code>2023-06-15 14:30:45 - INFO - Application started</code></p> </li> <li> <p>Verbose Format: <code>%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s</code></p> </li> <li>Used for file logging and production environments</li> <li>Example: <code>2023-06-15 14:30:45 - myapp.services - INFO - [user_service.py:45] - User created with ID 123</code></li> </ol>"},{"location":"LOGGING/#using-the-logging-system","title":"Using the Logging System","text":""},{"location":"LOGGING/#getting-a-logger","title":"Getting a Logger","text":"<p>To use the logging system in your code:</p> <pre><code>from src.config.logging import get_logger\n\n# Use the module name for the logger\nlogger = get_logger(__name__)\n\n# Now use the logger\nlogger.debug(\"Detailed debugging information\")\nlogger.info(\"Normal application event\")\nlogger.warning(\"Something unexpected but not critical\")\nlogger.error(\"Something failed but application continues\")\nlogger.critical(\"Application cannot continue\")\n</code></pre>"},{"location":"LOGGING/#logging-best-practices","title":"Logging Best Practices","text":"<ol> <li>Use Structured Logging: Include relevant context in your log messages</li> </ol> <pre><code># Instead of:\nlogger.info(f\"User {user_id} created\")\n\n# Use:\nlogger.info(\"User created\", extra={\"user_id\": user_id, \"email\": email})\n</code></pre> <ol> <li>Choose Appropriate Log Levels:</li> <li><code>DEBUG</code>: Detailed information for debugging</li> <li><code>INFO</code>: Confirmation that things are working</li> <li><code>WARNING</code>: Something unexpected but not an error</li> <li><code>ERROR</code>: An error that prevents a function from working</li> <li> <p><code>CRITICAL</code>: An error that prevents the application from working</p> </li> <li> <p>Include Exception Information:</p> </li> </ol> <pre><code>try:\n    # Some code that might raise an exception\n    result = complex_operation()\nexcept Exception as e:\n    logger.exception(\"Failed to perform complex operation\")\n    # The exception() method automatically includes the stack trace\n</code></pre>"},{"location":"LOGGING/#log-rotation","title":"Log Rotation","text":"<p>Log files are automatically rotated when they reach 10MB, with a maximum of 5 backup files kept for each log type. This prevents logs from consuming excessive disk space.</p>"},{"location":"LOGGING/#production-considerations","title":"Production Considerations","text":"<p>In production environments, consider:</p> <ol> <li>External Log Aggregation: Configure additional handlers for services like ELK, Datadog, or Sentry</li> <li>Log Security: Ensure logs don't contain sensitive information (PII, credentials, etc.)</li> <li>Monitoring: Set up alerts based on ERROR and CRITICAL log events</li> </ol>"},{"location":"LOGGING/#initializing-the-logging-system","title":"Initializing the Logging System","text":"<p>The logging system is automatically initialized when the application starts:</p> <pre><code># In main.py or startup code\nfrom src.config.logging import setup_logging\n\n# Initialize logging with the current environment\nsetup_logging(env=\"development\")  # or \"production\", \"staging\"\n</code></pre>"},{"location":"LOGGING/#conclusion","title":"Conclusion","text":"<p>Following these logging practices ensures that our application produces consistent, useful logs that aid in debugging, monitoring, and understanding system behavior across all environments. </p>"},{"location":"MODELS/","title":"SQLAlchemy Models Guide","text":"<p>This document provides comprehensive documentation for SQLAlchemy models in our backend architecture.</p>"},{"location":"MODELS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Structure and Conventions</li> <li>Base Model Configuration</li> <li>Model Relationships</li> <li>Common Field Types</li> <li>Indexing Strategy</li> <li>Lifecycle Events</li> <li>Best Practices</li> <li>Examples</li> </ul>"},{"location":"MODELS/#overview","title":"Overview","text":"<p>SQLAlchemy models represent database tables and are a core component of the Database Layer in our architecture. They:</p> <ul> <li>Define the data structure and relationships in the database</li> <li>Map Python objects to database records</li> <li>Provide a type-safe interface for working with data</li> <li>Handle database constraints and validations</li> </ul> <p>Models are stored in the <code>src/models/</code> directory, with each model typically in its own file.</p>"},{"location":"MODELS/#structure-and-conventions","title":"Structure and Conventions","text":""},{"location":"MODELS/#file-organization","title":"File Organization","text":"<pre><code>src/models/\n\u251c\u2500\u2500 __init__.py           # Exposes models for easier imports\n\u251c\u2500\u2500 item.py               # Models related to items\n\u251c\u2500\u2500 user.py               # Models related to users\n\u2514\u2500\u2500 other_domain.py       # Other domain-specific models\n</code></pre>"},{"location":"MODELS/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Model class names: PascalCase</li> <li>Table names: snake_case (auto-generated from class name)</li> <li>Column names: snake_case</li> <li>Primary key: <code>id</code> (standard across all models)</li> <li>Foreign keys: <code>{table_name}_id</code> (e.g., <code>user_id</code>)</li> </ul>"},{"location":"MODELS/#base-model-configuration","title":"Base Model Configuration","text":"<p>All models inherit from a common <code>Base</code> class which provides consistent behavior:</p> <pre><code># src/db/base.py\nfrom typing import Any\n\nfrom sqlalchemy.ext.declarative import declared_attr\nfrom sqlalchemy.orm import DeclarativeBase\n\n\nclass Base(DeclarativeBase):\n    \"\"\"Base class for all database models.\"\"\"\n\n    id: Any\n\n    # Generate __tablename__ automatically based on class name\n    @declared_attr.directive\n    def __tablename__(cls) -&gt; str:\n        return cls.__name__.lower()\n</code></pre>"},{"location":"MODELS/#model-relationships","title":"Model Relationships","text":"<p>SQLAlchemy supports various relationship types, configured using the <code>relationship</code> function.</p>"},{"location":"MODELS/#one-to-many-relationship","title":"One-to-Many Relationship","text":"<pre><code># Parent model (One)\nclass User(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(100))\n\n    # Define relationship\n    posts: Mapped[List[\"Post\"]] = relationship(\"Post\", back_populates=\"user\")\n\n# Child model (Many)\nclass Post(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    title: Mapped[str] = mapped_column(String(200))\n\n    # Foreign key\n    user_id: Mapped[int] = mapped_column(ForeignKey(\"user.id\"))\n\n    # Define relationship\n    user: Mapped[\"User\"] = relationship(\"User\", back_populates=\"posts\")\n</code></pre>"},{"location":"MODELS/#many-to-many-relationship","title":"Many-to-Many Relationship","text":"<pre><code># Association table (no model, just a table)\ntag_item_association = Table(\n    \"tag_item_association\",\n    Base.metadata,\n    Column(\"tag_id\", Integer, ForeignKey(\"tag.id\"), primary_key=True),\n    Column(\"item_id\", Integer, ForeignKey(\"item.id\"), primary_key=True),\n)\n\n# First entity\nclass Tag(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(50), unique=True)\n\n    # Define relationship\n    items: Mapped[List[\"Item\"]] = relationship(\n        \"Item\", \n        secondary=tag_item_association,\n        back_populates=\"tags\"\n    )\n\n# Second entity\nclass Item(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(100))\n\n    # Define relationship\n    tags: Mapped[List[\"Tag\"]] = relationship(\n        \"Tag\", \n        secondary=tag_item_association,\n        back_populates=\"items\"\n    )\n</code></pre>"},{"location":"MODELS/#one-to-one-relationship","title":"One-to-One Relationship","text":"<pre><code>class User(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(100))\n\n    # Define one-to-one relationship\n    profile: Mapped[\"UserProfile\"] = relationship(\n        \"UserProfile\", \n        back_populates=\"user\", \n        uselist=False\n    )\n\nclass UserProfile(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    bio: Mapped[Optional[str]] = mapped_column(String(1000), nullable=True)\n\n    # Foreign key\n    user_id: Mapped[int] = mapped_column(ForeignKey(\"user.id\"), unique=True)\n\n    # Define relationship back to User\n    user: Mapped[\"User\"] = relationship(\"User\", back_populates=\"profile\")\n</code></pre>"},{"location":"MODELS/#common-field-types","title":"Common Field Types","text":"<p>SQLAlchemy supports various field types, here are the most common ones:</p> Python Type SQLAlchemy Type Description <code>int</code> <code>Integer</code> Integer values <code>float</code> <code>Float</code> Floating point values <code>str</code> <code>String(length)</code> Variable length strings with max length <code>str</code> <code>Text</code> Unlimited length strings <code>bool</code> <code>Boolean</code> True/False values <code>datetime</code> <code>DateTime</code> Date and time values <code>date</code> <code>Date</code> Date values without time <code>timedelta</code> <code>Interval</code> Time intervals <code>Decimal</code> <code>Numeric</code> Precise decimal values <code>bytes</code> <code>LargeBinary</code> Binary data (files, etc.) <code>dict</code> <code>JSON</code> JSON data <code>enum.Enum</code> <code>Enum</code> Enumeration values <code>UUID</code> <code>UUID</code> UUID values <p>Example usage:</p> <pre><code>from datetime import datetime\nfrom typing import Optional\nfrom uuid import UUID, uuid4\n\nfrom sqlalchemy import DateTime, String, Boolean, Text\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nclass Product(Base):\n    id: Mapped[UUID] = mapped_column(default=uuid4, primary_key=True)\n    name: Mapped[str] = mapped_column(String(200))\n    description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)\n    price: Mapped[float]\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), default=datetime.utcnow\n    )\n    updated_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), \n        default=datetime.utcnow, \n        onupdate=datetime.utcnow\n    )\n</code></pre>"},{"location":"MODELS/#indexing-strategy","title":"Indexing Strategy","text":"<p>Indexes improve query performance. Common index types:</p>"},{"location":"MODELS/#simple-indexes","title":"Simple Indexes","text":"<pre><code>class User(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    email: Mapped[str] = mapped_column(String(255), index=True, unique=True)\n    username: Mapped[str] = mapped_column(String(50), index=True, unique=True)\n</code></pre>"},{"location":"MODELS/#composite-indexes","title":"Composite Indexes","text":"<pre><code>class Order(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    user_id: Mapped[int] = mapped_column(ForeignKey(\"user.id\"))\n    product_id: Mapped[int] = mapped_column(ForeignKey(\"product.id\"))\n    quantity: Mapped[int]\n    created_at: Mapped[datetime] = mapped_column(DateTime)\n\n    # Create a composite index on user_id and created_at\n    __table_args__ = (\n        Index('ix_order_user_id_created_at', 'user_id', 'created_at'),\n    )\n</code></pre>"},{"location":"MODELS/#when-to-use-indexes","title":"When to Use Indexes","text":"<ul> <li>Primary keys are automatically indexed</li> <li>Foreign keys should generally be indexed</li> <li>Columns frequently used in WHERE clauses</li> <li>Columns used in ORDER BY or GROUP BY</li> <li>Columns with high cardinality (many unique values)</li> </ul>"},{"location":"MODELS/#lifecycle-events","title":"Lifecycle Events","text":"<p>SQLAlchemy supports event listeners for model lifecycle events:</p> <pre><code>from sqlalchemy import event\n\n# Hook for before_insert event\n@event.listens_for(User, 'before_insert')\ndef hash_password(mapper, connection, user):\n    # Hash the password before saving to database\n    if user.password:\n        user.password_hash = hash_password(user.password)\n        user.password = None  # Don't store the plain password\n</code></pre> <p>Common events include: - <code>before_insert</code> - <code>after_insert</code> - <code>before_update</code> - <code>after_update</code> - <code>before_delete</code> - <code>after_delete</code></p>"},{"location":"MODELS/#best-practices","title":"Best Practices","text":""},{"location":"MODELS/#1-keep-models-simple","title":"1. Keep Models Simple","text":"<p>Models should represent database tables with minimal business logic. Complex logic should be in the service layer.</p>"},{"location":"MODELS/#2-use-type-annotations","title":"2. Use Type Annotations","text":"<p>Always use type annotations with <code>Mapped[]</code> for clarity and better type checking:</p> <pre><code># Good\nclass User(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(100))\n\n# Avoid\nclass User(Base):\n    id = mapped_column(Integer, primary_key=True)\n    name = mapped_column(String(100))\n</code></pre>"},{"location":"MODELS/#3-define-constraints-at-the-database-level","title":"3. Define Constraints at the Database Level","text":"<p>Use SQLAlchemy to define constraints enforced by the database:</p> <pre><code>class User(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    email: Mapped[str] = mapped_column(\n        String(255), \n        unique=True,  # Enforce uniqueness\n        nullable=False  # Require this field\n    )\n    age: Mapped[int] = mapped_column(CheckConstraint(\"age &gt;= 18\"))  # Check constraint\n</code></pre>"},{"location":"MODELS/#4-use-meaningful-default-values","title":"4. Use Meaningful Default Values","text":"<p>Provide default values where appropriate:</p> <pre><code>class Item(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(100))\n    is_active: Mapped[bool] = mapped_column(default=True)  # Default to active\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), \n        default=datetime.utcnow  # Automatic timestamp\n    )\n</code></pre>"},{"location":"MODELS/#5-add-proper-documentation","title":"5. Add Proper Documentation","text":"<p>Document your models with docstrings explaining purpose and relationships:</p> <pre><code>class User(Base):\n    \"\"\"\n    User model representing application users.\n\n    Relationships:\n        - Has many posts (one-to-many)\n        - Has one profile (one-to-one)\n    \"\"\"\n    id: Mapped[int] = mapped_column(primary_key=True)\n    # ...\n</code></pre>"},{"location":"MODELS/#6-use-soft-deletes-when-appropriate","title":"6. Use Soft Deletes When Appropriate","text":"<p>Consider using soft deletes for important data:</p> <pre><code>class User(Base):\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str] = mapped_column(String(100))\n    is_deleted: Mapped[bool] = mapped_column(default=False)\n    deleted_at: Mapped[Optional[datetime]] = mapped_column(\n        DateTime(timezone=True), \n        nullable=True\n    )\n</code></pre>"},{"location":"MODELS/#examples","title":"Examples","text":""},{"location":"MODELS/#example-basic-model-with-timestamps","title":"Example: Basic Model with Timestamps","text":"<pre><code>from datetime import datetime\nfrom typing import Optional\n\nfrom sqlalchemy import DateTime, String\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom src.db.base import Base\n\n\nclass Item(Base):\n    \"\"\"Item model representing products or services.\"\"\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    name: Mapped[str] = mapped_column(String(100), index=True)\n    description: Mapped[Optional[str]] = mapped_column(String(1000), nullable=True)\n    price: Mapped[float]\n    is_active: Mapped[bool] = mapped_column(default=True)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), default=datetime.utcnow\n    )\n    updated_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), \n        default=datetime.utcnow, \n        onupdate=datetime.utcnow\n    )\n</code></pre>"},{"location":"MODELS/#example-model-with-relationships","title":"Example: Model with Relationships","text":"<pre><code>from typing import List, Optional\n\nfrom sqlalchemy import ForeignKey, String\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom src.db.base import Base\n\n\nclass User(Base):\n    \"\"\"\n    User model representing application users.\n\n    Relationships:\n        - Has many orders (one-to-many)\n    \"\"\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    username: Mapped[str] = mapped_column(String(50), index=True, unique=True)\n    email: Mapped[str] = mapped_column(String(100), index=True, unique=True)\n    full_name: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)\n\n    # Relationships\n    orders: Mapped[List[\"Order\"]] = relationship(\"Order\", back_populates=\"user\")\n\n\nclass Order(Base):\n    \"\"\"\n    Order model representing user purchases.\n\n    Relationships:\n        - Belongs to a user (many-to-one)\n        - Has many items (one-to-many)\n    \"\"\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    total_amount: Mapped[float]\n\n    # Foreign keys\n    user_id: Mapped[int] = mapped_column(ForeignKey(\"user.id\"))\n\n    # Relationships\n    user: Mapped[\"User\"] = relationship(\"User\", back_populates=\"orders\")\n    items: Mapped[List[\"OrderItem\"]] = relationship(\"OrderItem\", back_populates=\"order\")\n\n\nclass OrderItem(Base):\n    \"\"\"\n    OrderItem model representing items within an order.\n\n    Relationships:\n        - Belongs to an order (many-to-one)\n    \"\"\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    quantity: Mapped[int]\n    unit_price: Mapped[float]\n\n    # Foreign keys\n    order_id: Mapped[int] = mapped_column(ForeignKey(\"order.id\"))\n    product_id: Mapped[int] = mapped_column(ForeignKey(\"product.id\"))\n\n    # Relationships\n    order: Mapped[\"Order\"] = relationship(\"Order\", back_populates=\"items\")\n    product: Mapped[\"Product\"] = relationship(\"Product\")\n</code></pre>"},{"location":"MODELS/#example-model-with-enums-and-custom-types","title":"Example: Model with Enums and Custom Types","text":"<pre><code>import enum\nfrom datetime import date\nfrom typing import Optional\n\nfrom sqlalchemy import Enum, Date, String\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom src.db.base import Base\n\n\nclass SubscriptionType(enum.Enum):\n    FREE = \"free\"\n    BASIC = \"basic\"\n    PREMIUM = \"premium\"\n    ENTERPRISE = \"enterprise\"\n\n\nclass Subscription(Base):\n    \"\"\"Subscription model for user service plans.\"\"\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    user_id: Mapped[int] = mapped_column(ForeignKey(\"user.id\"))\n\n    # Using enum type\n    type: Mapped[SubscriptionType] = mapped_column(\n        Enum(SubscriptionType), default=SubscriptionType.FREE\n    )\n\n    # Date fields\n    start_date: Mapped[date] = mapped_column(Date)\n    end_date: Mapped[Optional[date]] = mapped_column(Date, nullable=True)\n\n    # Billing information\n    billing_address: Mapped[Optional[str]] = mapped_column(String(500), nullable=True)\n    payment_method: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)\n</code></pre>"},{"location":"REPOSITORY_PATTERN/","title":"Repository Pattern Implementation","text":"<p>This document explains how the Repository Pattern is implemented in our project, with a focus on the <code>ExecutionRepository</code> as a practical example.</p>"},{"location":"REPOSITORY_PATTERN/#overview-of-the-repository-pattern","title":"Overview of the Repository Pattern","text":"<p>The Repository Pattern is a design pattern that abstracts the data access logic from the rest of the application. It provides a collection-like interface for accessing domain objects, regardless of the underlying data storage mechanism.</p>"},{"location":"REPOSITORY_PATTERN/#core-benefits","title":"Core Benefits","text":"<ol> <li>Separation of Concerns: Isolates data access logic from business logic</li> <li>Testability: Makes unit testing easier by allowing mock repositories</li> <li>Flexibility: Simplifies switching between different data sources or ORM implementations</li> <li>Consistency: Provides a consistent way to interact with data across the application</li> <li>Code Organization: Groups related data access operations together</li> </ol>"},{"location":"REPOSITORY_PATTERN/#implementation-in-our-project","title":"Implementation in Our Project","text":"<p>In our application, repositories are implemented as classes that handle database operations for specific domain entities.</p>"},{"location":"REPOSITORY_PATTERN/#base-repository","title":"Base Repository","text":"<p>All repositories inherit from a base repository class that provides common CRUD operations:</p> <pre><code>class BaseRepository:\n    def __init__(self, session: AsyncSession):\n        self.session = session\n        self.model = self._get_model()\n\n    def _get_model(self):\n        # Implementation to determine the model class\n\n    async def get(self, id: int) -&gt; Optional[Any]:\n        # Get entity by ID\n\n    async def get_all(self) -&gt; List[Any]:\n        # Get all entities\n\n    async def create(self, data: Dict[str, Any]) -&gt; Any:\n        # Create new entity\n\n    async def update(self, id: int, data: Dict[str, Any]) -&gt; Optional[Any]:\n        # Update existing entity\n\n    async def delete(self, id: int) -&gt; bool:\n        # Delete entity by ID\n</code></pre>"},{"location":"REPOSITORY_PATTERN/#example-executionrepository","title":"Example: ExecutionRepository","text":"<p>The <code>ExecutionRepository</code> extends the base repository and adds specific methods for execution-related operations:</p> <pre><code>class ExecutionRepository(BaseRepository):\n    def __init__(self, session: AsyncSession):\n        super().__init__(session)\n        self.model = ExecutionHistory\n\n    async def get_execution_by_job_id(self, job_id: str) -&gt; Optional[ExecutionHistory]:\n        \"\"\"Get execution by job ID.\"\"\"\n        query = select(self.model).where(self.model.job_id == job_id)\n        result = await self.session.execute(query)\n        return result.scalars().first()\n\n    async def get_execution_history(self, limit: int = 100, offset: int = 0) -&gt; Tuple[List[ExecutionHistory], int]:\n        \"\"\"Get paginated execution history.\"\"\"\n        query = select(self.model).order_by(desc(self.model.created_at)).offset(offset).limit(limit)\n        result = await self.session.execute(query)\n        executions = result.scalars().all()\n\n        # Get total count\n        count_query = select(func.count()).select_from(self.model)\n        count_result = await self.session.execute(count_query)\n        total = count_result.scalar() or 0\n\n        return executions, total\n\n    async def create_execution(self, data: Dict[str, Any]) -&gt; ExecutionHistory:\n        \"\"\"Create a new execution record.\"\"\"\n        execution = self.model(**data)\n        self.session.add(execution)\n        await self.session.commit()\n        await self.session.refresh(execution)\n        return execution\n\n    async def update_execution(self, execution_id: int, data: Dict[str, Any]) -&gt; Optional[ExecutionHistory]:\n        \"\"\"Update an execution record.\"\"\"\n        query = select(self.model).where(self.model.id == execution_id)\n        result = await self.session.execute(query)\n        execution = result.scalars().first()\n\n        if not execution:\n            return None\n\n        for key, value in data.items():\n            setattr(execution, key, value)\n\n        await self.session.commit()\n        await self.session.refresh(execution)\n        return execution\n\n    async def mark_execution_completed(self, execution_id: int, result: Dict[str, Any] = None) -&gt; Optional[ExecutionHistory]:\n        \"\"\"Mark an execution as completed.\"\"\"\n        data = {\n            \"status\": \"completed\",\n            \"completed_at\": datetime.now(UTC)\n        }\n\n        if result:\n            data[\"result\"] = result\n\n        return await self.update_execution(execution_id, data)\n\n    async def mark_execution_failed(self, execution_id: int, error: str) -&gt; Optional[ExecutionHistory]:\n        \"\"\"Mark an execution as failed.\"\"\"\n        data = {\n            \"status\": \"failed\",\n            \"completed_at\": datetime.now(UTC),\n            \"error\": error\n        }\n\n        return await self.update_execution(execution_id, data)\n</code></pre>"},{"location":"REPOSITORY_PATTERN/#use-in-service-layer","title":"Use in Service Layer","text":"<p>Repositories are used by services to perform data operations. Here's how the <code>ExecutionService</code> uses the <code>ExecutionRepository</code>:</p> <pre><code>class ExecutionService:\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def create_execution(self, config: CrewConfig, background_tasks = None) -&gt; Dict[str, Any]:\n        # Generate a new execution ID\n        execution_id = ExecutionService.create_execution_id()\n\n        # Generate a descriptive run name\n        run_name = await generate_run_name(config.agents_yaml, config.tasks_yaml, config.model, self.db)\n\n        # Create execution data\n        execution_data = {\n            \"job_id\": execution_id,\n            \"status\": ExecutionStatus.PENDING.value,\n            \"inputs\": {\n                # Details about the execution\n            },\n            \"run_name\": run_name,\n            \"created_at\": datetime.now(UTC)\n        }\n\n        # Create the execution record using the repository\n        execution_repo = ExecutionRepository(self.db)\n        await execution_repo.create_execution(data=execution_data)\n\n        # ... additional logic\n\n        return {\n            \"execution_id\": execution_id,\n            \"status\": ExecutionStatus.PENDING.value,\n            \"run_name\": run_name\n        }\n</code></pre>"},{"location":"REPOSITORY_PATTERN/#dependency-injection","title":"Dependency Injection","text":"<p>Repositories are typically instantiated with a database session passed from the API layer:</p> <pre><code>@router.get(\"/{execution_id}\", response_model=ExecutionResponse)\nasync def get_execution_status(execution_id: str, db: AsyncSession = Depends(get_db)):\n    \"\"\"Get the status of a specific execution.\"\"\"\n    execution_data = await ExecutionService.get_execution_status(db, execution_id)\n\n    if not execution_data:\n        raise HTTPException(status_code=404, detail=\"Execution not found\")\n\n    return ExecutionResponse(**execution_data)\n</code></pre> <p>In the service implementation:</p> <pre><code>@staticmethod\nasync def get_execution_status(db: AsyncSession, execution_id: str) -&gt; Dict[str, Any]:\n    \"\"\"Get the current status of an execution.\"\"\"\n    # Check in-memory storage first\n    if execution_id in ExecutionService.executions:\n        return ExecutionService.executions[execution_id]\n\n    # If not in memory, check database using repository\n    execution_repo = ExecutionRepository(db)\n\n    try:\n        run = await execution_repo.get_execution_by_job_id(job_id=execution_id)\n\n        if not run:\n            return None\n\n        return {\n            \"execution_id\": execution_id,\n            \"status\": run.status,\n            \"created_at\": run.created_at,\n            \"result\": run.result,\n            \"run_name\": run.run_name,\n            \"error\": run.error\n        }\n    except Exception as e:\n        logger.error(f\"Error getting execution status: {str(e)}\")\n        return None\n</code></pre>"},{"location":"REPOSITORY_PATTERN/#consolidation-benefits","title":"Consolidation Benefits","text":"<p>By consolidating the <code>ExecutionHistoryRepository</code> into a properly named <code>ExecutionRepository</code>, we achieve several benefits:</p> <ol> <li>Semantic Clarity: The name better represents its purpose</li> <li>Reduced Redundancy: Eliminates duplicate code across multiple repositories</li> <li>Improved Maintainability: All execution data access is in one place</li> <li>Consistent Interface: Methods follow a consistent naming convention</li> <li>Focused Responsibility: Each repository handles one domain entity</li> </ol>"},{"location":"REPOSITORY_PATTERN/#best-practices","title":"Best Practices","text":"<p>When implementing repositories, follow these guidelines:</p> <ol> <li>Keep Repositories Focused: Each repository should handle a single domain entity</li> <li>Use Descriptive Method Names: Names should clearly communicate the operation purpose</li> <li>Return Domain Entities: Not DTOs or raw data structures</li> <li>Handle Exceptions Appropriately: Don't expose database errors to callers</li> <li>Use Typing: Add proper type hints for better IDE support and code clarity</li> <li>Document Methods: Add docstrings to explain method purpose and parameters</li> <li>Follow Naming Conventions: Be consistent with method naming (e.g., <code>get_by_*</code>, <code>find_*</code>)</li> <li>Keep Query Logic in Repositories: Don't leak query details to services</li> </ol>"},{"location":"REPOSITORY_PATTERN/#migration-path","title":"Migration Path","text":"<p>When refactoring repositories, follow this process:</p> <ol> <li>Create the new repository with appropriate naming</li> <li>Implement all required methods</li> <li>Update service classes to use the new repository</li> <li>Change dependencies in API routes if necessary</li> <li>Test thoroughly to ensure functionality is preserved</li> <li>Delete the old repository once all references are updated</li> </ol>"},{"location":"REPOSITORY_PATTERN/#conclusion","title":"Conclusion","text":"<p>The Repository Pattern is a powerful abstraction that improves code organization, testability, and maintainability. Our implementation with <code>ExecutionRepository</code> demonstrates how to properly structure data access in a modern Python application with clear separation of concerns. </p>"},{"location":"SCHEMAS/","title":"Pydantic Schemas Guide","text":"<p>This document provides comprehensive documentation for Pydantic schemas in our backend architecture.</p>"},{"location":"SCHEMAS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Structure and Conventions</li> <li>Schema Types</li> <li>Field Validation</li> <li>Schema Composition</li> <li>Model Configuration</li> <li>Integration with SQLAlchemy</li> <li>Data Conversion</li> <li>Best Practices</li> <li>Examples</li> </ul>"},{"location":"SCHEMAS/#overview","title":"Overview","text":"<p>Pydantic schemas are Python classes that provide data validation, serialization, and documentation. In our architecture, they serve several critical purposes:</p> <ul> <li>API Input Validation: Validate incoming request data</li> <li>Response Serialization: Format outgoing response data</li> <li>Type Checking: Ensure type safety at runtime</li> <li>Documentation: Generate OpenAPI docs for the API</li> <li>Data Transformation: Convert between API and database formats</li> </ul> <p>Schemas are stored in the <code>src/schemas/</code> directory, with schemas for each domain typically in their own file.</p>"},{"location":"SCHEMAS/#structure-and-conventions","title":"Structure and Conventions","text":""},{"location":"SCHEMAS/#file-organization","title":"File Organization","text":"<pre><code>src/schemas/\n\u251c\u2500\u2500 __init__.py         # Exposes schemas for easier imports\n\u251c\u2500\u2500 item.py             # Schemas related to items\n\u251c\u2500\u2500 user.py             # Schemas related to users\n\u2514\u2500\u2500 other_domain.py     # Other domain-specific schemas\n</code></pre>"},{"location":"SCHEMAS/#naming-conventions","title":"Naming Conventions","text":"<p>We follow consistent naming patterns for different schema types:</p> <ul> <li>Base schemas: <code>Base{Resource}</code> (e.g., <code>BaseItem</code>)</li> <li>Creation schemas: <code>{Resource}Create</code> (e.g., <code>ItemCreate</code>)</li> <li>Update schemas: <code>{Resource}Update</code> (e.g., <code>ItemUpdate</code>)</li> <li>Response schemas: <code>{Resource}</code> (e.g., <code>Item</code>)</li> <li>Internal schemas: <code>{Resource}InDB</code> (e.g., <code>ItemInDB</code>)</li> </ul>"},{"location":"SCHEMAS/#schema-types","title":"Schema Types","text":"<p>In our architecture, we use different schema types for different purposes:</p>"},{"location":"SCHEMAS/#base-schemas","title":"Base Schemas","text":"<p>Base schemas define common attributes shared by multiple schemas:</p> <pre><code>class BaseItem(BaseModel):\n    \"\"\"Base schema with common item attributes.\"\"\"\n    name: str = Field(..., min_length=1, max_length=100)\n    description: Optional[str] = Field(None, max_length=1000)\n    price: float = Field(..., gt=0)\n    is_active: bool = True\n</code></pre>"},{"location":"SCHEMAS/#create-schemas","title":"Create Schemas","text":"<p>Used to validate data for creating new resources:</p> <pre><code>class ItemCreate(BaseItem):\n    \"\"\"Schema for creating a new item.\"\"\"\n    # Inherits all fields from BaseItem\n    # May add additional fields specific to creation\n    category_id: int\n</code></pre>"},{"location":"SCHEMAS/#update-schemas","title":"Update Schemas","text":"<p>Used to validate data for updating existing resources, usually with all fields optional:</p> <pre><code>class ItemUpdate(BaseModel):\n    \"\"\"Schema for updating an existing item.\"\"\"\n    name: Optional[str] = Field(None, min_length=1, max_length=100)\n    description: Optional[str] = Field(None, max_length=1000)\n    price: Optional[float] = Field(None, gt=0)\n    is_active: Optional[bool] = None\n    category_id: Optional[int] = None\n</code></pre>"},{"location":"SCHEMAS/#response-schemas","title":"Response Schemas","text":"<p>Used for API responses, including all fields that should be returned to clients:</p> <pre><code>class Item(BaseItem):\n    \"\"\"Schema for item responses.\"\"\"\n    id: int\n    created_at: datetime\n    updated_at: datetime\n    category: Optional[\"Category\"] = None\n\n    class Config:\n        from_attributes = True\n</code></pre>"},{"location":"SCHEMAS/#internal-schemas","title":"Internal Schemas","text":"<p>Used for internal data processing, may include fields not exposed to API:</p> <pre><code>class ItemInDB(Item):\n    \"\"\"Schema for internal use with additional fields.\"\"\"\n    deleted: bool = False\n    version: int = 1\n    internal_notes: Optional[str] = None\n</code></pre>"},{"location":"SCHEMAS/#field-validation","title":"Field Validation","text":"<p>Pydantic provides powerful field validation capabilities:</p>"},{"location":"SCHEMAS/#basic-validators","title":"Basic Validators","text":"<pre><code>class UserCreate(BaseModel):\n    username: str = Field(..., min_length=3, max_length=50, regex=\"^[a-zA-Z0-9_-]+$\")\n    email: EmailStr\n    password: str = Field(..., min_length=8)\n    age: int = Field(..., ge=18)  # Must be greater than or equal to 18\n    website: Optional[HttpUrl] = None\n</code></pre>"},{"location":"SCHEMAS/#custom-validators","title":"Custom Validators","text":"<p>Use <code>@field_validator</code> for custom field validations:</p> <pre><code>from pydantic import BaseModel, field_validator\n\nclass UserCreate(BaseModel):\n    username: str\n    password: str\n    password_confirm: str\n\n    @field_validator(\"username\")\n    @classmethod\n    def username_alphanumeric(cls, v):\n        if not v.isalnum():\n            raise ValueError(\"Username must be alphanumeric\")\n        return v\n\n    @field_validator(\"password_confirm\")\n    @classmethod\n    def passwords_match(cls, v, info):\n        if \"password\" in info.data and v != info.data[\"password\"]:\n            raise ValueError(\"Passwords do not match\")\n        return v\n</code></pre>"},{"location":"SCHEMAS/#model-validators","title":"Model Validators","text":"<p>Use <code>@model_validator</code> for validations across multiple fields:</p> <pre><code>from pydantic import BaseModel, model_validator\n\nclass Order(BaseModel):\n    items: List[OrderItem]\n    discount: float = 0.0\n    tax_rate: float\n\n    @model_validator(mode='after')\n    def check_total_with_discount(self):\n        total = sum(item.price * item.quantity for item in self.items)\n        if self.discount &gt; total:\n            raise ValueError(\"Discount cannot be greater than total\")\n        return self\n</code></pre>"},{"location":"SCHEMAS/#schema-composition","title":"Schema Composition","text":"<p>Schemas can be composed and nested to represent complex structures:</p>"},{"location":"SCHEMAS/#nested-schemas","title":"Nested Schemas","text":"<pre><code>class Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: str\n    country: str\n\nclass UserCreate(BaseModel):\n    username: str\n    email: EmailStr\n    password: str\n    address: Address  # Nested schema\n</code></pre>"},{"location":"SCHEMAS/#list-fields","title":"List Fields","text":"<pre><code>class TagCreate(BaseModel):\n    name: str\n\nclass PostCreate(BaseModel):\n    title: str\n    content: str\n    tags: List[TagCreate]  # List of nested schemas\n</code></pre>"},{"location":"SCHEMAS/#union-types","title":"Union Types","text":"<pre><code>class TextContent(BaseModel):\n    type: Literal[\"text\"]\n    text: str\n\nclass ImageContent(BaseModel):\n    type: Literal[\"image\"]\n    url: HttpUrl\n    caption: Optional[str] = None\n\nclass PostContent(BaseModel):\n    title: str\n    content: Union[TextContent, ImageContent]  # Can be either type\n</code></pre>"},{"location":"SCHEMAS/#model-configuration","title":"Model Configuration","text":"<p>Customize Pydantic behavior with model configuration:</p> <pre><code>class User(BaseModel):\n    id: int\n    username: str\n    email: str\n    created_at: datetime\n\n    class Config:\n        # Allow conversion from ORM models\n        from_attributes = True\n\n        # Use ISO format for dates in JSON\n        json_encoders = {\n            datetime: lambda dt: dt.isoformat()\n        }\n\n        # Validate assignment to attributes\n        validate_assignment = True\n\n        # Allow \"extra\" fields that aren't specified\n        extra = \"ignore\"\n</code></pre>"},{"location":"SCHEMAS/#integration-with-sqlalchemy","title":"Integration with SQLAlchemy","text":"<p>Pydantic integrates with SQLAlchemy models in our architecture:</p>"},{"location":"SCHEMAS/#converting-sqlalchemy-models-to-pydantic-schema","title":"Converting SQLAlchemy Models to Pydantic Schema","text":"<pre><code># With SQLAlchemy model instance \"db_item\"\nitem_schema = Item.model_validate(db_item)\n</code></pre>"},{"location":"SCHEMAS/#configuration-for-sqlalchemy-integration","title":"Configuration for SQLAlchemy Integration","text":"<pre><code>class Item(BaseModel):\n    id: int\n    name: str\n    description: Optional[str] = None\n    price: float\n\n    class Config:\n        from_attributes = True  # Enable ORM mode for SQLAlchemy conversion\n</code></pre>"},{"location":"SCHEMAS/#data-conversion","title":"Data Conversion","text":"<p>Schemas provide methods for data conversion:</p>"},{"location":"SCHEMAS/#to-dictionary","title":"To Dictionary","text":"<pre><code>item = Item(id=1, name=\"Example\", price=9.99)\nitem_dict = item.model_dump()  # {\"id\": 1, \"name\": \"Example\", \"price\": 9.99}\n</code></pre>"},{"location":"SCHEMAS/#to-json","title":"To JSON","text":"<pre><code>item_json = item.model_dump_json()  # '{\"id\": 1, \"name\": \"Example\", \"price\": 9.99}'\n</code></pre>"},{"location":"SCHEMAS/#includeexclude-fields","title":"Include/Exclude Fields","text":"<pre><code># Only include certain fields\nitem_dict = item.model_dump(include={\"name\", \"price\"})\n\n# Exclude certain fields\nitem_dict = item.model_dump(exclude={\"description\"})\n</code></pre>"},{"location":"SCHEMAS/#nested-includeexclude","title":"Nested Include/Exclude","text":"<pre><code>user_with_items = User(\n    id=1, \n    username=\"user1\", \n    items=[Item(id=1, name=\"Item 1\"), Item(id=2, name=\"Item 2\")]\n)\n\n# Include nested fields\nuser_dict = user_with_items.model_dump(include={\n    \"id\": True,\n    \"username\": True,\n    \"items\": {\"id\": True, \"name\": True}\n})\n</code></pre>"},{"location":"SCHEMAS/#best-practices","title":"Best Practices","text":""},{"location":"SCHEMAS/#1-define-clear-schema-types","title":"1. Define Clear Schema Types","text":"<p>Create distinct schemas for different operations:</p> <pre><code># Good: Clear separation of concerns\nclass ItemCreate(BaseModel):\n    # Fields for creating an item\n\nclass ItemUpdate(BaseModel):\n    # Fields for updating an item\n\nclass Item(BaseModel):\n    # Fields for returning an item in responses\n\n# Avoid: One schema for everything\nclass Item(BaseModel):\n    # Mixing create, update, and response fields\n</code></pre>"},{"location":"SCHEMAS/#2-use-field-validation","title":"2. Use Field Validation","text":"<p>Always validate input data with appropriate constraints:</p> <pre><code># Good: Proper validation\nclass UserCreate(BaseModel):\n    username: str = Field(..., min_length=3, max_length=50)\n    email: EmailStr  # Validates email format\n    age: int = Field(..., ge=18)  # Must be 18 or older\n\n# Avoid: Missing validation\nclass UserCreate(BaseModel):\n    username: str\n    email: str  # No format validation\n    age: int  # No range check\n</code></pre>"},{"location":"SCHEMAS/#3-make-update-schemas-optional","title":"3. Make Update Schemas Optional","text":"<p>Use <code>Optional</code> for all fields in update schemas:</p> <pre><code># Good: All fields optional for partial updates\nclass ItemUpdate(BaseModel):\n    name: Optional[str] = None\n    description: Optional[str] = None\n    price: Optional[float] = None\n\n# Avoid: Required fields in update schema\nclass ItemUpdate(BaseModel):\n    name: str  # Required field prevents partial updates\n    description: Optional[str] = None\n    price: float  # Required field prevents partial updates\n</code></pre>"},{"location":"SCHEMAS/#4-use-inheritance-for-common-fields","title":"4. Use Inheritance for Common Fields","text":"<p>Inherit from base schemas to avoid duplication:</p> <pre><code># Good: Using inheritance\nclass BaseItem(BaseModel):\n    name: str\n    description: Optional[str] = None\n    price: float\n\nclass ItemCreate(BaseItem):\n    category_id: int\n\nclass Item(BaseItem):\n    id: int\n    created_at: datetime\n\n# Avoid: Duplicating fields\nclass ItemCreate(BaseModel):\n    name: str  # Duplicated\n    description: Optional[str] = None  # Duplicated\n    price: float  # Duplicated\n    category_id: int\n\nclass Item(BaseModel):\n    id: int\n    name: str  # Duplicated\n    description: Optional[str] = None  # Duplicated\n    price: float  # Duplicated\n    created_at: datetime\n</code></pre>"},{"location":"SCHEMAS/#5-document-your-schemas","title":"5. Document Your Schemas","text":"<p>Add docstrings and field descriptions:</p> <pre><code>class UserCreate(BaseModel):\n    \"\"\"\n    Schema for creating a new user.\n\n    Attributes:\n        username: User's unique handle, alphanumeric only\n        email: User's email address, must be valid format\n        password: User's password, minimum 8 characters\n    \"\"\"\n    username: str = Field(\n        ..., \n        min_length=3, \n        max_length=50, \n        description=\"User's unique handle, alphanumeric only\"\n    )\n    email: EmailStr = Field(..., description=\"User's email address\")\n    password: str = Field(\n        ..., \n        min_length=8, \n        description=\"User's password, minimum 8 characters\"\n    )\n</code></pre>"},{"location":"SCHEMAS/#6-use-strict-type-validation","title":"6. Use Strict Type Validation","text":"<p>Enable strict type validation to catch type errors early:</p> <pre><code>class Config:\n    # Configuration for all schemas\n    model_config = {\n        \"strict\": True  # Enforce strict type checking\n    }\n</code></pre>"},{"location":"SCHEMAS/#7-keep-presentation-logic-out-of-schemas","title":"7. Keep Presentation Logic Out of Schemas","text":"<p>Avoid adding business logic to schemas - keep them focused on data validation:</p> <pre><code># Good: Schema focused on validation\nclass OrderCreate(BaseModel):\n    items: List[OrderItemCreate]\n    shipping_address_id: int\n\n# Avoid: Adding business logic in schemas\nclass OrderCreate(BaseModel):\n    items: List[OrderItemCreate]\n    shipping_address_id: int\n\n    def calculate_total(self):\n        # Business logic should be in service layer, not in schema\n        return sum(item.price * item.quantity for item in self.items)\n</code></pre>"},{"location":"SCHEMAS/#examples","title":"Examples","text":""},{"location":"SCHEMAS/#example-basic-schema-hierarchy","title":"Example: Basic Schema Hierarchy","text":"<pre><code>from datetime import datetime\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, EmailStr, Field, HttpUrl\n\n\nclass BaseUser(BaseModel):\n    \"\"\"Base user data shared across schemas.\"\"\"\n    email: EmailStr\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None\n    is_active: bool = True\n\n\nclass UserCreate(BaseUser):\n    \"\"\"Schema for creating a new user.\"\"\"\n    password: str = Field(..., min_length=8)\n    password_confirm: str = Field(..., min_length=8)\n\n    @field_validator(\"password_confirm\")\n    @classmethod\n    def passwords_match(cls, v, info):\n        if \"password\" in info.data and v != info.data[\"password\"]:\n            raise ValueError(\"Passwords do not match\")\n        return v\n\n\nclass UserUpdate(BaseModel):\n    \"\"\"Schema for updating an existing user.\"\"\"\n    email: Optional[EmailStr] = None\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None\n    is_active: Optional[bool] = None\n    password: Optional[str] = Field(None, min_length=8)\n\n\nclass User(BaseUser):\n    \"\"\"Schema for user responses.\"\"\"\n    id: int\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        from_attributes = True\n</code></pre>"},{"location":"SCHEMAS/#example-nested-schema-with-relationships","title":"Example: Nested Schema with Relationships","text":"<pre><code>from datetime import datetime\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass CategoryBase(BaseModel):\n    \"\"\"Base category data.\"\"\"\n    name: str = Field(..., min_length=1, max_length=50)\n    description: Optional[str] = None\n\n\nclass CategoryCreate(CategoryBase):\n    \"\"\"Schema for creating a new category.\"\"\"\n    pass\n\n\nclass Category(CategoryBase):\n    \"\"\"Schema for category responses.\"\"\"\n    id: int\n    created_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\nclass ItemBase(BaseModel):\n    \"\"\"Base item data.\"\"\"\n    name: str = Field(..., min_length=1, max_length=100)\n    description: Optional[str] = None\n    price: float = Field(..., gt=0)\n    is_active: bool = True\n\n\nclass ItemCreate(ItemBase):\n    \"\"\"Schema for creating a new item.\"\"\"\n    category_id: int\n\n\nclass Item(ItemBase):\n    \"\"\"Schema for item responses.\"\"\"\n    id: int\n    category_id: int\n    category: Optional[Category] = None\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\nclass CategoryWithItems(Category):\n    \"\"\"Category with nested items.\"\"\"\n    items: List[Item] = []\n</code></pre>"},{"location":"SCHEMAS/#example-complex-validation-and-custom-types","title":"Example: Complex Validation and Custom Types","text":"<pre><code>from datetime import date\nfrom enum import Enum\nfrom typing import List, Optional, Union\n\nfrom pydantic import BaseModel, EmailStr, Field, model_validator\n\n\nclass SubscriptionType(str, Enum):\n    FREE = \"free\"\n    BASIC = \"basic\"\n    PREMIUM = \"premium\"\n    ENTERPRISE = \"enterprise\"\n\n\nclass PaymentMethod(BaseModel):\n    \"\"\"Payment method details.\"\"\"\n    type: str = Field(..., regex=\"^(credit_card|paypal|bank_transfer)$\")\n    last_four: Optional[str] = Field(None, regex=\"^[0-9]{4}$\")\n    expiry_date: Optional[date] = None\n    is_default: bool = False\n\n\nclass AddressCreate(BaseModel):\n    \"\"\"Address creation schema.\"\"\"\n    street: str\n    city: str\n    state: str\n    postal_code: str\n    country: str = Field(..., min_length=2, max_length=2)  # ISO country code\n\n\nclass SubscriptionCreate(BaseModel):\n    \"\"\"Subscription creation schema.\"\"\"\n    type: SubscriptionType\n    payment_method_id: Optional[int] = None\n    address_id: Optional[int] = None\n    coupon_code: Optional[str] = None\n\n    @model_validator(mode='after')\n    def check_payment_method_for_paid_plans(self):\n        if self.type != SubscriptionType.FREE and not self.payment_method_id:\n            raise ValueError(\n                \"Payment method is required for non-free subscription types\"\n            )\n        return self\n</code></pre>"},{"location":"SCHEMAS/#example-schema-with-complex-computed-fields","title":"Example: Schema with Complex Computed Fields","text":"<pre><code>from datetime import datetime\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, computed_field\n\n\nclass OrderItem(BaseModel):\n    \"\"\"Order item within an order.\"\"\"\n    product_id: int\n    product_name: str\n    quantity: int = Field(..., gt=0)\n    unit_price: float = Field(..., gt=0)\n\n    @computed_field\n    def subtotal(self) -&gt; float:\n        return self.quantity * self.unit_price\n\n\nclass OrderCreate(BaseModel):\n    \"\"\"Order creation schema.\"\"\"\n    user_id: int\n    items: List[OrderItem]\n    shipping_address_id: int\n    billing_address_id: Optional[int] = None\n    coupon_code: Optional[str] = None\n\n\nclass Order(BaseModel):\n    \"\"\"Order response schema.\"\"\"\n    id: int\n    user_id: int\n    items: List[OrderItem]\n    shipping_address_id: int\n    billing_address_id: Optional[int] = None\n    status: str\n    created_at: datetime\n\n    @computed_field\n    def item_count(self) -&gt; int:\n        return sum(item.quantity for item in self.items)\n\n    @computed_field\n    def subtotal(self) -&gt; float:\n        return sum(item.subtotal for item in self.items)\n\n    @computed_field\n    def total(self) -&gt; float:\n        # Could include tax, shipping, etc.\n        return self.subtotal\n\n    class Config:\n        from_attributes = True\n</code></pre>"},{"location":"SCHEMAS_STRUCTURE/","title":"Schemas Folder Structure","text":"<p>This document provides a detailed guide to the organization and structure of the schemas folder in our FastAPI backend.</p>"},{"location":"SCHEMAS_STRUCTURE/#overview","title":"Overview","text":"<p>The <code>src/schemas/</code> directory contains all Pydantic models used for data validation, serialization, and documentation. These schemas are organized by domain and follow a consistent pattern to ensure maintainability and scalability.</p>"},{"location":"SCHEMAS_STRUCTURE/#directory-structure","title":"Directory Structure","text":"<pre><code>src/schemas/\n\u251c\u2500\u2500 __init__.py                 # Re-exports important schemas for easier imports\n\u251c\u2500\u2500 base.py                     # Common base schemas and mixins\n\u251c\u2500\u2500 item/                       # Item domain schemas\n\u2502   \u251c\u2500\u2500 __init__.py             # Re-exports from this domain\n\u2502   \u251c\u2500\u2500 item.py                 # Main item schemas\n\u2502   \u2514\u2500\u2500 item_category.py        # Related item category schemas\n\u251c\u2500\u2500 user/                       # User domain schemas\n\u2502   \u251c\u2500\u2500 __init__.py             # Re-exports from this domain\n\u2502   \u251c\u2500\u2500 user.py                 # Main user schemas\n\u2502   \u251c\u2500\u2500 profile.py              # User profile schemas\n\u2502   \u2514\u2500\u2500 auth.py                 # Authentication-related schemas\n\u251c\u2500\u2500 order/                      # Order domain schemas\n\u2502   \u251c\u2500\u2500 __init__.py             # Re-exports from this domain\n\u2502   \u251c\u2500\u2500 order.py                # Main order schemas\n\u2502   \u2514\u2500\u2500 order_item.py           # Order item schemas\n\u2514\u2500\u2500 common/                     # Shared/common schemas\n    \u251c\u2500\u2500 __init__.py             # Re-exports common schemas\n    \u251c\u2500\u2500 pagination.py           # Pagination schemas\n    \u251c\u2500\u2500 responses.py            # Common response schemas\n    \u2514\u2500\u2500 filters.py              # Query filter schemas\n</code></pre>"},{"location":"SCHEMAS_STRUCTURE/#organization-principles","title":"Organization Principles","text":""},{"location":"SCHEMAS_STRUCTURE/#domain-based-organization","title":"Domain-Based Organization","text":"<p>Schemas are organized by domain (business entity) to maintain separation of concerns:</p> <ul> <li>Each major domain has its own subdirectory (<code>item/</code>, <code>user/</code>, <code>order/</code>, etc.)</li> <li>Related schemas within a domain are grouped in the same file or closely related files</li> <li>Common/shared schemas are kept in the <code>common/</code> directory</li> </ul>"},{"location":"SCHEMAS_STRUCTURE/#re-export-pattern","title":"Re-export Pattern","text":"<p>To make imports cleaner throughout the application, we use the re-export pattern:</p> <pre><code># src/schemas/__init__.py\nfrom src.schemas.item import Item, ItemCreate, ItemUpdate\nfrom src.schemas.user import User, UserCreate, UserUpdate\nfrom src.schemas.common import PaginatedResponse, ErrorResponse\n\n# This allows imports like:\n# from src.schemas import User, ItemCreate\n# Instead of:\n# from src.schemas.user import User\n# from src.schemas.item import ItemCreate\n</code></pre>"},{"location":"SCHEMAS_STRUCTURE/#file-naming-conventions","title":"File Naming Conventions","text":"<ul> <li>Use singular nouns for schema files (<code>item.py</code>, not <code>items.py</code>)</li> <li>Use snake_case for filenames</li> <li>Name files after the primary entity they represent</li> <li>Use descriptive suffixes for related schemas (e.g., <code>item_category.py</code>)</li> </ul>"},{"location":"SCHEMAS_STRUCTURE/#schema-organization-within-files","title":"Schema Organization Within Files","text":"<p>Each schema file follows a consistent organization pattern:</p> <pre><code># Imports\nfrom datetime import datetime\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\n# Base schemas\nclass BaseItem(BaseModel):\n    \"\"\"Base schema with common item attributes.\"\"\"\n    name: str\n    description: Optional[str] = None\n\n# Input schemas\nclass ItemCreate(BaseItem):\n    \"\"\"Schema for creating a new item.\"\"\"\n    category_id: int\n\nclass ItemUpdate(BaseModel):\n    \"\"\"Schema for updating an existing item.\"\"\"\n    name: Optional[str] = None\n    description: Optional[str] = None\n    category_id: Optional[int] = None\n\n# Response schemas\nclass Item(BaseItem):\n    \"\"\"Schema for item responses.\"\"\"\n    id: int\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        from_attributes = True\n</code></pre>"},{"location":"SCHEMAS_STRUCTURE/#common-schema-types-in-each-domain","title":"Common Schema Types in Each Domain","text":"<p>Each domain typically includes these schema types:</p> <ol> <li>Base Schemas: Common attributes shared across schemas (e.g., <code>BaseItem</code>)</li> <li>Create Schemas: Validation for resource creation (e.g., <code>ItemCreate</code>)</li> <li>Update Schemas: Validation for resource updates (e.g., <code>ItemUpdate</code>)</li> <li>Response Schemas: Shapes of API responses (e.g., <code>Item</code>)</li> <li>Query Schemas: Parameters for filtering/querying (e.g., <code>ItemQuery</code>)</li> </ol>"},{"location":"SCHEMAS_STRUCTURE/#common-folder","title":"Common Folder","text":"<p>The <code>common/</code> folder contains schemas that are used across multiple domains:</p> <ul> <li>Pagination: Schemas for paginated responses</li> <li>Responses: Standard response wrappers (success, error)</li> <li>Filters: Common query parameter schemas</li> </ul> <p>Example: <pre><code># src/schemas/common/pagination.py\nfrom typing import Generic, List, TypeVar\nfrom pydantic import BaseModel\n\nT = TypeVar('T')\n\nclass PaginationParams(BaseModel):\n    \"\"\"Query parameters for pagination.\"\"\"\n    page: int = 1\n    limit: int = 10\n\nclass PaginatedResponse(BaseModel, Generic[T]):\n    \"\"\"A paginated response containing items of type T.\"\"\"\n    items: List[T]\n    total: int\n    page: int\n    limit: int\n    pages: int\n</code></pre></p>"},{"location":"SCHEMAS_STRUCTURE/#best-practices-for-schema-organization","title":"Best Practices for Schema Organization","text":"<ol> <li>Keep related schemas together: Group schemas that are commonly used together</li> <li>Don't over-nest: Avoid creating deep directory hierarchies</li> <li>Be consistent with naming: Follow established naming conventions</li> <li>Provide re-exports: Make imports easier with proper re-exports</li> <li>Document relationships: Comment on how schemas relate to each other</li> <li>Avoid circular imports: Structure files to prevent circular dependencies</li> </ol>"},{"location":"SCHEMAS_STRUCTURE/#integration-with-api-routes","title":"Integration with API Routes","text":"<p>The schema folder structure should mirror the API route structure where possible:</p> <ul> <li>For <code>/api/v1/items</code> endpoints, use schemas from <code>schemas/item/</code></li> <li>For <code>/api/v1/users</code> endpoints, use schemas from <code>schemas/user/</code></li> </ul> <p>This makes it easier to locate the relevant schemas for each endpoint.</p>"},{"location":"SCHEMAS_STRUCTURE/#schema-evolution-and-versioning","title":"Schema Evolution and Versioning","text":"<p>When APIs evolve, schemas may need versioning:</p> <ul> <li>Keep backwards-compatible changes in existing schemas when possible</li> <li>For breaking changes, consider creating versioned schemas (e.g., <code>item_v2.py</code>)</li> <li>Document deprecated schemas and fields with appropriate warnings</li> </ul>"},{"location":"SCHEMAS_STRUCTURE/#conclusion","title":"Conclusion","text":"<p>Following these organization principles makes our schema structure maintainable, scalable, and easy to navigate. The domain-driven organization ensures that related schemas are grouped together logically, while the consistent file and schema naming makes the codebase more predictable and easier to work with. </p>"},{"location":"agents/","title":"Agents Component Documentation","text":"<p>This document provides an overview of the Agents components in the CrewAI Manager frontend application.</p>"},{"location":"agents/#overview","title":"Overview","text":"<p>The Agents components are responsible for creating, managing, editing, and visualizing agents within the CrewAI system. They handle agent configuration, tool selection, LLM model selection, knowledge source management, and more.</p>"},{"location":"agents/#components-structure","title":"Components Structure","text":""},{"location":"agents/#agentnode","title":"AgentNode","text":"<p><code>AgentNode.tsx</code> implements a visual node component used in the workflow editor to represent an agent within the workflow.</p> <p>Key Features: - Displays agent information (name, role, goal) - Provides visual feedback when an agent is active or completed - Handles agent deletion and editing - Supports drag and drop interactions - Manages connections to other nodes (like tasks)</p>"},{"location":"agents/#agentform","title":"AgentForm","text":"<p><code>AgentForm.tsx</code> provides a comprehensive form for creating and editing agents.</p> <p>Key Features: - Input fields for basic agent properties (name, role, goal, backstory) - LLM model selection - Tools selection - Configuration for agent parameters (max iterations, RPM, execution time) - Memory and delegation settings - Knowledge source management - System/prompt/response template customization - AI-assisted template generation</p>"},{"location":"agents/#agentdialog","title":"AgentDialog","text":"<p><code>AgentDialog.tsx</code> implements a dialog for managing saved agents.</p> <p>Key Features: - Lists all saved agents - Allows selection of agents to add to the workflow - Provides actions to delete agents - Button to create new agents</p>"},{"location":"agents/#savedagents","title":"SavedAgents","text":"<p><code>SavedAgents.tsx</code> displays a table of all saved agents with their properties and actions to edit or delete them.</p> <p>Key Features: - Tabular view of agents with their properties - Edit and delete functionality - Display of agent features (like memory)</p>"},{"location":"agents/#agentgenerationdialog","title":"AgentGenerationDialog","text":"<p><code>AgentGenerationDialog.tsx</code> provides an AI-assisted agent generation interface.</p> <p>Key Features: - Text prompt input for describing the desired agent - Model selection for generation - Tool selection for the generated agent - Error handling and feedback</p>"},{"location":"agents/#toolselectiondialog","title":"ToolSelectionDialog","text":"<p><code>ToolSelectionDialog.tsx</code> implements a dialog for selecting tools to assign to agents or tasks.</p> <p>Key Features: - Lists available tools with descriptions - Search functionality for finding tools - Multi-selection capabilities - Target selection (which agents/tasks to apply tools to)</p>"},{"location":"agents/#llmselectiondialog","title":"LLMSelectionDialog","text":"<p><code>LLMSelectionDialog.tsx</code> provides a dialog for selecting an LLM (Language Learning Model) for agents.</p> <p>Key Features: - Lists available models - Shows model provider information - Handles model selection and application</p>"},{"location":"agents/#maxrpmselectiondialog","title":"MaxRPMSelectionDialog","text":"<p><code>MaxRPMSelectionDialog.tsx</code> allows setting the maximum RPM (Requests Per Minute) for agents.</p> <p>Key Features: - Predefined RPM options with descriptions - Applies selected RPM to agents</p>"},{"location":"agents/#knowledgesourcessection","title":"KnowledgeSourcesSection","text":"<p><code>KnowledgeSourcesSection.tsx</code> manages knowledge sources for agents.</p> <p>Key Features: - Supports multiple knowledge source types (text, file, URL, etc.) - File upload functionality - Configuration of chunking parameters - File existence verification</p>"},{"location":"agents/#data-flow","title":"Data Flow","text":"<ol> <li>Agents are created using the <code>AgentForm</code> component, either from scratch or using AI generation via <code>AgentGenerationDialog</code></li> <li>Saved agents can be viewed and managed in <code>SavedAgents</code> or selected for use in workflows via <code>AgentDialog</code></li> <li>Agents are visualized in the workflow using <code>AgentNode</code> components</li> <li>Agent properties like tools, LLM model, and max RPM can be modified through dedicated dialogs</li> </ol>"},{"location":"agents/#key-interfaces","title":"Key Interfaces","text":"<p>The Agents components use several key interfaces:</p> <ul> <li>Agent: Represents an agent with properties like name, role, goal, backstory, and configurations</li> <li>Tool: Represents a tool that can be assigned to agents</li> <li>KnowledgeSource: Represents a source of knowledge for an agent (text, file, URL)</li> <li>Models: Represents available LLM models that can be used by agents</li> </ul>"},{"location":"agents/#services-integration","title":"Services Integration","text":"<p>The Agents components integrate with several services:</p> <ul> <li>AgentService: For CRUD operations on agents</li> <li>ToolService: For retrieving available tools</li> <li>ModelService: For retrieving available LLM models</li> <li>GenerateService: For AI-assisted agent and template generation</li> <li>UploadService: For handling file uploads for knowledge sources</li> </ul>"},{"location":"agents/#best-practices","title":"Best Practices","text":"<p>When working with the Agents components:</p> <ol> <li>Always use the appropriate dialog for specific configurations (tools, LLM, RPM)</li> <li>Leverage AI generation for quick agent creation</li> <li>Ensure proper error handling, especially for file uploads and API operations</li> <li>Use the KnowledgeSourcesSection for managing agent knowledge sources</li> <li>Keep UI consistency with the rest of the application using MUI components </li> </ol>"},{"location":"crew/","title":"Crew","text":"<p>sequenceDiagram     participant UI as Frontend UI     participant CrewStore as CrewExecutionStore     participant JobService as JobExecutionService     participant ApiClient as API Client     participant ApiRouter as API Router     participant ExecService as ExecutionService     participant CrewExecService as CrewAIExecutionService     participant StatusService as ExecutionStatusService     participant Engine as CrewAIEngineService     participant ToolFactory as ToolFactory     participant ToolService as ToolService     participant ApiKeys as ApiKeysService     participant CrewPrep as CrewPreparation     participant Database as Database     participant CrewAI as CrewAI Library     participant LLM as LLM Manager</p> <pre><code>Note over UI,LLM: Crew Execution Process (Not Flow)\n\nUI-&gt;&gt;CrewStore: handleRunClick('crew')\nCrewStore-&gt;&gt;CrewStore: executeCrew(nodes, edges)\nCrewStore-&gt;&gt;JobService: executeJob(nodes, edges, planningEnabled, selectedModel, 'crew', additionalInputs)\nJobService-&gt;&gt;ApiClient: POST /executions\nApiClient-&gt;&gt;ApiRouter: execute_flow(request)\nApiRouter-&gt;&gt;ExecService: create_execution(config, background_tasks)\n\nExecService-&gt;&gt;Database: create execution record\nDatabase--&gt;&gt;ExecService: return execution details\n\nExecService-&gt;&gt;StatusService: update_status(execution_id, 'pending', 'Preparing execution')\n\nExecService-&gt;&gt;ExecService: run_crew_execution(execution_id, config, 'crew')\nExecService-&gt;&gt;CrewExecService: run_crew_execution(execution_id, config)\n\nCrewExecService-&gt;&gt;CrewExecService: Create asyncio task for prepare_and_run_crew\nCrewExecService--&gt;&gt;ExecService: Return immediate response with execution_id\nExecService--&gt;&gt;ApiRouter: Return execution response\nApiRouter--&gt;&gt;ApiClient: Return execution response\nApiClient--&gt;&gt;JobService: Return response with job_id\nJobService--&gt;&gt;CrewStore: Return execution response\nCrewStore--&gt;&gt;UI: Update with job_id and status\n\nNote over UI,Database: Asynchronous Execution Starts\n\nCrewExecService-&gt;&gt;StatusService: update_status(execution_id, 'preparing', 'Preparing crew execution')\n\nCrewExecService-&gt;&gt;Engine: _prepare_engine(config)\nEngine-&gt;&gt;Engine: initialize(model)\nEngine--&gt;&gt;CrewExecService: Return initialized engine\n\nCrewExecService-&gt;&gt;StatusService: update_status(execution_id, 'running', 'Running crew execution')\n\nCrewExecService-&gt;&gt;Engine: run_execution(execution_id, config)\n\nEngine-&gt;&gt;Engine: normalize_config(config)\nEngine-&gt;&gt;Engine: _setup_output_directory(execution_id)\n\nEngine-&gt;&gt;StatusService: update_status('preparing', 'Preparing CrewAI execution')\n\nEngine-&gt;&gt;ToolService: Create tool service\nEngine-&gt;&gt;ApiKeys: Get API keys\nEngine-&gt;&gt;ToolFactory: Create tool factory with API keys\n\nEngine-&gt;&gt;CrewPrep: Create CrewPreparation(config, tool_service, tool_factory)\nCrewPrep-&gt;&gt;CrewPrep: prepare()\nCrewPrep--&gt;&gt;Engine: Return prepared crew\n\nEngine-&gt;&gt;Engine: Set up event listeners for agent trace, task completion, detailed output\n\nEngine-&gt;&gt;StatusService: update_status('running', 'CrewAI execution is running')\n\nEngine-&gt;&gt;LLM: Get LLM instance with API keys\nLLM--&gt;&gt;Engine: Return configured LLM\n\nEngine-&gt;&gt;CrewAI: Run crew (using crew.kickoff())\n\nloop For each task in crew\n    CrewAI-&gt;&gt;LLM: Execute task with agent\n    LLM--&gt;&gt;CrewAI: Return task results\n    CrewAI-&gt;&gt;Engine: Emit events (agent trace, task completion)\n    Engine-&gt;&gt;StatusService: Update status with progress\n    StatusService-&gt;&gt;Database: Update execution record\nend\n\nCrewAI--&gt;&gt;Engine: Return execution results\n\nEngine-&gt;&gt;StatusService: update_status(execution_id, 'completed', 'Execution completed')\nStatusService-&gt;&gt;Database: Update execution status\n\nNote over UI,Database: UI receives completed status via polling\n</code></pre>"},{"location":"flows/","title":"Flows","text":"<p>sequenceDiagram     participant UI as Frontend UI     participant JobService as JobExecutionService     participant RunStore as CrewExecutionStore     participant ApiClient as API Client     participant Router as Flow API Router     participant ExecService as ExecutionService     participant CrewExecService as CrewAIExecutionService     participant FlowRepo as FlowRepository     participant FlowService as CrewAIFlowService     participant FlowRunner as FlowRunnerService (relocated)     participant Backend as BackendFlow     participant Engine as CrewAIEngineService     participant Llm as LLMManager     participant Keys as ApiKeysService     participant DB as Database     participant CrewAI as CrewAI Flow</p> <pre><code>Note over UI,CrewAI: Flow Execution Process - Updated Architecture\n\nUI-&gt;&gt;RunStore: handleRunClick(type: flow)\nRunStore-&gt;&gt;JobService: executeJob(..., type: flow)\nNote right of JobService: Prepare flow execution config with nodes, edges, flow_id\n\nJobService-&gt;&gt;ApiClient: POST /executions\nApiClient-&gt;&gt;Router: execute_flow(request)\nRouter-&gt;&gt;ExecService: execute_flow(flow_id, nodes, edges, job_id)\n\nExecService-&gt;&gt;CrewExecService: run_flow_execution(flow_id, nodes, edges, job_id, config)\n\nalt Has flow_id but no nodes\n    CrewExecService-&gt;&gt;FlowRepo: find_by_id(flow_id)\n    FlowRepo-&gt;&gt;DB: Query flow data\n    DB--&gt;&gt;FlowRepo: Return flow data\n    FlowRepo--&gt;&gt;CrewExecService: Return flow entity (nodes, edges, config)\n    CrewExecService-&gt;&gt;CrewExecService: Update execution_config with loaded data\nend\n\nCrewExecService-&gt;&gt;FlowService: run_flow(flow_id, job_id, config)\n\nFlowService-&gt;&gt;FlowRunner: run_flow(flow_id, job_id, config)\n\nFlowRunner-&gt;&gt;FlowRunner: Create execution record via repository\nFlowRunner-&gt;&gt;DB: Create flow execution record\nFlowRunner--&gt;&gt;FlowService: Return job_id and execution_id (async)\nFlowService--&gt;&gt;CrewExecService: Return execution details\nCrewExecService--&gt;&gt;ExecService: Return execution response\nExecService--&gt;&gt;Router: Return execution response\nRouter--&gt;&gt;ApiClient: Return execution response\nApiClient--&gt;&gt;JobService: Return response with job_id\nJobService--&gt;&gt;RunStore: Return job execution response\nRunStore--&gt;&gt;UI: Update with job_id and status\nNote right of UI: UI starts polling for status\n\nNote over FlowRunner,CrewAI: Asynchronous Flow Execution\n\nFlowRunner-&gt;&gt;FlowRunner: Create flow execution task\n\nFlowRunner-&gt;&gt;FlowRunner: _run_flow_execution(execution_id, flow_id, job_id, config)\n\nFlowRunner-&gt;&gt;Keys: Initialize API keys\nKeys--&gt;&gt;FlowRunner: Return API keys\n\nFlowRunner-&gt;&gt;FlowRunner: Create event listeners (Agent Trace, Task Completion, Detailed Output)\n\nFlowRunner-&gt;&gt;Backend: Create BackendFlow(job_id, flow_id)\nFlowRunner-&gt;&gt;Backend: Set repositories (flow, task, agent, tool)\n\nalt No nodes in config\n    Backend-&gt;&gt;Backend: load_flow() via flow repository\n    Backend-&gt;&gt;FlowRepo: find_by_id(flow_id)\n    FlowRepo-&gt;&gt;DB: Query flow data\n    DB--&gt;&gt;FlowRepo: Return flow data\n    FlowRepo--&gt;&gt;Backend: Return flow entity\n    Backend-&gt;&gt;Backend: Update config with loaded data\nend\n\nFlowRunner-&gt;&gt;Backend: setup output directory\nFlowRunner-&gt;&gt;DB: Update execution status to RUNNING via repository\n\nFlowRunner-&gt;&gt;Backend: kickoff()\n\nBackend-&gt;&gt;Backend: load_flow() if not already loaded\n\nBackend-&gt;&gt;Backend: flow() - create CrewAI Flow\n\nBackend-&gt;&gt;DB: Query task, agent and tool data via repositories\nDB--&gt;&gt;Backend: Return task, agent, and tool data\n\nBackend-&gt;&gt;Llm: _get_llm()\nLlm-&gt;&gt;Keys: get_provider_api_key()\nKeys--&gt;&gt;Llm: Return API keys\nLlm--&gt;&gt;Backend: Return configured LLM\n\nBackend-&gt;&gt;CrewAI: kickoff_async()\n\nCrewAI-&gt;&gt;CrewAI: Execute flow with agents and tasks\nNote right of CrewAI: CrewAI handles the LLM calls, tools, and task execution\n\nCrewAI--&gt;&gt;Backend: Return execution result\n\nBackend-&gt;&gt;Backend: Convert result to dictionary\nBackend--&gt;&gt;FlowRunner: Return execution result\n\nFlowRunner-&gt;&gt;DB: Update execution status to COMPLETED/FAILED via repository\n\nUI-&gt;&gt;ApiClient: Poll for execution status\nApiClient-&gt;&gt;Router: get_flow_execution(execution_id)\nRouter-&gt;&gt;FlowService: get_flow_execution(execution_id)\nFlowService-&gt;&gt;FlowRunner: get_flow_execution(execution_id)\nFlowRunner-&gt;&gt;DB: Query execution record via repository\nDB--&gt;&gt;FlowRunner: Return execution data\nFlowRunner--&gt;&gt;FlowService: Return execution details\nFlowService--&gt;&gt;Router: Return execution details\nRouter--&gt;&gt;ApiClient: Return execution response\nApiClient--&gt;&gt;UI: Update UI with execution status and result\n\nNote over UI,CrewAI: Separation of Concerns in New Architecture\nNote right of ExecService: ExecutionService delegates to CrewAIExecutionService\nNote right of CrewExecService: CrewAIExecutionService accesses data via repositories\nNote right of FlowRepo: Repository layer handles all database access\nNote right of FlowService: CrewAIFlowService acts as adapter to FlowRunnerService\nNote right of FlowRunner: FlowRunnerService (now in engines/crewai/flow) handles execution details\n</code></pre>"},{"location":"generation/","title":"Generation Features in Kasal","text":""},{"location":"generation/#overview","title":"Overview","text":"<p>Kasal provides powerful AI-assisted generation capabilities to help users quickly create agents, tasks, and crew plans. This document covers how to use these generation features through both the UI and keyboard shortcuts.</p>"},{"location":"generation/#generation-capabilities","title":"Generation Capabilities","text":""},{"location":"generation/#1-generate-agents","title":"1. Generate Agents","text":"<p>The Agent Generation feature allows you to create agents with specific roles, goals, and backstories using natural language descriptions.</p>"},{"location":"generation/#how-to-access-agent-generation","title":"How to Access Agent Generation","text":"<p>Through UI: 1. Navigate to the workflow designer canvas 2. Click the \"Generate Agent\" button in the toolbar 3. The Agent Generation dialog will open</p> <p>Using Keyboard Shortcuts: - Press <code>g</code> followed by <code>a</code> (vim-style shortcut for \"generate agent\")</p>"},{"location":"generation/#using-agent-generation","title":"Using Agent Generation","text":"<ol> <li>In the Agent Generation dialog, provide:</li> <li>Description: Describe the type of agent you want to create (e.g., \"A data analysis expert who can review financial data\")</li> <li> <p>Additional Context (optional): Add any specific requirements or context</p> </li> <li> <p>Click \"Generate\" to create the agent</p> </li> <li> <p>Review and edit the generated agent properties:</p> </li> <li>Name: The agent's identifier</li> <li>Role: The agent's professional role</li> <li>Goal: What the agent aims to accomplish</li> <li> <p>Backstory: The agent's background and context</p> </li> <li> <p>Click \"Save\" to add the agent to your workflow</p> </li> </ol>"},{"location":"generation/#example-agent-description","title":"Example Agent Description","text":"<pre><code>A cybersecurity expert specializing in network vulnerabilities and threat detection. \nThe agent should be able to analyze network traffic patterns and identify potential security risks.\n</code></pre>"},{"location":"generation/#2-generate-tasks","title":"2. Generate Tasks","text":"<p>The Task Generation feature helps you create well-defined tasks for your agents to perform.</p>"},{"location":"generation/#how-to-access-task-generation","title":"How to Access Task Generation","text":"<p>Through UI: 1. Navigate to the workflow designer canvas 2. Click the \"Generate Task\" button in the toolbar 3. The Task Generation dialog will open</p> <p>Using Keyboard Shortcuts: - Press <code>g</code> followed by <code>t</code> (vim-style shortcut for \"generate task\")</p>"},{"location":"generation/#using-task-generation","title":"Using Task Generation","text":"<ol> <li>In the Task Generation dialog, provide:</li> <li>Description: Describe the task you want to create (e.g., \"Analyze website traffic data and identify patterns\")</li> <li> <p>Additional Context (optional): Add any specific requirements or context</p> </li> <li> <p>Click \"Generate\" to create the task</p> </li> <li> <p>Review and edit the generated task properties:</p> </li> <li>Name: The task's identifier</li> <li>Description: Detailed explanation of what the task entails</li> <li>Expected Output: The expected result or deliverable</li> <li> <p>Tools (optional): Any tools required for the task</p> </li> <li> <p>Click \"Save\" to add the task to your workflow</p> </li> </ol>"},{"location":"generation/#example-task-description","title":"Example Task Description","text":"<pre><code>Review the latest quarterly financial reports and create a summary of key performance indicators,\nhighlighting any significant changes from the previous quarter.\n</code></pre>"},{"location":"generation/#3-generate-crew-plans","title":"3. Generate Crew Plans","text":"<p>The Crew Plan Generation feature helps you design an entire workflow by automatically creating and connecting multiple agents and tasks.</p>"},{"location":"generation/#how-to-access-crew-plan-generation","title":"How to Access Crew Plan Generation","text":"<p>Through UI: 1. Navigate to the workflow designer canvas 2. Click the \"Generate Crew Plan\" button in the toolbar 3. The Crew Plan Generation dialog will open</p> <p>Using Keyboard Shortcuts: - Press <code>g</code> followed by <code>c</code> (vim-style shortcut for \"generate crew\")</p>"},{"location":"generation/#using-crew-plan-generation","title":"Using Crew Plan Generation","text":"<ol> <li>In the Crew Plan Generation dialog, provide:</li> <li>Objective: The overall goal you want to achieve (e.g., \"Build a comprehensive market analysis report for a new product launch\")</li> <li>Requirements (optional): Any specific requirements or constraints</li> <li> <p>Additional Context (optional): Any background information that might be helpful</p> </li> <li> <p>Click \"Generate\" to create the crew plan</p> </li> <li> <p>Review the generated plan, which will include:</p> </li> <li>Multiple agents with defined roles</li> <li>Tasks assigned to those agents</li> <li> <p>Connections between agents and tasks showing workflow</p> </li> <li> <p>Click \"Apply\" to add the entire crew plan to your workflow</p> </li> </ol>"},{"location":"generation/#example-crew-plan-objective","title":"Example Crew Plan Objective","text":"<pre><code>Create a comprehensive content marketing strategy for a new SaaS product, \nincluding audience analysis, content calendar, and distribution channels.\n</code></pre>"},{"location":"generation/#automatic-connection-generation","title":"Automatic Connection Generation","text":"<p>After creating multiple agents and tasks, you can automatically generate logical connections between them.</p>"},{"location":"generation/#how-to-generate-connections","title":"How to Generate Connections","text":"<p>Through UI: 1. Create multiple agents and tasks on the canvas 2. Click the \"Generate Connections\" button in the toolbar</p> <p>Using Keyboard Shortcuts: - Press <code>c</code> followed by <code>c</code> (vim-style shortcut for \"create connections\")</p> <p>This feature analyzes the roles of your agents and the requirements of your tasks, then creates appropriate connections between them based on their compatibility.</p>"},{"location":"generation/#shortcut-quick-reference","title":"Shortcut Quick Reference","text":"Feature Shortcut Description Generate Agent <code>g</code>, <code>a</code> Open the Agent Generation dialog Generate Task <code>g</code>, <code>t</code> Open the Task Generation dialog Generate Crew Plan <code>g</code>, <code>c</code> Open the Crew Plan Generation dialog Generate Connections <code>c</code>, <code>c</code> Automatically connect agents and tasks Execute Crew <code>e</code>, <code>c</code> Execute the current crew workflow"},{"location":"generation/#best-practices-for-generation","title":"Best Practices for Generation","text":"<ol> <li>Be Specific: The more specific your descriptions, the better the generated results</li> <li>Iterate: Generate initial components, then refine them for best results</li> <li>Provide Context: Include domain-specific information for more accurate generation</li> <li>Review Outputs: Always review generated components before executing workflows</li> <li>Use Templates: Save successful generations as templates for future use</li> </ol>"},{"location":"generation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"generation/#common-issues","title":"Common Issues","text":"<ul> <li>Vague Generations: If the generated components are too generic, provide more specific descriptions</li> <li>Incorrect Connections: If connections don't make sense, try regenerating with more explicit role definitions</li> <li>Generation Errors: If you encounter errors during generation, check your API configuration and connectivity</li> </ul>"},{"location":"generation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues with the generation features:</p> <ol> <li>Check the application logs for detailed error messages</li> <li>Ensure your LLM API keys are correctly configured</li> <li>Try simplifying your descriptions if complex ones are causing issues </li> </ol>"},{"location":"job/","title":"Jobs Component Documentation","text":"<p>This document provides an overview of the Jobs components in the CrewAI Manager frontend application.</p>"},{"location":"job/#overview","title":"Overview","text":"<p>The Jobs components are responsible for managing, displaying, and analyzing job executions within the CrewAI system. These components handle run history, execution logs, trace visualization, result presentation, and job status monitoring.</p>"},{"location":"job/#components-structure","title":"Components Structure","text":""},{"location":"job/#runhistory","title":"RunHistory","text":"<p><code>RunHistory.tsx</code> is the primary component for displaying the history of workflow runs.</p> <p>Key Features: - Tabular view of all past workflow executions - Sorting and filtering capabilities - Pagination for large result sets - Job management actions (view, delete, schedule) - Integration with other job components (logs, trace, results) - Real-time status updates through polling - User activity tracking to optimize polling</p>"},{"location":"job/#showlogs","title":"ShowLogs","text":"<p><code>ShowLogs.tsx</code> displays the execution logs for a specific job.</p> <p>Key Features: - Real-time log streaming - Historical log viewing - Auto-scroll functionality - Log filtering - Pagination through infinite scrolling - Manual refresh option</p>"},{"location":"job/#showresult","title":"ShowResult","text":"<p><code>ShowResult.tsx</code> displays the results of a completed job execution.</p> <p>Key Features: - Formatted display of execution results - Markdown rendering with proper styling - Link detection and formatting - Support for various result types (text, objects, arrays) - Tabbed interface for multiple result sections</p>"},{"location":"job/#showtrace","title":"ShowTrace","text":"<p><code>ShowTrace.tsx</code> visualizes the execution trace of a job.</p> <p>Key Features: - Step-by-step visualization of job execution - Timeline representation - Detailed information for each trace step - Error handling and retry capabilities - Markdown rendering for trace content</p>"},{"location":"job/#jobstatusindicator","title":"JobStatusIndicator","text":"<p><code>JobStatusIndicator.tsx</code> provides a real-time status indicator for running jobs.</p> <p>Key Features: - Real-time status updates - Error reporting - Auto-close on job completion - Visual feedback on job status</p>"},{"location":"job/#llmlogs","title":"LLMLogs","text":"<p><code>LLMLogs.tsx</code> displays logs specific to LLM (Language Learning Model) interactions.</p> <p>Key Features: - Detailed view of model API calls - Performance metrics (token usage, duration) - Expandable details for each log entry - Filtering by endpoint - Pagination - Auto-refresh functionality</p>"},{"location":"job/#runactions","title":"RunActions","text":"<p><code>RunActions.tsx</code> provides action buttons for job management.</p> <p>Key Features: - View result action - Download PDF report - View inputs (load workflow) - View execution trace - View logs - Schedule job - Delete job</p>"},{"location":"job/#rundialogs","title":"RunDialogs","text":"<p><code>RunDialogs.tsx</code> contains dialog components for job-related actions.</p> <p>Key Features: - Delete confirmation dialog - Job scheduling dialog with cron expression support - Delete run confirmation dialog</p>"},{"location":"job/#data-flow","title":"Data Flow","text":"<ol> <li>The <code>RunHistory</code> component displays a list of all job executions</li> <li>Users can interact with each job through <code>RunActions</code> buttons</li> <li>Detail views (<code>ShowLogs</code>, <code>ShowResult</code>, <code>ShowTrace</code>) display specific aspects of a job execution</li> <li>Status updates are shown through <code>JobStatusIndicator</code></li> <li>Dialog components in <code>RunDialogs</code> handle confirmations for destructive actions</li> </ol>"},{"location":"job/#key-interfaces","title":"Key Interfaces","text":"<p>The Jobs components use several key interfaces:</p> <ul> <li>Run: Represents a job execution with properties like status, duration, results</li> <li>LogEntry: Represents a log message from the job execution</li> <li>LLMLog: Represents a log entry specific to LLM API calls</li> <li>Trace: Represents an execution trace step</li> <li>ResultValue: Represents a job execution result value</li> </ul>"},{"location":"job/#services-integration","title":"Services Integration","text":"<p>The Jobs components integrate with several services:</p> <ul> <li>RunService: For CRUD operations on runs and job management</li> <li>LogService: For retrieving and streaming logs</li> <li>TraceService: For retrieving execution traces</li> <li>ScheduleService: For scheduling recurring jobs</li> </ul>"},{"location":"job/#real-time-features","title":"Real-time Features","text":"<p>The Jobs components implement several real-time features:</p> <ul> <li>Status polling: Regular checks for job status updates</li> <li>Log streaming: Real-time display of logs during execution</li> <li>User activity detection: Optimization of polling based on user activity</li> </ul>"},{"location":"job/#pdf-generation","title":"PDF Generation","text":"<p>Job results can be exported as PDF reports using the <code>generateRunPDF</code> utility function, which is accessible through the <code>RunActions</code> component.</p>"},{"location":"job/#best-practices","title":"Best Practices","text":"<p>When working with the Jobs components:</p> <ol> <li>Use proper error handling to provide useful feedback to users</li> <li>Implement pagination for large datasets to improve performance</li> <li>Provide sorting and filtering options for better user experience</li> <li>Optimize real-time updates to balance freshness and performance</li> <li>Use proper formatting for different types of content (logs, results, traces)</li> <li>Implement responsive designs that work well on different screen sizes</li> <li>Use internationalization (i18n) for all user-facing text</li> <li>Maintain consistent styling with the rest of the application using MUI components </li> </ol>"},{"location":"nodeDecorator/","title":"Node Decoration System","text":"<p>This document describes the Node Decoration system in the CrewAI Manager application, which highlights active and completed tasks in the workflow editor.</p>"},{"location":"nodeDecorator/#overview","title":"Overview","text":"<p>The Node Decoration system is responsible for:</p> <ol> <li>Tracking which tasks are currently active during job execution</li> <li>Tracking which tasks have been completed</li> <li>Updating the visual state of nodes in the workflow to reflect their status</li> <li>Providing a consistent interface for components to interact with this functionality</li> </ol>"},{"location":"nodeDecorator/#implementation","title":"Implementation","text":"<p>The system consists of:</p> <ol> <li>A Zustand store (<code>nodeDecorator.ts</code>) that maintains state and provides decoration logic</li> <li>A custom hook (<code>useNodeDecorator.ts</code>) that provides a clean interface to the store</li> <li>Integration with other components and hooks (like <code>useTaskHighlighter.ts</code>) that consume this functionality</li> </ol>"},{"location":"nodeDecorator/#store-nodedecoratorts","title":"Store: nodeDecorator.ts","text":"<p>The Node Decorator store maintains the current state of task execution and provides methods to update and query this state.</p>"},{"location":"nodeDecorator/#state","title":"State","text":"<ul> <li><code>currentTaskId</code>: The ID of the task currently being executed</li> <li><code>completedTaskIds</code>: An array of IDs for tasks that have been completed</li> </ul>"},{"location":"nodeDecorator/#actions","title":"Actions","text":"<ul> <li><code>setCurrentTaskId</code>: Update the currently active task</li> <li><code>setCompletedTaskIds</code>: Set the full list of completed tasks</li> <li><code>addCompletedTaskId</code>: Add a single task to the completed list</li> <li><code>clearCompletedTaskIds</code>: Clear the list of completed tasks</li> <li><code>decorateNodesWithActiveStatus</code>: Apply the current state to a set of nodes, returning updated nodes with visual indicators</li> </ul>"},{"location":"nodeDecorator/#hook-usenodedecoratorts","title":"Hook: useNodeDecorator.ts","text":"<p>The custom hook provides a convenient interface to the store with memoized handlers.</p>"},{"location":"nodeDecorator/#usage","title":"Usage","text":"<pre><code>import { useNodeDecorator } from '../hooks/workflow/useNodeDecorator';\nimport { Node, Edge } from 'reactflow';\n\nconst MyComponent = () =&gt; {\n  const { \n    // State\n    currentTaskId,              // Currently active task ID\n    completedTaskIds,           // List of completed task IDs\n\n    // Actions\n    setCurrentTaskId,           // Set the current task\n    setCompletedTaskIds,        // Set completed tasks\n    addCompletedTaskId,         // Add a task to completed list\n    clearCompletedTaskIds,      // Clear completed tasks\n    decorateNodes               // Apply decoration to nodes\n  } = useNodeDecorator();\n\n  // Example: Update nodes with active/completed status\n  const updateNodes = (nodes: Node[], edges: Edge[]) =&gt; {\n    const decoratedNodes = decorateNodes(nodes, edges);\n    // Use the decorated nodes...\n  };\n};\n</code></pre>"},{"location":"nodeDecorator/#integration-with-task-highlighter","title":"Integration with Task Highlighter","text":"<p>The Node Decorator system is integrated with the Task Highlighter, which monitors job execution and updates the node decoration state accordingly.</p>"},{"location":"nodeDecorator/#usetaskhighlighterts","title":"useTaskHighlighter.ts","text":"<p>This hook:</p> <ol> <li>Monitors active runs from the Run Status store</li> <li>Updates the Node Decorator store when task status changes</li> <li>Applies node decoration to the workflow nodes</li> <li>Notifies parent components of job status changes</li> </ol>"},{"location":"nodeDecorator/#visual-indicators","title":"Visual Indicators","text":"<p>The decoration system applies the following visual states to nodes:</p> <ul> <li><code>isActive: true</code>: Indicates a task is currently being executed</li> <li><code>isCompleted: true</code>: Indicates a task has been completed</li> </ul> <p>These flags are used by the node components to apply appropriate styling.</p>"},{"location":"nodeDecorator/#task-id-matching","title":"Task ID Matching","text":"<p>The system handles various task ID formats for compatibility:</p> <ul> <li>Direct matches: <code>taskId === currentTaskId</code></li> <li>Prefix matches: <code>currentTaskId.startsWith('task_')</code> for format <code>task_task-XXX</code></li> <li>Inclusion matches: <code>currentTaskId.includes(taskId)</code></li> </ul>"},{"location":"nodeDecorator/#agent-node-decoration","title":"Agent Node Decoration","text":"<p>Agent nodes are decorated based on their connections to task nodes:</p> <ul> <li>If an agent is connected to an active task, it is marked as active</li> <li>If an agent is connected to a completed task, it is marked as completed</li> </ul> <p>This provides visual feedback about which agents are involved in the current task execution. </p>"},{"location":"shortcuts/","title":"Keyboard Shortcuts System Documentation","text":""},{"location":"shortcuts/#overview","title":"Overview","text":"<p>The keyboard shortcuts system in the CrewAI Manager application provides a powerful way to interact with the workflow designer through keyboard commands. This document covers the technical implementation details and component usage of the shortcuts system.</p>"},{"location":"shortcuts/#technical-architecture","title":"Technical Architecture","text":""},{"location":"shortcuts/#core-components","title":"Core Components","text":"<ol> <li>useShortcuts Hook (<code>frontend/src/hooks/global/useShortcuts.ts</code>)</li> <li>Main hook that manages keyboard shortcut functionality</li> <li>Handles key sequence tracking and matching</li> <li>Manages dialog state and shortcut enabling/disabling</li> <li>Provides debugging capabilities</li> <li> <p>Integrates with Zustand state management</p> </li> <li> <p>Shortcuts UI Components</p> </li> <li><code>ShortcutsCircle.tsx</code>: Modal display of available shortcuts</li> <li><code>ShortcutsToggle.tsx</code>: Button to show/hide shortcuts</li> <li> <p><code>ShortcutsStore</code>: Zustand store for managing shortcuts state</p> </li> <li> <p>Type Definitions (<code>frontend/src/types/shortcuts.ts</code>)</p> </li> <li>Defines shortcut actions, configurations, and context types</li> </ol>"},{"location":"shortcuts/#key-features","title":"Key Features","text":"<ul> <li>Multi-key Sequences: Support for complex key combinations</li> <li>Dialog Awareness: Automatically disables shortcuts when dialogs are open</li> <li>Debugging Support: Comprehensive logging for troubleshooting</li> <li>Extensible Design: Easy to add new shortcuts and handlers</li> <li>State Management: Integration with Zustand for global state</li> <li>Validation: Pre-action validation for node operations</li> <li>Error Handling: Improved error management via Zustand store</li> </ul>"},{"location":"shortcuts/#component-usage","title":"Component Usage","text":""},{"location":"shortcuts/#1-crewcanvas","title":"1. CrewCanvas","text":"<p>Location: <code>frontend/src/components/WorkflowDesigner/CrewCanvas.tsx</code></p> <p>Usage: <pre><code>const { shortcuts } = useShortcuts({\n  flowInstance: reactFlowInstanceRef.current,\n  onDeleteSelected: handleDeleteSelected,\n  onClearCanvas: handleClear,\n  onZoomIn: () =&gt; reactFlowInstanceRef.current?.zoomIn(),\n  onZoomOut: () =&gt; reactFlowInstanceRef.current?.zoomOut(),\n  onFitView: () =&gt; reactFlowInstanceRef.current?.fitView({ padding: 0.2 }),\n  onExecuteCrew: handleExecuteCrew,\n  onExecuteFlow: () =&gt; executeCrew(nodes, edges),\n  onOpenAgentDialog: () =&gt; setIsAgentGenerationDialogOpen(true),\n  onOpenTaskDialog: () =&gt; setIsTaskGenerationDialogOpen(true),\n  onOpenCrewPlanningDialog: () =&gt; setIsCrewPlanningDialogOpen(true),\n  onGenerateConnections: handleGenerateConnections,\n  onOpenSaveCrew: () =&gt; setIsSaveCrewDialogOpen(true),\n  onOpenCrewFlowDialog: () =&gt; setIsCrewFlowDialogOpen(true),\n  onChangeLLMForAllAgents: handleChangeLLM,\n  onChangeMaxRPMForAllAgents: handleChangeMaxRPM,\n  onChangeToolsForAllAgents: handleChangeTools,\n  onOpenLLMDialog: () =&gt; setIsLLMSelectionDialogOpen(true),\n  onOpenToolDialog: () =&gt; setIsToolDialogOpen(true),\n  onOpenMaxRPMDialog: () =&gt; setIsMaxRPMSelectionDialogOpen(true),\n  disabled: false,\n  useWorkflowStore: true\n});\n</code></pre></p> <p>Handled Actions: - Canvas operations (delete, clear, fit view) - Agent and task management - Dialog control - Execution commands with validation</p>"},{"location":"shortcuts/#2-flowcanvas","title":"2. FlowCanvas","text":"<p>Location: <code>frontend/src/components/WorkflowDesigner/FlowCanvas.tsx</code></p> <p>Usage: <pre><code>const { shortcuts: _shortcuts } = useShortcuts({\n  flowInstance: reactFlowInstanceRef.current,\n  onDeleteSelected: handleDeleteSelected,\n  onClearCanvas: handleClearCanvas,\n  onFitView: () =&gt; {\n    if (reactFlowInstanceRef.current) {\n      reactFlowInstanceRef.current.fitView({ padding: 0.2 });\n    }\n  },\n  disabled: isRendering || hasError\n});\n</code></pre></p> <p>Handled Actions: - Basic canvas operations - Node and edge management - View control</p>"},{"location":"shortcuts/#3-workflowdesigner","title":"3. WorkflowDesigner","text":"<p>Location: <code>frontend/src/components/WorkflowDesigner/WorkflowDesigner.tsx</code></p> <p>Integration: - Coordinates between CrewCanvas and FlowCanvas - Manages overall workflow state - Handles shortcut-related UI components</p>"},{"location":"shortcuts/#default-shortcuts","title":"Default Shortcuts","text":""},{"location":"shortcuts/#canvas-operations","title":"Canvas Operations","text":"Action Keys Description Delete Selected <code>Delete</code> or <code>Backspace</code> Delete selected nodes/edges Clear Canvas <code>d</code>, <code>d</code> Clear entire canvas (vim-style) Clear Canvas <code>Alt</code>, <code>c</code> Clear entire canvas Fit View <code>v</code>, <code>f</code> Fit view to all nodes (vim-style) Fit View <code>Control</code>, <code>0</code> Fit view to all nodes Zoom In <code>Control</code>, <code>=</code> Zoom in Zoom Out <code>Control</code>, <code>-</code> Zoom out Toggle Fullscreen <code>f</code> Toggle fullscreen mode"},{"location":"shortcuts/#edit-operations","title":"Edit Operations","text":"Action Keys Description Undo <code>Control</code>, <code>z</code> Undo last action Redo <code>Control</code>, <code>Shift</code>, <code>z</code> Redo last undone action Redo <code>Control</code>, <code>y</code> Redo last undone action Select All <code>Control</code>, <code>a</code> Select all nodes Copy <code>Control</code>, <code>c</code> Copy selected nodes Paste <code>Control</code>, <code>v</code> Paste copied nodes"},{"location":"shortcuts/#agent-operations","title":"Agent Operations","text":"Action Keys Description Open Agent Dialog <code>g</code>, <code>a</code> Open Generate Agent dialog Open Task Dialog <code>g</code>, <code>t</code> Open Generate Task dialog Open Crew Planning <code>g</code>, <code>c</code> Open Generate Crew Plan dialog Generate Connections <code>c</code>, <code>c</code> Generate connections between agents/tasks"},{"location":"shortcuts/#crew-operations","title":"Crew Operations","text":"Action Keys Description Execute Crew <code>e</code>, <code>c</code> Execute Crew (validates agent &amp; task nodes) Execute Flow <code>e</code>, <code>f</code> Execute Flow Show Run Result <code>s</code>, <code>r</code> Show Run Result dialog Open Crew/Flow Dialog <code>l</code>, <code>c</code> Open Crew/Flow selection dialog"},{"location":"shortcuts/#agent-configuration","title":"Agent Configuration","text":"Action Keys Description Change LLM <code>l</code>, <code>l</code>, <code>m</code> Change LLM model for all agents (validates agent nodes) Change Max RPM <code>m</code>, <code>a</code>, <code>x</code>, <code>r</code> Change Max RPM for all agents (validates agent nodes) Change Tools <code>t</code>, <code>o</code>, <code>o</code>, <code>l</code> Change tools for all agents (validates agent nodes)"},{"location":"shortcuts/#implementation-details","title":"Implementation Details","text":""},{"location":"shortcuts/#key-sequence-tracking","title":"Key Sequence Tracking","text":"<p>The system uses a <code>keySequence</code> ref to track multi-key shortcuts: <pre><code>const keySequence = useRef&lt;string[]&gt;([]);\n</code></pre></p>"},{"location":"shortcuts/#dialog-state-management","title":"Dialog State Management","text":"<p>Shortcuts are automatically disabled when dialogs are open: <pre><code>const hasOpenDialog = document.querySelector('.MuiDialog-root') !== null;\nif (hasOpenDialog) {\n  console.log('useShortcuts - Dialog is open, blocking shortcuts');\n  return;\n}\n</code></pre></p>"},{"location":"shortcuts/#handler-management-with-react-refs","title":"Handler Management with React Refs","text":"<p>Handlers are memoized and accessed via refs to prevent unnecessary re-renders: <pre><code>// Define a stable ref for handlers\nconst handlerRef = useRef&lt;HandlerMap | null&gt;(null);\n\n// Memoize handlers\nconst handlers = useMemo(() =&gt; ({\n  'deleteSelected': () =&gt; { /* ... */ },\n  'clearCanvas': () =&gt; { /* ... */ },\n  // ... other handlers\n}), [/* dependencies */]);\n\n// Keep the handlerRef updated with the latest handlers\nuseEffect(() =&gt; {\n  handlerRef.current = handlers;\n}, [handlers]);\n\n// Use handlerRef.current in event listeners\nconst handler = handlerRef.current ? handlerRef.current[matchedShortcut.action] : null;\nif (handler) {\n  handler();\n}\n</code></pre></p>"},{"location":"shortcuts/#validation-logic","title":"Validation Logic","text":"<p>The shortcuts system now includes built-in validation for operations:</p> <pre><code>// Helper function to validate crew execution requirements\nconst validateCrewExecution = (currentNodes: Node[]): boolean =&gt; {\n  const hasAgentNodes = currentNodes.some(node =&gt; node.type === 'agentNode');\n  const hasTaskNodes = currentNodes.some(node =&gt; node.type === 'taskNode');\n\n  if (!hasAgentNodes || !hasTaskNodes) {\n    setErrorMessage('Crew execution requires at least one agent and one task node');\n    setShowError(true);\n    return false;\n  }\n\n  return true;\n};\n\n// Helper function to validate agent nodes existence\nconst validateAgentNodes = (currentNodes: Node[]): boolean =&gt; {\n  const hasAgentNodes = currentNodes.some(node =&gt; node.type === 'agentNode');\n\n  if (!hasAgentNodes) {\n    setErrorMessage('This operation requires at least one agent node');\n    setShowError(true);\n    return false;\n  }\n\n  return true;\n};\n</code></pre>"},{"location":"shortcuts/#zustand-state-integration","title":"Zustand State Integration","text":"<p>The shortcuts system integrates with Zustand stores for state management:</p> <pre><code>// Get workflow state and actions from the store if enabled\nconst workflowStore = useWorkflowStore();\nconst { nodes: workflowNodes, edges: workflowEdges, setNodes, setEdges, clearWorkflow } = workflowStore;\n\n// Get crew execution state and actions\nconst crewExecutionStore = useCrewExecutionStore();\nconst { \n  executeCrew: executeCrewAction, \n  executeFlow: executeFlowAction,\n  setErrorMessage,\n  setShowError\n} = crewExecutionStore;\n\n// Get error store for global error management\nconst errorStore = useErrorStore();\n</code></pre>"},{"location":"shortcuts/#error-handling","title":"Error Handling","text":"<p>Enhanced error handling with Zustand's error store:</p> <pre><code>try {\n  // Execute crew action\n  if (validateCrewExecution(currentNodes)) {\n    executeCrewAction(currentNodes, currentEdges);\n  }\n} catch (error) {\n  console.error('Error executing crew:', error);\n  setErrorMessage(`Error executing crew: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  setShowError(true);\n}\n</code></pre>"},{"location":"shortcuts/#debugging-support","title":"Debugging Support","text":"<p>The system provides detailed logging: <pre><code>console.log('useShortcuts - Key event captured:', event.key);\nconsole.log('useShortcuts - Render cycle dependencies:', {\n  handlersKeys: Object.keys(handlerRef.current || {}),\n  disabledValue: currentDisabled,\n  shortcutsCount: currentShortcuts.length\n});\n</code></pre></p>"},{"location":"shortcuts/#best-practices","title":"Best Practices","text":"<ol> <li>Adding New Shortcuts:</li> <li>Add the action type to <code>ShortcutAction</code> in <code>shortcuts.ts</code></li> <li>Add the shortcut configuration to <code>DEFAULT_SHORTCUTS</code></li> <li>Implement the handler in the appropriate component</li> <li> <p>Add validation logic if needed</p> </li> <li> <p>Handler Implementation:</p> </li> <li>Use <code>useCallback</code> for handler functions</li> <li>Include proper validation and error handling</li> <li>Add appropriate logging for debugging</li> <li> <p>Implement graceful failure mechanisms</p> </li> <li> <p>Dependency Management:</p> </li> <li>Use React refs to avoid excessive re-renders</li> <li>Carefully manage dependencies in <code>useMemo</code> hooks</li> <li>Use ESLint's <code>react-hooks/exhaustive-deps</code> rule with care</li> <li> <p>Consider using <code>// eslint-disable-next-line react-hooks/exhaustive-deps</code> when necessary</p> </li> <li> <p>State Management Integration:</p> </li> <li>Use Zustand stores for shared state</li> <li>Access store actions directly in handlers</li> <li>Prefer store actions over local state updates</li> <li> <p>Maintain consistency between local and global state</p> </li> <li> <p>Testing Shortcuts:</p> </li> <li>Test in different contexts (with/without dialogs)</li> <li>Verify multi-key sequences work correctly</li> <li>Check for conflicts with existing shortcuts</li> <li>Test validation logic with various node configurations</li> </ol>"},{"location":"shortcuts/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>Shortcuts Not Working:</li> <li>Check if a dialog is open</li> <li>Verify the component is focused</li> <li>Check console logs for debugging information</li> <li> <p>Ensure validations are passing</p> </li> <li> <p>Handler Not Executing:</p> </li> <li>Verify the handler is properly registered</li> <li>Check for errors in the handler implementation</li> <li>Ensure the shortcut sequence is correctly matched</li> <li> <p>Verify that validation conditions are met</p> </li> <li> <p>Performance Issues:</p> </li> <li>Check for unnecessary re-renders</li> <li>Verify handler memoization</li> <li>Monitor key sequence tracking</li> <li> <p>Use React DevTools to check for render cycles</p> </li> <li> <p>Validation Always Failing:</p> </li> <li>Check node types in the validation functions</li> <li>Verify node data structure</li> <li>Log node content to debug issues</li> <li>Ensure error messages are being correctly set</li> </ol>"},{"location":"shortcuts/#future-improvements","title":"Future Improvements","text":"<ol> <li>Planned Enhancements:</li> <li>Custom shortcut configuration</li> <li>Shortcut conflict detection</li> <li>Visual shortcut editor</li> <li>Shortcut learning mode</li> <li>Enhanced validation feedback</li> <li> <p>Full integration with all Zustand stores</p> </li> <li> <p>Technical Debt:</p> </li> <li>Further improve handler management</li> <li>Enhance type safety</li> <li>Extend debugging capabilities</li> <li>Optimize performance</li> <li>Refine validation logic </li> </ol>"},{"location":"task/","title":"Tasks Component Documentation","text":"<p>This document provides an overview of the Tasks components in the CrewAI Manager frontend application.</p>"},{"location":"task/#overview","title":"Overview","text":"<p>The Tasks components are responsible for creating, managing, editing, and visualizing tasks within the CrewAI system. These components handle task configuration, tool assignment, conditional execution settings, and advanced parameters like caching, callbacks, and error handling.</p>"},{"location":"task/#components-structure","title":"Components Structure","text":""},{"location":"task/#tasknode","title":"TaskNode","text":"<p><code>TaskNode.tsx</code> implements a visual node component used in the workflow editor to represent a task within the workflow.</p> <p>Key Features: - Displays task information (name, description, expected output) - Provides visual feedback for active or completed tasks - Handles task deletion and editing - Supports drag and drop interactions - Manages connections to other nodes (like agents or other tasks) - Supports connecting tasks in sequence through double-clicking</p>"},{"location":"task/#taskform","title":"TaskForm","text":"<p><code>TaskForm.tsx</code> provides a comprehensive form for creating and editing tasks.</p> <p>Key Features: - Input fields for basic task properties (name, description, expected output) - Tools selection - Agent assignment - Async execution configuration - Context definition (relationships with other tasks) - Integration with advanced configuration - AI-assisted task generation</p>"},{"location":"task/#taskdialog","title":"TaskDialog","text":"<p><code>TaskDialog.tsx</code> implements a dialog for managing saved tasks.</p> <p>Key Features: - Lists all saved tasks - Allows selection of tasks to add to the workflow - Provides actions to delete tasks - Button to create new tasks - Multi-selection capabilities</p>"},{"location":"task/#savedtasks","title":"SavedTasks","text":"<p><code>SavedTasks.tsx</code> displays a table of all saved tasks with their properties and actions to edit or delete them.</p> <p>Key Features: - Tabular view of tasks with their properties - Edit and delete functionality - Displays associated agent - Notification system for operation feedback</p>"},{"location":"task/#taskgenerationdialog","title":"TaskGenerationDialog","text":"<p><code>TaskGenerationDialog.tsx</code> provides an AI-assisted task generation interface.</p> <p>Key Features: - Text prompt input for describing the desired task - Model selection for generation - Error handling and feedback - Handles keyboard shortcuts (Enter to generate)</p>"},{"location":"task/#taskadvancedconfig","title":"TaskAdvancedConfig","text":"<p><code>TaskAdvancedConfig.tsx</code> provides advanced configuration options for tasks.</p> <p>Key Features: - Execution settings (async, priority, timeout) - Caching configuration (enable/disable, TTL) - Output formatting (JSON schema, file path) - Error handling strategy (retry on fail, max retries) - Callback function selection - Human input requirement setting - Conditional execution configuration</p>"},{"location":"task/#data-flow","title":"Data Flow","text":"<ol> <li>Tasks are created using the <code>TaskForm</code> component, either from scratch or using AI generation via <code>TaskGenerationDialog</code></li> <li>Saved tasks can be viewed and managed in <code>SavedTasks</code> or selected for use in workflows via <code>TaskDialog</code></li> <li>Tasks are visualized in the workflow using <code>TaskNode</code> components</li> <li>Advanced task configurations are managed through the <code>TaskAdvancedConfig</code> component within the task form</li> </ol>"},{"location":"task/#key-interfaces","title":"Key Interfaces","text":"<p>The Tasks components use several key interfaces:</p> <ul> <li>Task: Represents a task with properties like name, description, expected output, and configurations</li> <li>TaskFormData: Represents the form data structure used for editing tasks</li> <li>TaskAdvancedConfigProps: Represents the props for the advanced configuration component</li> <li>TaskCallbackOption: Represents available callback functions for tasks</li> </ul>"},{"location":"task/#services-integration","title":"Services Integration","text":"<p>The Tasks components integrate with several services:</p> <ul> <li>TaskService: For CRUD operations on tasks</li> <li>ToolService: For retrieving available tools to assign to tasks</li> <li>AgentService: For retrieving available agents to assign tasks to</li> <li>ModelService: For retrieving available LLM models for task generation</li> <li>GenerateService: For AI-assisted task generation</li> </ul>"},{"location":"task/#conditional-execution","title":"Conditional Execution","text":"<p>Tasks can be configured with conditional execution through:</p> <ul> <li>Condition types: Predefined conditions like 'is_data_missing'</li> <li>Error handling strategies: Different approaches to handle errors (retry, ignore, fail)</li> <li>Human input requirement: Option to require human confirmation before proceeding</li> </ul>"},{"location":"task/#best-practices","title":"Best Practices","text":"<p>When working with the Tasks components:</p> <ol> <li>Use clear, descriptive names and detailed descriptions for tasks</li> <li>Configure appropriate error handling strategies based on task criticality</li> <li>Set meaningful timeout values to prevent workflow blockages</li> <li>Use async execution for tasks that don't need immediate results</li> <li>Leverage AI generation for quick task creation</li> <li>Use the proper output configuration based on the task's output format</li> <li>Set appropriate caching policies to improve performance and reduce redundant operations</li> <li>Keep UI consistency with the rest of the application using MUI components </li> </ol>"},{"location":"workflow/","title":"WorkflowDesigner Component Documentation","text":"<p>This document provides an overview of the WorkflowDesigner components in the CrewAI Manager frontend application.</p>"},{"location":"workflow/#overview","title":"Overview","text":"<p>The WorkflowDesigner components form the core of the workflow creation and visualization interface in the CrewAI Manager. This module allows users to visually design agent-based workflows by creating agents, tasks, and connections between them. It leverages ReactFlow for the graph-based visualization and interaction capabilities.</p>"},{"location":"workflow/#components-structure","title":"Components Structure","text":""},{"location":"workflow/#workflowdesigner","title":"WorkflowDesigner","text":"<p><code>WorkflowDesigner.tsx</code> serves as the main container component that orchestrates the entire workflow design experience.</p> <p>Key Features: - Manages the overall state of the workflow editor - Coordinates between canvas, toolbar, and panels - Handles dialog management for various operations - Manages theme and error states - Handles node and edge operations (add, delete, update) - Provides access to agent and task management - Integrates with the execution system</p>"},{"location":"workflow/#crewcanvas","title":"CrewCanvas","text":"<p><code>CrewCanvas.tsx</code> implements the primary canvas where agents and tasks are visualized and connected.</p> <p>Key Features: - Renders agent and task nodes - Handles node and edge interactions - Supports drag and drop operations - Provides tools for connecting agents and tasks - Implements node selection and context menus - Automatic positioning of nodes - Connection validation - Enhanced validation for operations - Integration with Zustand state management - Comprehensive error handling - Keyboard shortcuts with validation logic</p> <p>State Management: - Uses Zustand stores for global state management:   - <code>useWorkflowStore</code>: Manages nodes, edges, and UI state   - <code>useCrewExecutionStore</code>: Handles crew execution state and actions   - <code>useErrorStore</code>: Centralizes error management - Implements validation before crew execution and agent operations</p> <p>Error Handling: - Uses the global error store for consistent error reporting - Validates preconditions for operations (node existence, node types, etc.) - Provides clear error messages to users - Implements try/catch blocks in critical operations</p> <p>Keyboard Shortcuts Integration: - Integrates with the <code>useShortcuts</code> hook for keyboard navigation - Custom handlers validate node conditions before actions - Shortcuts for all major operations with appropriate validation - Uses React refs to optimize performance and prevent re-renders</p>"},{"location":"workflow/#flowcanvas","title":"FlowCanvas","text":"<p><code>FlowCanvas.tsx</code> provides an alternative view for flow-based editing of the workflow.</p> <p>Key Features: - Flow-oriented visualization of the workflow - Alternative node layout and organization - Specialized edge rendering - Flow-specific controls and interactions</p>"},{"location":"workflow/#workflowtoolbar","title":"WorkflowToolbar","text":"<p><code>WorkflowToolbar.tsx</code> implements the toolbar interface with actions for workflow manipulation.</p> <p>Key Features: - Model selection for workflow execution - Agent and task creation buttons - Run/execute workflow functionality - Planning and schema detection toggles - Access to configuration dialogs - Save and load functionality</p>"},{"location":"workflow/#workflowpanels","title":"WorkflowPanels","text":"<p><code>WorkflowPanels.tsx</code> manages the layout and arrangement of the main panels in the designer.</p> <p>Key Features: - Responsive panel layout management - Split view between crew and flow canvases - Resizable panels with drag handles - Adjusts for run history visibility - Theme-aware styling</p>"},{"location":"workflow/#workflowdialogs","title":"WorkflowDialogs","text":"<p><code>WorkflowDialogs.tsx</code> centralizes the management of all dialog components used in the workflow designer.</p> <p>Key Features: - Agent and task selection dialogs - Crew planning dialog - Schedule configuration - API keys management - Tool configuration - Log viewing - Flow selection and configuration</p>"},{"location":"workflow/#canvascontrols","title":"CanvasControls","text":"<p><code>CanvasControls.tsx</code> provides user interface controls for canvas manipulation.</p> <p>Key Features: - Zoom in/out controls - Fit view functionality - Canvas clearing - Interactivity toggling - Customizable control buttons</p>"},{"location":"workflow/#crewcanvascontrols","title":"CrewCanvasControls","text":"<p><code>CrewCanvasControls.tsx</code> extends canvas controls with crew-specific functionality.</p> <p>Key Features: - Crew-specific actions - Agent generation controls - Layout adjustment - Connection management</p>"},{"location":"workflow/#other-supporting-components","title":"Other Supporting Components","text":"<ul> <li>WorkflowToolbarStyle.tsx: Style components for the toolbar</li> <li>FlowCanvasControls.tsx: Flow-specific canvas controls</li> <li>flow-config.ts: Configuration for the flow visualization</li> <li>index.ts: Entry point for the module</li> </ul>"},{"location":"workflow/#data-flow","title":"Data Flow","text":"<ol> <li>The <code>WorkflowDesigner</code> component initializes the state and loads any existing workflow</li> <li>User interactions with the <code>WorkflowToolbar</code> trigger actions like adding agents or tasks</li> <li>The <code>CrewCanvas</code> and <code>FlowCanvas</code> visualize the workflow nodes and edges</li> <li>Dialogs managed by <code>WorkflowDialogs</code> allow for detailed configuration of workflow elements</li> <li>Canvas controls enable navigation and visualization adjustments</li> <li>When executing, the workflow state is passed to the execution system</li> </ol>"},{"location":"workflow/#key-hooks-and-stores","title":"Key Hooks and Stores","text":"<p>The WorkflowDesigner components utilize several custom hooks and state stores:</p> <ul> <li>useWorkflowStore: Zustand store for workflow state (nodes, edges, UI state)</li> <li>useThemeManager: Manages dark/light theme</li> <li>useErrorStore: Handles error state and messages</li> <li>useAgentManager: Manages agent-related operations</li> <li>useTaskManager: Manages task-related operations</li> <li>useFlowManager: Manages flow-specific operations</li> <li>useCrewExecutionStore: Manages execution state and operations</li> <li>useShortcuts: Provides keyboard shortcuts with validation logic</li> </ul>"},{"location":"workflow/#zustand-state-management","title":"Zustand State Management","text":"<p>The WorkflowDesigner leverages Zustand for efficient state management:</p>"},{"location":"workflow/#core-stores","title":"Core Stores:","text":"<ol> <li>Workflow Store (<code>workflow.ts</code>)</li> <li>Manages the state of the workflow editor</li> <li>Tracks nodes, edges, and selection state</li> <li>Handles UI configuration and user preferences</li> <li> <p>Provides actions for manipulating the workflow</p> </li> <li> <p>Error Store (<code>error.ts</code>)</p> </li> <li>Centralizes error handling</li> <li>Manages error messages and visibility</li> <li>Provides consistent error reporting</li> <li> <p>Used by all components for error management</p> </li> <li> <p>Crew Execution Store (<code>crewExecution.ts</code>)</p> </li> <li>Manages execution state for crews and flows</li> <li>Tracks job IDs and execution status</li> <li>Provides actions for executing workflows</li> <li>Handles execution errors and notifications</li> </ol>"},{"location":"workflow/#store-integration","title":"Store Integration:","text":"<ul> <li>Components access state and actions directly from stores</li> <li>Updates are propagated automatically to all subscribers</li> <li>Stores persist relevant state to localStorage</li> <li>Custom hooks may wrap store functionality for additional logic</li> </ul>"},{"location":"workflow/#reactflow-integration","title":"ReactFlow Integration","text":"<p>The WorkflowDesigner leverages ReactFlow for graph visualization with several custom additions:</p> <ul> <li>Custom Node Types: Agent and task node implementations</li> <li>Custom Edge Types: Animated edges for visualizing connections</li> <li>Custom Controls: Enhanced control panels</li> <li>State Management: Integration with application state management</li> <li>Event Handling: Custom handlers for interactions</li> <li>Validation: Pre-operation validation for nodes and edges</li> </ul>"},{"location":"workflow/#node-operation-validation","title":"Node Operation Validation","text":"<p>The WorkflowDesigner implements comprehensive validation for node operations:</p>"},{"location":"workflow/#crew-execution-validation","title":"Crew Execution Validation:","text":"<pre><code>const validateCrewExecution = (nodes: Node[]): boolean =&gt; {\n  const agentNodes = nodes.filter(node =&gt; node.type === 'agentNode');\n  const taskNodes = nodes.filter(node =&gt; node.type === 'taskNode');\n\n  if (agentNodes.length === 0 || taskNodes.length === 0) {\n    errorStore.setErrorMessage('Crew execution requires at least one agent and one task node');\n    return false;\n  }\n\n  // Check if agent nodes have valid IDs\n  const invalidAgents = agentNodes.filter(node =&gt; !node.data?.agentId);\n  if (invalidAgents.length &gt; 0) {\n    errorStore.setErrorMessage('Some agent nodes are missing valid IDs');\n    return false;\n  }\n\n  // Check if task nodes have valid IDs\n  const invalidTasks = taskNodes.filter(node =&gt; !node.data?.taskId);\n  if (invalidTasks.length &gt; 0) {\n    errorStore.setErrorMessage('Some task nodes are missing valid IDs');\n    return false;\n  }\n\n  return true;\n};\n</code></pre>"},{"location":"workflow/#agent-operations-validation","title":"Agent Operations Validation:","text":"<pre><code>const validateAgentNodes = (nodes: Node[]): boolean =&gt; {\n  const agentNodes = nodes.filter(node =&gt; node.type === 'agentNode');\n\n  if (agentNodes.length === 0) {\n    errorStore.setErrorMessage('This operation requires at least one agent node');\n    return false;\n  }\n\n  return true;\n};\n</code></pre>"},{"location":"workflow/#connection-generation-validation","title":"Connection Generation Validation:","text":"<pre><code>if (agentNodes.length === 0 || taskNodes.length === 0) {\n  errorStore.setErrorMessage('You need at least one agent and one task to generate connections');\n  return false;\n}\n</code></pre>"},{"location":"workflow/#keyboard-shortcuts-system","title":"Keyboard Shortcuts System","text":"<p>The WorkflowDesigner includes a sophisticated keyboard shortcuts system:</p>"},{"location":"workflow/#implementation","title":"Implementation:","text":"<ul> <li>Uses the <code>useShortcuts</code> hook for tracking key sequences</li> <li>Supports multi-key shortcuts (e.g., 'e', 'c' for Execute Crew)</li> <li>Disables shortcuts when dialogs are open</li> <li>Provides extensive logging for debugging</li> <li>Uses React refs to optimize performance</li> </ul>"},{"location":"workflow/#key-features","title":"Key Features:","text":"<ul> <li>Validates node conditions before executing shortcuts</li> <li>Integrates with Zustand stores for state access</li> <li>Provides comprehensive error handling</li> <li>Supports vim-style and traditional shortcuts</li> <li>Includes tooltips and visual indicators</li> </ul>"},{"location":"workflow/#core-operations","title":"Core Operations:","text":"<ul> <li>Canvas manipulation (zoom, fit, clear)</li> <li>Agent and task operations (create, connect)</li> <li>Crew execution with validation</li> <li>Dialog control</li> <li>Node selection and editing</li> </ul>"},{"location":"workflow/#connection-and-ai-features","title":"Connection and AI Features","text":"<p>The WorkflowDesigner includes AI-powered features for workflow design:</p> <ul> <li>Auto-connection: AI-suggested connections between agents and tasks</li> <li>Agent Generation: AI-assisted agent creation</li> <li>Task Generation: AI-assisted task creation</li> <li>Crew Planning: AI-powered workflow generation</li> <li>Schema Detection: Automatic detection of data schemas</li> </ul>"},{"location":"workflow/#responsive-design","title":"Responsive Design","text":"<p>The WorkflowDesigner implements responsive design principles:</p> <ul> <li>Resizable Panels: Adjustable panel sizes</li> <li>Collapsible Elements: Toggling visibility of various elements</li> <li>Adaptive Controls: Controls that adjust to available space</li> <li>Theme Support: Light and dark theme modes</li> </ul>"},{"location":"workflow/#error-handling","title":"Error Handling","text":"<p>The WorkflowDesigner implements a robust error handling system:</p>"},{"location":"workflow/#error-store-integration","title":"Error Store Integration:","text":"<ul> <li>Centralized error state management</li> <li>Consistent error display across components</li> <li>Clear error messages for users</li> <li>Error reset capabilities</li> </ul>"},{"location":"workflow/#error-types-handled","title":"Error Types Handled:","text":"<ul> <li>Validation errors (missing nodes, invalid configurations)</li> <li>API errors (failed requests, timeouts)</li> <li>React Flow render errors (ResizeObserver issues)</li> <li>Execution errors (failed crew executions)</li> </ul>"},{"location":"workflow/#error-reporting","title":"Error Reporting:","text":"<ul> <li>Console logging for debugging</li> <li>User-friendly error displays</li> <li>Error indicators in the UI</li> <li>Error state persistence for analysis</li> </ul>"},{"location":"workflow/#best-practices","title":"Best Practices","text":"<p>When working with the WorkflowDesigner components:</p> <ol> <li>State Management:</li> <li>Use Zustand stores for global state instead of local state</li> <li>Access store actions directly in components</li> <li>Subscribe only to needed state slices for performance</li> <li> <p>Use the error store for all error reporting</p> </li> <li> <p>Validation:</p> </li> <li>Always validate node conditions before operations</li> <li>Provide clear error messages for validation failures</li> <li>Use try/catch blocks for error handling</li> <li> <p>Log validation failures for debugging</p> </li> <li> <p>React Hooks:</p> </li> <li>Follow the React Hooks rules</li> <li>Use appropriate dependency arrays for useEffect and useMemo</li> <li>Consider useRef for values that shouldn't trigger re-renders</li> <li> <p>Add ESLint comments when necessary for dependency management</p> </li> <li> <p>Performance:</p> </li> <li>Memoize expensive calculations and components</li> <li>Use React.memo for pure components</li> <li>Optimize re-renders by careful state management</li> <li> <p>Monitor React DevTools for performance issues</p> </li> <li> <p>Component Structure:</p> </li> <li>Maintain separation of concerns between components</li> <li>Use proper hooks for state management</li> <li>Follow the established patterns for dialog management</li> <li>Leverage the existing validation and error systems </li> </ol>"},{"location":"zustand/","title":"State Management with Zustand","text":"<p>This document provides an overview of the state management system used in the CrewAI Manager application, which primarily uses Zustand for state management.</p>"},{"location":"zustand/#introduction-to-zustand","title":"Introduction to Zustand","text":"<p>Zustand is a small, fast, and scalable state management solution for React applications. The application has migrated from Redux to Zustand for most of its state management needs to simplify state logic and improve performance.</p>"},{"location":"zustand/#store-structure","title":"Store Structure","text":"<p>Each Zustand store in the application follows a similar pattern:</p> <ol> <li>A TypeScript interface defining the state shape and actions</li> <li>An initial state object</li> <li>A store creation using <code>create</code> from Zustand</li> <li>Action implementations that modify the state</li> </ol>"},{"location":"zustand/#available-stores","title":"Available Stores","text":""},{"location":"zustand/#workflow-store-workflowts","title":"Workflow Store (<code>workflow.ts</code>)","text":"<p>Manages the state for the workflow editor, including nodes, edges, and UI configuration.</p> <p>State: - <code>nodes</code>: Array of workflow nodes - <code>edges</code>: Array of connections between nodes - <code>selectedEdges</code>: Currently selected edges - <code>contextMenu</code>: Context menu state (position and related edge) - <code>flowConfig</code>: Configuration for the workflow - <code>draggedNodeIds</code>: IDs of nodes being dragged - <code>manuallyPositionedNodes</code>: IDs of nodes positioned manually - <code>hasSeenTutorial</code>: Flag indicating if user has seen the tutorial - <code>hasSeenHandlebar</code>: Flag indicating if user has seen the handlebar - <code>uiState</code>: State for UI elements like minimap visibility</p> <p>Key Actions: - <code>setNodes</code>: Update the nodes in the workflow - <code>setEdges</code>: Update the edges in the workflow - <code>addEdge</code>: Add a new connection to the workflow - <code>deleteEdge</code>: Remove an edge from the workflow - <code>clearCanvas</code>: Clear all nodes and edges - <code>updateNodePosition</code>: Update a node's position</p>"},{"location":"zustand/#node-decorator-store-nodedecoratorts","title":"Node Decorator Store (<code>nodeDecorator.ts</code>)","text":"<p>Manages the state for highlighting active and completed tasks in the workflow.</p> <p>State: - <code>currentTaskId</code>: ID of the currently active task - <code>completedTaskIds</code>: Array of completed task IDs</p> <p>Key Actions: - <code>setCurrentTaskId</code>: Update the current task ID - <code>setCompletedTaskIds</code>: Update the completed tasks list - <code>addCompletedTaskId</code>: Add a task to the completed list - <code>clearCompletedTaskIds</code>: Clear all completed tasks - <code>decorateNodesWithActiveStatus</code>: Apply active/completed status to nodes</p>"},{"location":"zustand/#error-store-errorts","title":"Error Store (<code>error.ts</code>)","text":"<p>Manages application-wide error state.</p> <p>State: - <code>showError</code>: Flag indicating if an error should be displayed - <code>errorMessage</code>: Content of the error message</p> <p>Key Actions: - <code>showErrorMessage</code>: Display an error message - <code>clearError</code>: Hide and clear the current error - <code>resetError</code>: Reset error state to initial values</p>"},{"location":"zustand/#api-keys-store-apikeysts","title":"API Keys Store (<code>apiKeys.ts</code>)","text":"<p>Manages API key secrets for integrations.</p> <p>State: - <code>secrets</code>: Array of API key secrets - <code>loading</code>: Flag indicating if keys are being loaded - <code>error</code>: Error message, if any</p> <p>Key Actions: - <code>fetchAPIKeys</code>: Load API keys from the backend - <code>updateSecrets</code>: Update the list of secrets - <code>clearError</code>: Clear any error messages</p>"},{"location":"zustand/#job-management-store-jobmanagementts","title":"Job Management Store (<code>jobManagement.ts</code>)","text":"<p>Manages state related to job execution.</p> <p>State: - <code>jobId</code>: ID of the current job - <code>isRunning</code>: Flag indicating if a job is currently running - <code>selectedModel</code>: Selected model for the job - <code>planningEnabled</code>: Flag indicating if planning is enabled - <code>schemaDetectionEnabled</code>: Flag indicating if schema detection is enabled - <code>tools</code>: Available tools for the job - <code>selectedTools</code>: IDs of selected tools</p> <p>Key Actions: - <code>setJobId</code>: Update the current job ID - <code>setIsRunning</code>: Update the running state - <code>setSelectedModel</code>: Set the model to use - <code>setTools</code>: Update the available tools - <code>setSelectedTools</code>: Update the selected tools - <code>resetJobManagement</code>: Reset the state to initial values</p>"},{"location":"zustand/#model-config-store-modelconfigts","title":"Model Config Store (<code>modelConfig.ts</code>)","text":"<p>Manages configuration for LLM models.</p> <p>State: - <code>models</code>: Available models - <code>currentEditModel</code>: Currently edited model - <code>editDialogOpen</code>: Flag indicating if edit dialog is open - <code>isNewModel</code>: Flag indicating if a new model is being created - <code>loading</code>: Flag indicating if models are being loaded - <code>saving</code>: Flag indicating if model changes are being saved - <code>modelsChanged</code>: Flag indicating if models have been modified - <code>searchTerm</code>: Search term for filtering models - <code>databricksEnabled</code>: Flag indicating if Databricks is enabled - <code>error</code>: Error message, if any - <code>refreshKey</code>: Key used to trigger refreshes - <code>activeTab</code>: Currently active tab in the model config UI</p> <p>Key Actions: - <code>setModels</code>: Update the available models - <code>setCurrentEditModel</code>: Set the model being edited - <code>setEditDialogOpen</code>: Open/close the edit dialog - <code>setLoading</code>: Update the loading state - <code>setSaving</code>: Update the saving state - <code>setModelsChanged</code>: Mark models as changed/unchanged - <code>resetModelConfig</code>: Reset the state to initial values</p>"},{"location":"zustand/#run-result-store-runresultts","title":"Run Result Store (<code>runResult.ts</code>)","text":"<p>Manages the state for displaying run results.</p> <p>State: - <code>selectedRun</code>: Currently selected run result - <code>isOpen</code>: Flag indicating if the run result view is open</p> <p>Key Actions: - <code>showRunResult</code>: Display a run result - <code>closeRunResult</code>: Close the run result view - <code>setSelectedRun</code>: Set the selected run</p>"},{"location":"zustand/#theme-store-themets","title":"Theme Store (<code>theme.ts</code>)","text":"<p>Manages the application theme.</p> <p>State: - <code>mode</code>: Current theme mode (light/dark) - <code>primaryColor</code>: Primary theme color - <code>secondaryColor</code>: Secondary theme color</p> <p>Key Actions: - <code>setMode</code>: Change the theme mode - <code>setPrimaryColor</code>: Change the primary color - <code>setSecondaryColor</code>: Change the secondary color - <code>resetTheme</code>: Reset to default theme settings</p>"},{"location":"zustand/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Custom Hooks: Instead of directly using the stores in components, use the provided custom hooks from the <code>hooks</code> directory.</p> </li> <li> <p>Minimize Renders: Be careful about which parts of the state you subscribe to. Only subscribe to the specific pieces of state your component needs.</p> </li> <li> <p>Action Consistency: Use the provided actions to modify state rather than attempting to modify state directly.</p> </li> <li> <p>Type Safety: Take advantage of TypeScript interfaces to ensure type safety when working with store state.</p> </li> </ol>"},{"location":"zustand/#migration-from-redux","title":"Migration from Redux","text":"<p>Most of the application state has been migrated from Redux to Zustand, but there is still a placeholder Redux store in place for backward compatibility. New state should be implemented using Zustand stores.</p>"},{"location":"zustand/#persist-middleware","title":"Persist Middleware","text":"<p>Some stores (like the workflow store) use Zustand's persist middleware to save state to localStorage. This allows state to persist across page reloads.</p> <pre><code>export const useWorkflowStore = create&lt;WorkflowState&gt;()(\n  persist(\n    (set, get) =&gt; ({\n      // Store implementation\n    }),\n    {\n      name: 'workflow-storage',\n      partialize: (state) =&gt; ({\n        // Only persisted parts of the state\n        nodes: state.nodes,\n        edges: state.edges,\n        hasSeenTutorial: state.hasSeenTutorial,\n        hasSeenHandlebar: state.hasSeenHandlebar,\n        manuallyPositionedNodes: state.manuallyPositionedNodes\n      }),\n    }\n  )\n);\n</code></pre>"},{"location":"zustand/#zustand-store-implementation-guide","title":"Zustand Store Implementation Guide","text":"<p>This document provides guidance for implementing new Zustand stores in the CrewAI Manager application.</p>"},{"location":"zustand/#basic-structure","title":"Basic Structure","text":"<p>A typical Zustand store implementation follows this structure:</p> <pre><code>import { create } from 'zustand';\nimport { persist } from 'zustand/middleware'; // Optional, for persisted stores\n\n// 1. Define the state and actions interface\ninterface MyStoreState {\n  // State properties\n  someValue: string;\n  loading: boolean;\n  error: string | null;\n\n  // Actions\n  setSomeValue: (value: string) =&gt; void;\n  setLoading: (loading: boolean) =&gt; void;\n  setError: (error: string | null) =&gt; void;\n  resetStore: () =&gt; void;\n}\n\n// 2. Define initial state\nconst initialState = {\n  someValue: '',\n  loading: false,\n  error: null,\n};\n\n// 3. Create the store\nexport const useMyStore = create&lt;MyStoreState&gt;((set) =&gt; ({\n  // Include the initial state\n  ...initialState,\n\n  // Implement actions\n  setSomeValue: (value: string) =&gt; \n    set(() =&gt; ({ someValue: value })),\n\n  setLoading: (loading: boolean) =&gt; \n    set(() =&gt; ({ loading })),\n\n  setError: (error: string | null) =&gt; \n    set(() =&gt; ({ error })),\n\n  resetStore: () =&gt; \n    set(() =&gt; ({ ...initialState })),\n}));\n</code></pre>"},{"location":"zustand/#implementing-a-persisted-store","title":"Implementing a Persisted Store","text":"<p>For stores that need to persist their state across page reloads:</p> <pre><code>export const useMyPersistedStore = create&lt;MyStoreState&gt;()(\n  persist(\n    (set) =&gt; ({\n      // Store implementation with initial state and actions\n      ...initialState,\n\n      setSomeValue: (value: string) =&gt; \n        set(() =&gt; ({ someValue: value })),\n\n      // ... other actions\n    }),\n    {\n      name: 'my-persisted-store', // Name used in localStorage\n      partialize: (state) =&gt; ({\n        // Only include the properties you want to persist\n        someValue: state.someValue,\n        // Exclude transient state like loading or error\n      }),\n    }\n  )\n);\n</code></pre>"},{"location":"zustand/#using-get-to-access-current-state","title":"Using <code>get</code> to Access Current State","text":"<p>Sometimes an action needs access to the current state:</p> <pre><code>export const useCounterStore = create&lt;CounterState&gt;((set, get) =&gt; ({\n  count: 0,\n\n  increment: () =&gt; \n    set((state) =&gt; ({ count: state.count + 1 })),\n\n  // Alternative using get to access current state\n  incrementAlternative: () =&gt; {\n    const currentCount = get().count;\n    set({ count: currentCount + 1 });\n  },\n\n  reset: () =&gt; \n    set({ count: 0 }),\n}));\n</code></pre>"},{"location":"zustand/#handling-async-actions","title":"Handling Async Actions","text":"<p>For stores that need to interact with APIs:</p> <pre><code>import { create } from 'zustand';\nimport { YourAPIService } from '../api';\n\ninterface DataState {\n  data: any[];\n  loading: boolean;\n  error: string | null;\n\n  fetchData: () =&gt; Promise&lt;void&gt;;\n  clearData: () =&gt; void;\n}\n\nexport const useDataStore = create&lt;DataState&gt;((set) =&gt; ({\n  data: [],\n  loading: false,\n  error: null,\n\n  fetchData: async () =&gt; {\n    set({ loading: true, error: null });\n\n    try {\n      const apiService = YourAPIService.getInstance();\n      const data = await apiService.getData();\n      set({ data, loading: false });\n    } catch (error) {\n      set({ \n        loading: false, \n        error: error instanceof Error ? error.message : 'An unexpected error occurred'\n      });\n    }\n  },\n\n  clearData: () =&gt; \n    set({ data: [] }),\n}));\n</code></pre>"},{"location":"zustand/#implementing-computed-values","title":"Implementing Computed Values","text":"<p>Zustand doesn't have built-in computed values like some other state management libraries, but you can implement them in a custom hook:</p> <pre><code>// Store definition\ninterface TodoState {\n  todos: { id: number; text: string; completed: boolean }[];\n  addTodo: (text: string) =&gt; void;\n  toggleTodo: (id: number) =&gt; void;\n}\n\nexport const useTodoStore = create&lt;TodoState&gt;((set) =&gt; ({\n  todos: [],\n\n  addTodo: (text: string) =&gt; \n    set((state) =&gt; ({ \n      todos: [...state.todos, { id: Date.now(), text, completed: false }] \n    })),\n\n  toggleTodo: (id: number) =&gt; \n    set((state) =&gt; ({ \n      todos: state.todos.map(todo =&gt; \n        todo.id === id ? { ...todo, completed: !todo.completed } : todo\n      ) \n    })),\n}));\n\n// Custom hook with computed values\nimport { useMemo } from 'react';\n\nexport const useTodoWithComputed = () =&gt; {\n  const { todos, addTodo, toggleTodo } = useTodoStore();\n\n  const completedTodos = useMemo(() =&gt; \n    todos.filter(todo =&gt; todo.completed), [todos]);\n\n  const incompleteTodos = useMemo(() =&gt; \n    todos.filter(todo =&gt; !todo.completed), [todos]);\n\n  const totalTodos = useMemo(() =&gt; \n    todos.length, [todos]);\n\n  return {\n    todos,\n    completedTodos,\n    incompleteTodos,\n    totalTodos,\n    addTodo,\n    toggleTodo,\n  };\n};\n</code></pre>"},{"location":"zustand/#combining-multiple-stores","title":"Combining Multiple Stores","text":"<p>To share functionality between stores or combine multiple stores, use custom hooks:</p> <pre><code>import { useUserStore } from './userStore';\nimport { useProductStore } from './productStore';\n\nexport const useShoppingCart = () =&gt; {\n  const { userId, isAuthenticated } = useUserStore();\n  const { products, fetchProductById } = useProductStore();\n\n  // Implement shopping cart logic using both stores\n\n  return {\n    // Return combined state and functions\n  };\n};\n</code></pre>"},{"location":"zustand/#best-practices_1","title":"Best Practices","text":"<ol> <li> <p>Separating Concerns: Each store should focus on a specific domain (user, products, UI state, etc.).</p> </li> <li> <p>Naming Conventions:</p> </li> <li>Store hooks: <code>useXXXStore</code></li> <li>Custom hooks wrapping stores: <code>useXXX</code></li> <li>Boolean state: <code>isXXX</code> or <code>hasXXX</code></li> <li> <p>Action functions: <code>setXXX</code>, <code>updateXXX</code>, <code>resetXXX</code></p> </li> <li> <p>Type Safety: Always define TypeScript interfaces for state and action parameters.</p> </li> <li> <p>Immutability: Always treat state as immutable and create new objects/arrays when updating.</p> </li> <li> <p>Reusability: Prefer small, focused stores that can be combined with custom hooks.</p> </li> <li> <p>Avoid Derived State: Don't store values that can be derived from other state.</p> </li> <li> <p>Documentation: Document each store's purpose, state structure, and action behaviors.</p> </li> </ol>"},{"location":"zustand/#example-complete-store-implementation","title":"Example: Complete Store Implementation","text":"<p>Here's a complete example of a Zustand store for user authentication:</p> <pre><code>import { create } from 'zustand';\nimport { persist } from 'zustand/middleware';\nimport { AuthService } from '../api/AuthService';\n\ninterface User {\n  id: string;\n  username: string;\n  email: string;\n  role: 'admin' | 'user';\n}\n\ninterface AuthState {\n  // State\n  user: User | null;\n  isAuthenticated: boolean;\n  token: string | null;\n  loading: boolean;\n  error: string | null;\n\n  // Actions\n  login: (username: string, password: string) =&gt; Promise&lt;void&gt;;\n  logout: () =&gt; void;\n  checkAuth: () =&gt; Promise&lt;void&gt;;\n  clearError: () =&gt; void;\n}\n\nconst initialState = {\n  user: null,\n  isAuthenticated: false,\n  token: null,\n  loading: false,\n  error: null,\n};\n\nexport const useAuthStore = create&lt;AuthState&gt;()(\n  persist(\n    (set) =&gt; ({\n      ...initialState,\n\n      login: async (username: string, password: string) =&gt; {\n        set({ loading: true, error: null });\n\n        try {\n          const authService = AuthService.getInstance();\n          const { user, token } = await authService.login(username, password);\n\n          set({ \n            user,\n            token,\n            isAuthenticated: true,\n            loading: false\n          });\n        } catch (error) {\n          set({ \n            loading: false, \n            error: error instanceof Error ? error.message : 'Login failed'\n          });\n        }\n      },\n\n      logout: () =&gt; {\n        const authService = AuthService.getInstance();\n        authService.logout();\n\n        set({ \n          user: null,\n          token: null,\n          isAuthenticated: false,\n          error: null\n        });\n      },\n\n      checkAuth: async () =&gt; {\n        set({ loading: true });\n\n        try {\n          const authService = AuthService.getInstance();\n          const { user, token } = await authService.checkAuth();\n\n          set({ \n            user,\n            token,\n            isAuthenticated: true,\n            loading: false\n          });\n        } catch (error) {\n          set({ \n            user: null,\n            token: null,\n            isAuthenticated: false,\n            loading: false\n          });\n        }\n      },\n\n      clearError: () =&gt; \n        set({ error: null }),\n    }),\n    {\n      name: 'auth-storage',\n      partialize: (state) =&gt; ({\n        token: state.token,\n      }),\n    }\n  )\n); \n\n\n\n# Custom Hooks\n\nThis document provides an overview of the custom hooks used in the CrewAI Manager application to interact with Zustand stores.\n\n## Introduction\n\nThe application uses custom hooks to provide a clean interface between components and Zustand stores. These hooks encapsulate store interactions and provide additional functionality and type safety.\n\n## Hook Structure\n\nMost custom hooks in the application follow a similar pattern:\n\n1. Import state and actions from a Zustand store\n2. Create callback functions for actions (using `useCallback`)\n3. Return a simplified interface with state and wrapped action handlers\n\n## Global Hooks\n\n### useError\n\n**File**: `src/hooks/global/useError.ts`\n\nProvides access to the application-wide error handling system.\n\n```typescript\nimport { useError } from '../hooks/global/useError';\n\nconst MyComponent = () =&gt; {\n  const { \n    showError,          // Boolean indicating if an error is being shown\n    errorMessage,       // String containing the error message\n    handleCloseError,   // Function to close the error dialog\n    showErrorMessage    // Function to show a new error message\n  } = useError();\n\n  // Example usage\n  const handleSubmit = async () =&gt; {\n    try {\n      await submitData();\n    } catch (error) {\n      showErrorMessage('Failed to submit data: ' + error.message);\n    }\n  };\n};\n</code></pre>"},{"location":"zustand/#useapikeys","title":"useAPIKeys","text":"<p>File: <code>src/hooks/global/useAPIKeys.ts</code></p> <p>Manages API keys for external services.</p> <pre><code>import { useAPIKeys } from '../hooks/global/useAPIKeys';\n\nconst MyComponent = () =&gt; {\n  const { \n    secrets,        // Array of API key secrets\n    loading,        // Boolean indicating if keys are being loaded\n    error,          // Error message, if any\n    updateSecrets   // Function to update the list of secrets\n  } = useAPIKeys();\n\n  // The hook automatically fetches API keys on mount\n};\n</code></pre>"},{"location":"zustand/#usemodelconfig","title":"useModelConfig","text":"<p>File: <code>src/hooks/global/useModelConfig.ts</code></p> <p>Manages configuration for LLM models.</p> <pre><code>import { useModelConfig } from '../hooks/global/useModelConfig';\n\nconst MyComponent = () =&gt; {\n  const {\n    models,                  // Available models\n    currentEditModel,        // Currently edited model\n    editDialogOpen,          // Is edit dialog open\n    isNewModel,              // Is a new model being created\n    loading,                 // Are models being loaded\n    saving,                  // Are changes being saved\n    handleSetModels,         // Update models\n    handleSetCurrentEditModel, // Set model being edited\n    handleSetEditDialogOpen, // Open/close edit dialog\n    // ... other state and actions\n  } = useModelConfig();\n};\n</code></pre>"},{"location":"zustand/#userunresult","title":"useRunResult","text":"<p>File: <code>src/hooks/global/useRunResult.ts</code></p> <p>Manages the state for displaying execution run results.</p> <pre><code>import { useRunResult } from '../hooks/global/useRunResult';\n\nconst MyComponent = () =&gt; {\n  const {\n    selectedRun,       // Currently selected run result\n    isOpen,            // Is run result view open\n    showRunResult,     // Show a run result\n    closeRunResult,    // Close run result view\n    setSelectedRun     // Set selected run\n  } = useRunResult();\n\n  // Example usage\n  const handleRunClick = (run) =&gt; {\n    showRunResult(run);\n  };\n};\n</code></pre>"},{"location":"zustand/#workflow-hooks","title":"Workflow Hooks","text":""},{"location":"zustand/#usenodedecorator","title":"useNodeDecorator","text":"<p>File: <code>src/hooks/workflow/useNodeDecorator.ts</code></p> <p>Provides methods to decorate nodes with active and completed status.</p> <pre><code>import { useNodeDecorator } from '../hooks/workflow/useNodeDecorator';\n\nconst MyComponent = () =&gt; {\n  const {\n    currentTaskId,            // Currently active task ID\n    completedTaskIds,         // List of completed task IDs\n    setCurrentTaskId,         // Update active task\n    setCompletedTaskIds,      // Set all completed tasks\n    addCompletedTaskId,       // Add a completed task\n    clearCompletedTaskIds,    // Clear completed tasks\n    decorateNodes             // Apply decoration to nodes\n  } = useNodeDecorator();\n\n  // Example usage\n  const updateNodeVisuals = (nodes, edges) =&gt; {\n    const decoratedNodes = decorateNodes(nodes, edges);\n    setNodes(decoratedNodes);\n  };\n};\n</code></pre>"},{"location":"zustand/#useworkflowredux","title":"useWorkflowRedux","text":"<p>File: <code>src/hooks/workflow/useWorkflowRedux.ts</code></p> <p>Provides access to the workflow editor state and operations.</p> <pre><code>import { useWorkflowRedux } from '../hooks/workflow/useWorkflowRedux';\n\nconst MyComponent = () =&gt; {\n  const {\n    nodes,               // Workflow nodes\n    edges,               // Workflow edges\n    selectedEdges,       // Selected edges\n    handleClearCanvas,   // Clear the canvas\n    handleAddEdge,       // Add an edge\n    handleDeleteEdge,    // Delete an edge\n    onNodesChange,       // Handle node changes\n    onEdgesChange,       // Handle edge changes\n    // ... other state and actions\n  } = useWorkflowRedux({\n    showErrorMessage: (msg) =&gt; console.error(msg)\n  });\n};\n</code></pre>"},{"location":"zustand/#usecrewexecution","title":"useCrewExecution","text":"<p>File: <code>src/hooks/workflow/useCrewExecution.ts</code></p> <p>Manages the execution of CrewAI workflows.</p> <pre><code>import { useCrewExecution } from '../hooks/workflow/useCrewExecution';\n\nconst MyComponent = () =&gt; {\n  const {\n    isExecuting,         // Is a workflow being executed\n    jobId,               // Current job ID\n    selectedModel,       // Selected model for execution\n    handleSetJobId,      // Set job ID\n    handleSetIsExecuting, // Set execution state\n    handleExecuteCrew,   // Execute a crew\n    // ... other state and actions\n  } = useCrewExecution();\n\n  // Example usage\n  const startExecution = async () =&gt; {\n    await handleExecuteCrew(crewConfig);\n  };\n};\n</code></pre>"},{"location":"zustand/#usejobmanagement","title":"useJobManagement","text":"<p>File: <code>src/hooks/workflow/useJobManagement.ts</code></p> <p>Manages job execution state and tools.</p> <pre><code>import { useJobManagement } from '../hooks/workflow/useJobManagement';\n\nconst MyComponent = () =&gt; {\n  const {\n    jobId,                // Current job ID\n    isRunning,            // Is a job running\n    selectedModel,        // Selected model\n    tools,                // Available tools\n    selectedTools,        // Selected tools\n    handleSetJobId,       // Set job ID\n    handleSetIsRunning,   // Set running state\n    handleSetSelectedTools, // Set selected tools\n    // ... other state and actions\n  } = useJobManagement();\n};\n</code></pre>"},{"location":"zustand/#context-hooks","title":"Context Hooks","text":""},{"location":"zustand/#usethemecontext","title":"useThemeContext","text":"<p>File: <code>src/hooks/context/useThemeContext.ts</code></p> <p>Provides access to the application theme settings.</p> <pre><code>import { useThemeContext } from '../hooks/context/useThemeContext';\n\nconst MyComponent = () =&gt; {\n  const {\n    mode,               // Current theme mode (light/dark)\n    primaryColor,       // Primary theme color\n    secondaryColor,     // Secondary theme color\n    handleModeChange,   // Change theme mode\n    handlePrimaryColorChange, // Change primary color\n    handleSecondaryColorChange, // Change secondary color\n    handleResetTheme    // Reset to default theme\n  } = useThemeContext();\n\n  // Example usage\n  const toggleTheme = () =&gt; {\n    handleModeChange(mode === 'light' ? 'dark' : 'light');\n  };\n};\n</code></pre>"},{"location":"zustand/#best-practices_2","title":"Best Practices","text":"<ol> <li> <p>Use Component-Specific Hooks: For complex components, consider creating component-specific hooks that use global hooks internally.</p> </li> <li> <p>Minimize Dependencies: Keep the dependency array of <code>useCallback</code> and <code>useEffect</code> as small as possible to prevent unnecessary rerenders.</p> </li> <li> <p>Handle Side Effects in Hooks: Manage API calls and side effects inside hooks rather than components when possible.</p> </li> <li> <p>Consistent Naming: Use the <code>handleXXX</code> naming convention for action handlers and <code>isXXX</code> for boolean state.</p> </li> <li> <p>Type Safety: Ensure all hooks have proper TypeScript typing for parameters and return values.</p> </li> </ol>"},{"location":"zustand/#example-building-a-custom-hook","title":"Example: Building a Custom Hook","text":"<p>Here's an example of how a custom hook is structured:</p> <pre><code>import { useCallback } from 'react';\nimport { useYourZustandStore } from '../../store/yourStore';\n\nexport const useYourCustomHook = () =&gt; {\n  // Get state and actions from Zustand store\n  const { \n    someState, \n    someAction, \n    anotherState,\n    anotherAction \n  } = useYourZustandStore();\n\n  // Create callback functions for actions\n  const handleSomeAction = useCallback((param: string) =&gt; {\n    // Additional logic if needed\n    someAction(param);\n  }, [someAction]);\n\n  const handleAnotherAction = useCallback(() =&gt; {\n    // Additional logic if needed\n    anotherAction();\n  }, [anotherAction]);\n\n  // Return simplified interface\n  return {\n    someState,\n    anotherState,\n    handleSomeAction,\n    handleAnotherAction,\n  };\n};\n</code></pre>"},{"location":"zustand/#migration-examples","title":"Migration Examples","text":""},{"location":"zustand/#migrating-from-utility-functions-to-zustand","title":"Migrating from Utility Functions to Zustand","text":"<p>As part of the application's evolution, we are moving utility functions that manage state to Zustand stores. This section provides an example of how to migrate a utility function to a Zustand store.</p>"},{"location":"zustand/#case-study-node-decorator","title":"Case Study: Node Decorator","text":"<p>The Node Decorator system was originally implemented as a utility function in <code>src/utils/nodeDecorator.ts</code>. It has been migrated to a Zustand store to provide better state management and integration with the React component lifecycle.</p>"},{"location":"zustand/#before-utility-function-approach","title":"Before: Utility Function Approach","text":"<pre><code>// src/utils/nodeDecorator.ts (original)\nimport { Node, Edge } from 'reactflow';\n\nexport const decorateNodesWithActiveStatus = (\n  nodes: Node[], \n  edges?: Edge[], \n  currentTaskId?: string,\n  completedTaskIds: string[] = []\n): Node[] =&gt; {\n  // Implementation details\n  // ...\n};\n\n// Usage in a component\nimport { decorateNodesWithActiveStatus } from '../utils/nodeDecorator';\n\nconst MyComponent = () =&gt; {\n  const [nodes, setNodes] = useState&lt;Node[]&gt;([]);\n  const [edges, setEdges] = useState&lt;Edge[]&gt;([]);\n  const [currentTaskId, setCurrentTaskId] = useState&lt;string | null&gt;(null);\n  const [completedTasks, setCompletedTasks] = useState&lt;string[]&gt;([]);\n\n  // When task status changes\n  useEffect(() =&gt; {\n    const decoratedNodes = decorateNodesWithActiveStatus(\n      nodes,\n      edges,\n      currentTaskId || undefined,\n      completedTasks\n    );\n    setNodes(decoratedNodes);\n  }, [currentTaskId, completedTasks]);\n};\n</code></pre>"},{"location":"zustand/#after-zustand-store-approach","title":"After: Zustand Store Approach","text":"<pre><code>// src/store/nodeDecorator.ts\nimport { create } from 'zustand';\nimport { Node, Edge } from 'reactflow';\n\ninterface NodeDecoratorState {\n  currentTaskId: string | undefined;\n  completedTaskIds: string[];\n\n  setCurrentTaskId: (taskId: string | undefined) =&gt; void;\n  setCompletedTaskIds: (taskIds: string[]) =&gt; void;\n  decorateNodesWithActiveStatus: (nodes: Node[], edges?: Edge[]) =&gt; Node[];\n}\n\nexport const useNodeDecoratorStore = create&lt;NodeDecoratorState&gt;((set, get) =&gt; ({\n  // State and actions implementation\n  // ...\n}));\n\n// src/hooks/workflow/useNodeDecorator.ts\nimport { useCallback } from 'react';\nimport { useNodeDecoratorStore } from '../../store/nodeDecorator';\n\nexport const useNodeDecorator = () =&gt; {\n  // Custom hook implementation\n  // ...\n};\n\n// Usage in a component\nimport { useNodeDecorator } from '../hooks/workflow/useNodeDecorator';\n\nconst MyComponent = () =&gt; {\n  const [nodes, setNodes] = useState&lt;Node[]&gt;([]);\n  const [edges, setEdges] = useState&lt;Edge[]&gt;([]);\n  const { \n    setCurrentTaskId, \n    setCompletedTaskIds, \n    decorateNodes \n  } = useNodeDecorator();\n\n  // When task status changes\n  useEffect(() =&gt; {\n    // Update the store state\n    setCurrentTaskId(taskId);\n    setCompletedTaskIds(completedTasks);\n\n    // Apply decoration\n    const decoratedNodes = decorateNodes(nodes, edges);\n    setNodes(decoratedNodes);\n  }, [taskId, completedTasks]);\n};\n</code></pre>"},{"location":"zustand/#benefits-of-migration","title":"Benefits of Migration","text":"<ol> <li>State Persistence: Zustand stores can persist state across rerenders and component unmounts</li> <li>Centralized State: State is managed in a single location rather than being passed through props</li> <li>Performance: Zustand is optimized for performance and reduces unnecessary rerenders</li> <li>Type Safety: TypeScript interfaces ensure proper state and action usage</li> <li>Testing: Easier to test state changes and actions in isolation</li> <li>Reusability: State logic can be easily shared between components</li> </ol>"},{"location":"zustand/#migration-process","title":"Migration Process","text":"<ol> <li>Create a Zustand store: Define state and actions in a new store</li> <li>Create a custom hook: Provide a clean interface to the store</li> <li>Update components: Replace direct function calls with hook usage</li> <li>Provide backward compatibility: Update the original utility to use the store internally</li> <li>Document the migration: Add documentation on the new approach</li> </ol> <p>For detailed examples, see: - Node Decorator Store - Node Decorator Hook - Node Decorator Documentation </p>"}]}